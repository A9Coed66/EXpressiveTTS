{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Chunk audio\n",
    "    output: 1. chunked audio: audio file\n",
    "2. Denoise audio\n",
    "    output: 2.denoise audio: audio file\n",
    "3. Diarization\n",
    "    output: 3. diary: dataframe [columns: start, end, speaker]\n",
    "4. Speaker labeled from diary logs\n",
    "    output: 4. speaker labeled: dataframe [columns: audio_path, diary_label, model_label, score, verified]\n",
    "5. Concat near audio files to one file\n",
    "    output: 5. concatenated audio:  dataframe [columns: start. end, speaker]\n",
    "                                    audio file\n",
    "6. Audio speech recognition:\n",
    "    output: 6. transcript: dataframe [columns: audio_path, transcript, speaker]\n",
    "\"\"\"\n",
    "### 0. setup data\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-ap\", \"--audio_path\", type=str, default=0,\n",
    "#     help=\"path of audio file\")\n",
    "# ap.add_argument(\"-fn\", \"--folder_name\", type=str)\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "### 1. Chunk audio\n",
    "from split_audio import split_audio\n",
    "from denoise import denoise\n",
    "from create_diarization import create_diarization\n",
    "from remove_collision import remove_collision, split_diarization\n",
    "# from verify_speaker import verify_speaker\n",
    "# from concat_audio import concat_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/home/tuannd/tuanlha/EXpressiveTTS/data/audio/minh yeu nhau di.mp3'\n",
    "folder_name = 'MYNBYT/T1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_audio import split_audio\n",
    "split_audio(audio_path, folder_name)    # Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save chunk_4.mp3\n",
      "Save chunk_0.mp3\n",
      "Save chunk_5.mp3\n",
      "Save chunk_2.mp3\n",
      "Save chunk_1.mp3\n",
      "Save chunk_6.mp3\n",
      "Save chunk_3.mp3\n"
     ]
    }
   ],
   "source": [
    "from denoise import denoise\n",
    "denoise(folder_name)                    # Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display as disp\n",
    "import torch\n",
    "import torchaudio\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio\n",
    "import os\n",
    "\n",
    "def denoise(folder_name, get_audio = True):\n",
    "    model = pretrained.dns64().cuda()\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/denoised/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/chunk/{folder_name}'):    # file_name = chunk/yeunhaudi/chunk_{i}.mp3\n",
    "        file_path = os.path.join(f'{data_path}/chunk/{folder_name}', file_name)\n",
    "        wav, sr = torchaudio.load(file_path)\n",
    "        wav = convert_audio(wav.cuda(), sr, model.sample_rate, model.chin)\n",
    "        with torch.no_grad():\n",
    "            denoised = model(wav[None])[0]\n",
    "        if get_audio:\n",
    "            torchaudio.save(f'{save_path}/{file_name}', denoised.to('cpu'), sr)\n",
    "            print(f\"Save {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading diarization model...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "secret = \"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\"\n",
    "\n",
    "print(\"Loading diarization model...\")\n",
    "diarization = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=secret)\n",
    "\n",
    "\n",
    "diarization.to(torch.device(\"cuda\"))\n",
    "\n",
    "def create_diarization(folder_name):\n",
    "    # apply pretrained pipeline\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/diary/{folder_name}'\n",
    "\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/denoised/{folder_name}'):\n",
    "        file_path = os.path.join(f'{data_path}/denoised/{folder_name}', file_name)\n",
    "        diary = diarization(file_path)\n",
    "        with open(f'{save_path}/logs_{file_name[:-4]}.pkl', 'wb') as f:\n",
    "            pickle.dump(diary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3008) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2816) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1472) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1280) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3168) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2688) too large for available bit count (2384)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (840)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (736) too large for available bit count (656)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2528) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2208) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2656) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (928) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3488) too large for available bit count (3352)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1792) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1024) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1984) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2208) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2816) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2496) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1600) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2272) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2784) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1280) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (656)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (840)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1760) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3072) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1984) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2368) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2272) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2528) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2368) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2048) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2464) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1024) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2496) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2048) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2272) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2464) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2016) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1888) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1792) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2560) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2368) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1568) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1472) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1728) too large for available bit count (1704)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2240) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1984) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2240) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1824) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3008) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1472) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1312) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1472) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1760) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1568) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (656)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1984) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2016) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2016) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1568) too large for available bit count (1520)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2368) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (928) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1520)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2848) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1824) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1280) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2688) too large for available bit count (2568)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3104) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1024) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1728) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1232)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1232)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2592) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2080) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2272) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2464) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2144) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (656)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1024) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (928) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3072) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2528) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2048) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1760) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3072) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1824) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n"
     ]
    }
   ],
   "source": [
    "create_diarization(folder_name)         # Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=1.0s stop=1.9s speaker_SPEAKER_00\n",
      "start=7.1s stop=8.0s speaker_SPEAKER_00\n",
      "start=8.3s stop=8.4s speaker_SPEAKER_00\n",
      "start=20.0s stop=21.9s speaker_SPEAKER_00\n",
      "start=28.3s stop=28.8s speaker_SPEAKER_00\n",
      "start=29.3s stop=29.7s speaker_SPEAKER_00\n",
      "start=30.7s stop=36.7s speaker_SPEAKER_04\n",
      "start=36.7s stop=42.6s speaker_SPEAKER_01\n",
      "start=43.0s stop=43.6s speaker_SPEAKER_01\n",
      "start=44.0s stop=46.4s speaker_SPEAKER_01\n",
      "start=47.2s stop=47.5s speaker_SPEAKER_01\n",
      "start=47.9s stop=48.3s speaker_SPEAKER_01\n",
      "start=48.3s stop=48.5s speaker_SPEAKER_00\n",
      "start=48.5s stop=49.0s speaker_SPEAKER_01\n",
      "start=49.0s stop=49.8s speaker_SPEAKER_00\n",
      "start=50.2s stop=50.5s speaker_SPEAKER_00\n",
      "start=52.7s stop=53.5s speaker_SPEAKER_00\n",
      "start=54.6s stop=55.7s speaker_SPEAKER_00\n",
      "start=55.7s stop=56.0s speaker_SPEAKER_00\n",
      "start=64.3s stop=64.6s speaker_SPEAKER_00\n",
      "start=71.9s stop=72.6s speaker_SPEAKER_02\n",
      "start=74.0s stop=75.0s speaker_SPEAKER_02\n",
      "start=75.5s stop=77.0s speaker_SPEAKER_02\n",
      "start=77.5s stop=80.5s speaker_SPEAKER_02\n",
      "start=80.9s stop=84.1s speaker_SPEAKER_02\n",
      "start=84.7s stop=86.0s speaker_SPEAKER_01\n",
      "start=86.6s stop=87.8s speaker_SPEAKER_02\n",
      "start=88.4s stop=89.9s speaker_SPEAKER_02\n",
      "start=95.3s stop=96.4s speaker_SPEAKER_04\n",
      "start=96.9s stop=98.0s speaker_SPEAKER_04\n",
      "start=98.5s stop=98.9s speaker_SPEAKER_02\n",
      "start=99.7s stop=101.4s speaker_SPEAKER_02\n",
      "start=102.4s stop=103.1s speaker_SPEAKER_04\n",
      "start=103.5s stop=104.0s speaker_SPEAKER_02\n",
      "start=104.6s stop=105.4s speaker_SPEAKER_02\n",
      "start=107.2s stop=108.1s speaker_SPEAKER_02\n",
      "start=108.5s stop=109.9s speaker_SPEAKER_02\n",
      "start=110.3s stop=111.0s speaker_SPEAKER_02\n",
      "start=111.5s stop=116.0s speaker_SPEAKER_02\n",
      "start=116.2s stop=117.2s speaker_SPEAKER_02\n",
      "start=121.0s stop=122.1s speaker_SPEAKER_02\n",
      "start=124.2s stop=130.5s speaker_SPEAKER_02\n",
      "start=130.7s stop=132.1s speaker_SPEAKER_02\n",
      "start=132.1s stop=132.3s speaker_SPEAKER_04\n",
      "start=137.3s stop=137.6s speaker_SPEAKER_00\n",
      "start=139.1s stop=139.2s speaker_SPEAKER_00\n",
      "start=139.2s stop=139.2s speaker_SPEAKER_00\n",
      "start=139.3s stop=139.7s speaker_SPEAKER_00\n",
      "start=140.2s stop=140.5s speaker_SPEAKER_00\n",
      "start=148.9s stop=150.0s speaker_SPEAKER_04\n",
      "start=150.6s stop=151.2s speaker_SPEAKER_04\n",
      "start=152.3s stop=152.9s speaker_SPEAKER_03\n",
      "start=156.0s stop=156.7s speaker_SPEAKER_04\n",
      "start=159.3s stop=163.1s speaker_SPEAKER_02\n",
      "start=170.1s stop=171.1s speaker_SPEAKER_00\n",
      "start=171.8s stop=173.2s speaker_SPEAKER_00\n",
      "start=172.3s stop=172.3s speaker_SPEAKER_01\n",
      "start=175.6s stop=176.4s speaker_SPEAKER_00\n",
      "start=176.4s stop=176.5s speaker_SPEAKER_01\n",
      "start=176.5s stop=179.6s speaker_SPEAKER_04\n",
      "start=176.5s stop=176.6s speaker_SPEAKER_01\n",
      "start=181.0s stop=181.6s speaker_SPEAKER_01\n",
      "start=182.1s stop=182.2s speaker_SPEAKER_01\n",
      "start=182.2s stop=182.2s speaker_SPEAKER_00\n",
      "start=182.2s stop=182.3s speaker_SPEAKER_04\n",
      "start=182.3s stop=182.4s speaker_SPEAKER_01\n",
      "start=183.9s stop=184.5s speaker_SPEAKER_04\n",
      "start=185.2s stop=185.9s speaker_SPEAKER_04\n",
      "start=186.4s stop=188.8s speaker_SPEAKER_04\n",
      "start=190.1s stop=190.5s speaker_SPEAKER_03\n",
      "start=190.6s stop=191.8s speaker_SPEAKER_04\n",
      "start=194.7s stop=195.1s speaker_SPEAKER_03\n",
      "start=196.9s stop=197.4s speaker_SPEAKER_03\n",
      "start=201.4s stop=201.9s speaker_SPEAKER_03\n",
      "start=203.2s stop=204.9s speaker_SPEAKER_03\n",
      "start=209.4s stop=212.7s speaker_SPEAKER_03\n",
      "start=213.7s stop=214.3s speaker_SPEAKER_03\n",
      "start=225.5s stop=227.5s speaker_SPEAKER_03\n",
      "start=228.1s stop=228.5s speaker_SPEAKER_03\n",
      "start=232.4s stop=233.8s speaker_SPEAKER_02\n",
      "start=234.7s stop=234.8s speaker_SPEAKER_03\n",
      "start=236.2s stop=240.2s speaker_SPEAKER_02\n",
      "start=241.9s stop=242.9s speaker_SPEAKER_04\n",
      "start=244.3s stop=244.4s speaker_SPEAKER_04\n",
      "start=244.4s stop=245.0s speaker_SPEAKER_01\n",
      "start=246.1s stop=248.1s speaker_SPEAKER_01\n",
      "start=248.5s stop=249.0s speaker_SPEAKER_01\n",
      "start=249.4s stop=250.6s speaker_SPEAKER_02\n",
      "start=251.4s stop=253.7s speaker_SPEAKER_02\n",
      "start=253.9s stop=255.5s speaker_SPEAKER_04\n",
      "start=255.9s stop=256.2s speaker_SPEAKER_04\n",
      "start=257.9s stop=257.9s speaker_SPEAKER_02\n",
      "start=257.9s stop=258.3s speaker_SPEAKER_03\n",
      "start=270.1s stop=271.8s speaker_SPEAKER_02\n",
      "start=272.3s stop=272.9s speaker_SPEAKER_02\n",
      "start=272.5s stop=273.6s speaker_SPEAKER_04\n",
      "start=274.2s stop=274.7s speaker_SPEAKER_04\n",
      "start=275.9s stop=277.6s speaker_SPEAKER_04\n",
      "start=290.0s stop=290.2s speaker_SPEAKER_00\n",
      "start=292.2s stop=294.0s speaker_SPEAKER_00\n",
      "start=298.0s stop=298.9s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/tuannd/tuanlha/EXpressiveTTS/data/diary/MYNBYT/T1/logs_chunk_0.pkl\"\n",
    "with open(path, 'rb') as file:\n",
    "    # S dng pickle  ti i tng t tp\n",
    "    loaded_object = pickle.load(file)\n",
    "for turn, _, speaker in loaded_object.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import librosa\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def create_origin_logs(diarization):\n",
    "    logs = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        logs.append([round(turn.start,2), round(turn.end,2), speaker])\n",
    "    return logs\n",
    "\n",
    "def remove_collision(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/logs_no_col/{folder_name}'\n",
    "\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    for file_name in os.listdir(f'{data_path}/diary/{folder_name}'):\n",
    "        print(file_name)\n",
    "        file_path = os.path.join(f'{data_path}/diary/{folder_name}', file_name)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            diary = pickle.load(f)\n",
    "        origin_log = create_origin_logs(diary)\n",
    "        print(origin_log)\n",
    "        log = []\n",
    "        # Pre\n",
    "        if not origin_log:\n",
    "            with open(f'{save_path}/{file_name[:-4]}.json', 'w') as f:   \n",
    "            # /log_no_col/Yen nhau di/logs_chunk_1.json\n",
    "                json.dump(log, f)\n",
    "            continue\n",
    "\n",
    "        preivous = [origin_log[0][0], origin_log[0][1]]\n",
    "        last_end = origin_log[0][1]\n",
    "        if last_end < origin_log[1][0]:\n",
    "            log.append([preivous, origin_log[0][2]])\n",
    "        \n",
    "        # In\n",
    "        for i in range(1, len(origin_log)-1):\n",
    "            start, end = origin_log[i][0], origin_log[i][1]\n",
    "            if start < last_end:\n",
    "                last_end = max(last_end, end)\n",
    "            else:\n",
    "                if end > origin_log[i+1][0]:\n",
    "                    preivous = [start, end]\n",
    "                else:\n",
    "                    preivous = [start, end]\n",
    "                    if end-start > 1:\n",
    "                        log.append([[start, end], origin_log[i][2]])\n",
    "        \n",
    "        # End\n",
    "        if origin_log[-1][0] > last_end+1:\n",
    "            if origin_log[-1][1] - origin_log[-1][0]>0.1:\n",
    "                log.append([[origin_log[-1][0], origin_log[-1][1]], origin_log[-1][2]])\n",
    "\n",
    "        # Save\n",
    "        with open(f'{save_path}/{file_name[:-4]}.json', 'w') as f:   \n",
    "            # /log_no_col/Yen nhau di/logs_chunk_1.json\n",
    "            json.dump(log, f)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_chunk_4.pkl\n",
      "[[0.03, 0.89, 'SPEAKER_02'], [3.86, 5.03, 'SPEAKER_02'], [5.09, 5.43, 'SPEAKER_02'], [6.78, 9.19, 'SPEAKER_02'], [9.8, 11.15, 'SPEAKER_02'], [11.74, 13.18, 'SPEAKER_02'], [14.07, 15.3, 'SPEAKER_02'], [24.45, 25.04, 'SPEAKER_02'], [26.44, 26.93, 'SPEAKER_02'], [28.5, 29.26, 'SPEAKER_02'], [31.99, 32.19, 'SPEAKER_02'], [34.15, 35.62, 'SPEAKER_02'], [39.16, 40.35, 'SPEAKER_03'], [39.43, 39.5, 'SPEAKER_02'], [39.54, 39.74, 'SPEAKER_02'], [42.08, 42.89, 'SPEAKER_03'], [42.99, 43.03, 'SPEAKER_03'], [43.06, 43.91, 'SPEAKER_03'], [43.97, 44.06, 'SPEAKER_03'], [44.11, 44.63, 'SPEAKER_03'], [45.37, 47.45, 'SPEAKER_03'], [47.5, 47.92, 'SPEAKER_03'], [50.89, 51.13, 'SPEAKER_03'], [51.72, 53.74, 'SPEAKER_02'], [53.05, 53.69, 'SPEAKER_03'], [61.1, 62.4, 'SPEAKER_03'], [69.96, 70.35, 'SPEAKER_02'], [71.23, 73.27, 'SPEAKER_02'], [73.27, 73.35, 'SPEAKER_01'], [73.93, 74.89, 'SPEAKER_02'], [76.22, 77.03, 'SPEAKER_02'], [77.03, 77.47, 'SPEAKER_01'], [77.88, 79.02, 'SPEAKER_01'], [79.43, 85.0, 'SPEAKER_01'], [87.78, 88.24, 'SPEAKER_02'], [88.49, 89.4, 'SPEAKER_02'], [90.33, 91.43, 'SPEAKER_02'], [92.07, 95.22, 'SPEAKER_02'], [97.92, 100.3, 'SPEAKER_02'], [121.36, 123.0, 'SPEAKER_03'], [128.47, 129.19, 'SPEAKER_02'], [130.56, 131.5, 'SPEAKER_02'], [133.75, 134.22, 'SPEAKER_02'], [135.44, 136.55, 'SPEAKER_02'], [137.34, 138.3, 'SPEAKER_02'], [141.29, 143.67, 'SPEAKER_02'], [144.13, 144.78, 'SPEAKER_02'], [146.03, 146.71, 'SPEAKER_02'], [147.99, 148.83, 'SPEAKER_01'], [162.54, 163.09, 'SPEAKER_01'], [163.47, 165.46, 'SPEAKER_01'], [166.3, 167.58, 'SPEAKER_01'], [167.84, 167.92, 'SPEAKER_01'], [169.14, 169.42, 'SPEAKER_00'], [169.42, 169.49, 'SPEAKER_01'], [169.49, 170.84, 'SPEAKER_00'], [170.84, 170.86, 'SPEAKER_02'], [170.86, 170.87, 'SPEAKER_00'], [171.5, 172.04, 'SPEAKER_01'], [172.04, 173.1, 'SPEAKER_02'], [174.64, 175.62, 'SPEAKER_02'], [177.47, 177.62, 'SPEAKER_02'], [178.77, 179.11, 'SPEAKER_02'], [179.56, 179.88, 'SPEAKER_02'], [179.95, 180.04, 'SPEAKER_02'], [180.53, 181.25, 'SPEAKER_02'], [185.08, 185.49, 'SPEAKER_02'], [186.45, 188.41, 'SPEAKER_02'], [194.4, 194.9, 'SPEAKER_02'], [199.86, 201.15, 'SPEAKER_02'], [206.13, 206.85, 'SPEAKER_03'], [211.42, 212.25, 'SPEAKER_03'], [227.98, 228.48, 'SPEAKER_03'], [230.97, 231.03, 'SPEAKER_03'], [232.47, 241.77, 'SPEAKER_00'], [242.36, 242.71, 'SPEAKER_00'], [244.09, 244.9, 'SPEAKER_00'], [244.9, 244.94, 'SPEAKER_01'], [244.94, 244.97, 'SPEAKER_00'], [244.97, 247.03, 'SPEAKER_01'], [247.03, 247.79, 'SPEAKER_02'], [254.96, 255.43, 'SPEAKER_02'], [256.97, 257.49, 'SPEAKER_02'], [262.35, 263.01, 'SPEAKER_03'], [265.24, 266.15, 'SPEAKER_02'], [266.5, 268.5, 'SPEAKER_02'], [268.68, 269.02, 'SPEAKER_02'], [269.22, 269.85, 'SPEAKER_02'], [270.4, 272.92, 'SPEAKER_02'], [273.81, 274.06, 'SPEAKER_02'], [275.73, 275.75, 'SPEAKER_03'], [275.75, 275.97, 'SPEAKER_02'], [275.97, 276.04, 'SPEAKER_03'], [276.04, 276.21, 'SPEAKER_02'], [279.13, 280.17, 'SPEAKER_02'], [280.34, 281.66, 'SPEAKER_02'], [282.33, 282.74, 'SPEAKER_02'], [283.02, 283.43, 'SPEAKER_02'], [283.53, 284.07, 'SPEAKER_02'], [284.71, 285.08, 'SPEAKER_02'], [285.71, 286.06, 'SPEAKER_02'], [286.3, 286.74, 'SPEAKER_02'], [287.31, 288.19, 'SPEAKER_02'], [288.34, 289.17, 'SPEAKER_02'], [289.96, 290.31, 'SPEAKER_02'], [290.87, 291.33, 'SPEAKER_02'], [292.14, 292.15, 'SPEAKER_02'], [292.15, 292.17, 'SPEAKER_03'], [292.17, 292.42, 'SPEAKER_02'], [293.23, 293.27, 'SPEAKER_03'], [293.27, 293.45, 'SPEAKER_02'], [294.09, 294.97, 'SPEAKER_02'], [296.98, 297.55, 'SPEAKER_02'], [297.96, 298.47, 'SPEAKER_02'], [298.97, 299.92, 'SPEAKER_02'], [299.95, 299.97, 'SPEAKER_02']]\n",
      "logs_chunk_5.pkl\n",
      "[[1.09, 4.47, 'SPEAKER_01'], [5.36, 6.19, 'SPEAKER_01'], [6.61, 7.41, 'SPEAKER_01'], [8.0, 9.28, 'SPEAKER_01'], [10.02, 10.63, 'SPEAKER_01'], [12.84, 13.09, 'SPEAKER_01'], [14.29, 15.25, 'SPEAKER_01'], [15.74, 16.25, 'SPEAKER_03'], [17.04, 18.41, 'SPEAKER_03'], [19.96, 20.69, 'SPEAKER_01'], [21.09, 22.17, 'SPEAKER_03'], [24.57, 25.48, 'SPEAKER_01'], [25.95, 27.12, 'SPEAKER_01'], [27.5, 28.13, 'SPEAKER_01'], [28.62, 30.15, 'SPEAKER_01'], [31.3, 32.45, 'SPEAKER_01'], [32.6, 34.37, 'SPEAKER_01'], [35.0, 36.26, 'SPEAKER_01'], [36.97, 37.29, 'SPEAKER_01'], [38.02, 42.17, 'SPEAKER_01'], [42.81, 43.53, 'SPEAKER_01'], [43.82, 46.35, 'SPEAKER_01'], [47.01, 50.62, 'SPEAKER_03'], [53.0, 54.45, 'SPEAKER_01'], [54.96, 56.07, 'SPEAKER_01'], [56.7, 57.47, 'SPEAKER_01'], [65.69, 65.71, 'SPEAKER_05'], [65.71, 67.45, 'SPEAKER_01'], [68.12, 69.78, 'SPEAKER_01'], [69.93, 72.15, 'SPEAKER_03'], [72.56, 73.72, 'SPEAKER_01'], [74.08, 76.37, 'SPEAKER_01'], [76.37, 76.39, 'SPEAKER_05'], [84.49, 84.51, 'SPEAKER_05'], [84.51, 85.87, 'SPEAKER_01'], [86.3, 87.17, 'SPEAKER_01'], [87.71, 90.3, 'SPEAKER_01'], [91.51, 91.88, 'SPEAKER_01'], [94.23, 96.98, 'SPEAKER_01'], [97.48, 98.55, 'SPEAKER_01'], [99.02, 101.45, 'SPEAKER_01'], [101.65, 103.15, 'SPEAKER_01'], [103.74, 104.15, 'SPEAKER_01'], [105.03, 107.91, 'SPEAKER_01'], [108.54, 110.76, 'SPEAKER_03'], [111.3, 111.71, 'SPEAKER_03'], [112.01, 114.09, 'SPEAKER_01'], [115.42, 116.94, 'SPEAKER_01'], [118.7, 120.23, 'SPEAKER_01'], [120.67, 121.35, 'SPEAKER_01'], [122.12, 125.02, 'SPEAKER_01'], [126.02, 126.78, 'SPEAKER_01'], [127.25, 128.53, 'SPEAKER_01'], [128.53, 128.55, 'SPEAKER_05'], [129.38, 129.7, 'SPEAKER_05'], [142.14, 142.15, 'SPEAKER_05'], [142.15, 142.68, 'SPEAKER_00'], [142.68, 142.71, 'SPEAKER_05'], [143.86, 143.87, 'SPEAKER_05'], [143.87, 146.66, 'SPEAKER_00'], [147.6, 150.37, 'SPEAKER_00'], [150.66, 155.01, 'SPEAKER_00'], [153.83, 154.18, 'SPEAKER_03'], [154.72, 156.16, 'SPEAKER_03'], [162.32, 163.3, 'SPEAKER_05'], [163.3, 163.31, 'SPEAKER_01'], [167.77, 171.89, 'SPEAKER_01'], [173.12, 175.85, 'SPEAKER_03'], [177.64, 177.67, 'SPEAKER_01'], [177.67, 178.16, 'SPEAKER_05'], [178.16, 178.18, 'SPEAKER_01'], [179.87, 180.96, 'SPEAKER_05'], [183.87, 184.09, 'SPEAKER_02'], [188.02, 188.31, 'SPEAKER_02'], [194.73, 197.33, 'SPEAKER_04'], [200.66, 203.54, 'SPEAKER_04'], [206.48, 209.08, 'SPEAKER_04'], [211.17, 211.96, 'SPEAKER_04'], [212.34, 213.31, 'SPEAKER_04'], [213.77, 215.42, 'SPEAKER_04'], [217.9, 217.92, 'SPEAKER_04'], [217.92, 236.01, 'SPEAKER_03'], [239.2, 239.25, 'SPEAKER_04'], [239.25, 239.96, 'SPEAKER_03'], [241.41, 241.43, 'SPEAKER_04'], [241.43, 251.86, 'SPEAKER_03'], [253.07, 255.65, 'SPEAKER_03'], [255.97, 263.96, 'SPEAKER_03'], [264.55, 267.33, 'SPEAKER_03'], [267.97, 268.26, 'SPEAKER_02'], [268.34, 273.29, 'SPEAKER_03'], [273.59, 279.08, 'SPEAKER_03'], [279.18, 282.11, 'SPEAKER_03'], [283.55, 283.72, 'SPEAKER_02'], [284.1, 284.29, 'SPEAKER_02'], [285.88, 287.4, 'SPEAKER_02'], [289.15, 289.27, 'SPEAKER_02']]\n",
      "logs_chunk_3.pkl\n",
      "[[1.8, 6.11, 'SPEAKER_03'], [7.52, 10.11, 'SPEAKER_03'], [15.37, 20.13, 'SPEAKER_03'], [20.33, 20.79, 'SPEAKER_03'], [23.98, 24.63, 'SPEAKER_00'], [27.05, 28.36, 'SPEAKER_00'], [31.77, 33.9, 'SPEAKER_00'], [34.54, 34.89, 'SPEAKER_00'], [35.79, 39.03, 'SPEAKER_00'], [49.19, 58.01, 'SPEAKER_00'], [60.38, 60.51, 'SPEAKER_00'], [61.47, 61.51, 'SPEAKER_00'], [61.56, 63.26, 'SPEAKER_00'], [65.67, 65.76, 'SPEAKER_00'], [68.71, 69.51, 'SPEAKER_00'], [71.18, 71.58, 'SPEAKER_00'], [76.69, 76.78, 'SPEAKER_03'], [77.59, 78.08, 'SPEAKER_03'], [79.17, 80.47, 'SPEAKER_00'], [82.28, 83.04, 'SPEAKER_00'], [83.87, 87.14, 'SPEAKER_00'], [88.56, 89.74, 'SPEAKER_03'], [90.77, 90.89, 'SPEAKER_03'], [91.11, 91.29, 'SPEAKER_03'], [91.83, 92.44, 'SPEAKER_03'], [92.89, 93.96, 'SPEAKER_03'], [96.51, 97.53, 'SPEAKER_03'], [97.97, 98.97, 'SPEAKER_03'], [98.99, 106.53, 'SPEAKER_03'], [107.36, 108.64, 'SPEAKER_03'], [107.52, 107.85, 'SPEAKER_00'], [109.79, 110.24, 'SPEAKER_03'], [110.73, 111.95, 'SPEAKER_03'], [113.89, 116.55, 'SPEAKER_03'], [114.49, 114.66, 'SPEAKER_00'], [120.45, 121.92, 'SPEAKER_03'], [121.94, 122.36, 'SPEAKER_03'], [122.68, 125.61, 'SPEAKER_03'], [127.81, 128.65, 'SPEAKER_03'], [130.76, 132.09, 'SPEAKER_03'], [132.09, 132.16, 'SPEAKER_00'], [132.26, 132.5, 'SPEAKER_00'], [133.55, 134.29, 'SPEAKER_00'], [143.37, 144.48, 'SPEAKER_03'], [144.89, 145.27, 'SPEAKER_00'], [146.73, 146.93, 'SPEAKER_03'], [146.93, 147.11, 'SPEAKER_00'], [147.67, 148.19, 'SPEAKER_00'], [148.58, 149.04, 'SPEAKER_00'], [167.35, 167.89, 'SPEAKER_00'], [169.44, 171.35, 'SPEAKER_00'], [179.6, 180.09, 'SPEAKER_00'], [205.06, 205.5, 'SPEAKER_00'], [206.07, 206.55, 'SPEAKER_00'], [206.55, 206.56, 'SPEAKER_01'], [208.05, 209.53, 'SPEAKER_02'], [210.26, 211.26, 'SPEAKER_01'], [212.55, 214.31, 'SPEAKER_01'], [215.22, 216.99, 'SPEAKER_01'], [218.41, 218.83, 'SPEAKER_01'], [219.19, 219.66, 'SPEAKER_01'], [220.0, 221.65, 'SPEAKER_01'], [222.06, 222.7, 'SPEAKER_01'], [222.7, 223.14, 'SPEAKER_02'], [223.84, 224.82, 'SPEAKER_02'], [226.51, 227.29, 'SPEAKER_02'], [228.0, 229.7, 'SPEAKER_02'], [229.78, 230.71, 'SPEAKER_02'], [231.98, 234.07, 'SPEAKER_01'], [234.32, 235.79, 'SPEAKER_01'], [236.43, 236.65, 'SPEAKER_01'], [237.43, 238.15, 'SPEAKER_01'], [238.58, 240.01, 'SPEAKER_01'], [240.55, 242.64, 'SPEAKER_01'], [242.79, 244.7, 'SPEAKER_01'], [245.28, 245.83, 'SPEAKER_02'], [246.2, 247.55, 'SPEAKER_02'], [248.62, 251.01, 'SPEAKER_02'], [252.21, 253.48, 'SPEAKER_02'], [254.08, 254.47, 'SPEAKER_02'], [257.91, 258.61, 'SPEAKER_02'], [259.3, 260.99, 'SPEAKER_02'], [261.63, 264.12, 'SPEAKER_02'], [265.14, 266.37, 'SPEAKER_01'], [266.37, 266.4, 'SPEAKER_02'], [267.69, 271.01, 'SPEAKER_01'], [271.7, 274.28, 'SPEAKER_01'], [274.57, 275.46, 'SPEAKER_02'], [276.0, 278.28, 'SPEAKER_02'], [278.82, 280.11, 'SPEAKER_02'], [281.27, 282.11, 'SPEAKER_02'], [282.7, 283.28, 'SPEAKER_02'], [284.04, 285.17, 'SPEAKER_02'], [286.32, 287.87, 'SPEAKER_02'], [288.34, 288.86, 'SPEAKER_01'], [291.61, 292.41, 'SPEAKER_02'], [292.96, 294.16, 'SPEAKER_02'], [294.26, 295.56, 'SPEAKER_02'], [295.66, 295.73, 'SPEAKER_02'], [295.73, 295.9, 'SPEAKER_01'], [295.9, 295.97, 'SPEAKER_02'], [295.97, 296.17, 'SPEAKER_03'], [296.17, 297.15, 'SPEAKER_02'], [297.45, 298.79, 'SPEAKER_02'], [298.97, 299.26, 'SPEAKER_02'], [299.46, 299.97, 'SPEAKER_02']]\n",
      "logs_chunk_2.pkl\n",
      "[[0.74, 1.57, 'SPEAKER_00'], [2.02, 3.71, 'SPEAKER_00'], [4.37, 5.62, 'SPEAKER_00'], [6.04, 6.33, 'SPEAKER_00'], [6.51, 8.59, 'SPEAKER_00'], [8.91, 9.89, 'SPEAKER_00'], [10.48, 11.03, 'SPEAKER_00'], [11.59, 12.52, 'SPEAKER_00'], [12.52, 12.97, 'SPEAKER_01'], [13.6, 14.29, 'SPEAKER_01'], [15.03, 18.07, 'SPEAKER_01'], [18.69, 20.38, 'SPEAKER_01'], [21.04, 24.92, 'SPEAKER_01'], [24.92, 32.18, 'SPEAKER_00'], [32.67, 37.29, 'SPEAKER_00'], [38.34, 39.96, 'SPEAKER_01'], [39.96, 40.43, 'SPEAKER_00'], [44.29, 44.88, 'SPEAKER_02'], [45.9, 47.15, 'SPEAKER_02'], [52.48, 53.0, 'SPEAKER_02'], [53.88, 54.79, 'SPEAKER_02'], [55.7, 58.44, 'SPEAKER_02'], [59.68, 61.27, 'SPEAKER_02'], [62.2, 64.22, 'SPEAKER_02'], [65.24, 66.3, 'SPEAKER_02'], [67.99, 68.44, 'SPEAKER_02'], [72.34, 73.29, 'SPEAKER_02'], [76.95, 82.53, 'SPEAKER_02'], [104.93, 105.89, 'SPEAKER_06'], [108.13, 108.4, 'SPEAKER_06'], [113.55, 114.66, 'SPEAKER_06'], [118.76, 119.0, 'SPEAKER_06'], [126.53, 126.95, 'SPEAKER_06'], [128.11, 128.53, 'SPEAKER_06'], [130.19, 130.44, 'SPEAKER_06'], [132.18, 132.5, 'SPEAKER_06'], [138.36, 139.01, 'SPEAKER_06'], [142.12, 143.15, 'SPEAKER_06'], [143.2, 143.42, 'SPEAKER_06'], [148.65, 148.77, 'SPEAKER_06'], [155.72, 155.74, 'SPEAKER_02'], [155.74, 156.87, 'SPEAKER_05'], [156.87, 156.88, 'SPEAKER_02'], [156.88, 158.86, 'SPEAKER_04'], [159.99, 161.74, 'SPEAKER_05'], [162.52, 164.85, 'SPEAKER_05'], [166.64, 168.04, 'SPEAKER_05'], [168.65, 170.08, 'SPEAKER_05'], [171.01, 172.51, 'SPEAKER_05'], [172.68, 173.81, 'SPEAKER_05'], [178.57, 182.26, 'SPEAKER_05'], [182.92, 184.1, 'SPEAKER_05'], [183.56, 184.32, 'SPEAKER_03'], [185.39, 185.81, 'SPEAKER_03'], [186.15, 188.68, 'SPEAKER_03'], [188.95, 190.97, 'SPEAKER_03'], [190.97, 191.22, 'SPEAKER_05'], [191.22, 191.24, 'SPEAKER_03'], [191.34, 191.43, 'SPEAKER_05'], [191.43, 191.46, 'SPEAKER_03'], [191.46, 194.09, 'SPEAKER_05'], [195.14, 200.81, 'SPEAKER_05'], [201.52, 201.74, 'SPEAKER_05'], [202.6, 204.02, 'SPEAKER_05'], [204.89, 206.46, 'SPEAKER_05'], [207.69, 208.44, 'SPEAKER_02'], [208.44, 208.47, 'SPEAKER_03'], [209.28, 210.78, 'SPEAKER_03'], [211.66, 212.28, 'SPEAKER_03'], [213.09, 215.79, 'SPEAKER_03'], [215.88, 219.51, 'SPEAKER_03'], [220.4, 220.55, 'SPEAKER_03'], [221.43, 229.89, 'SPEAKER_04'], [230.75, 231.61, 'SPEAKER_04'], [231.94, 239.72, 'SPEAKER_04'], [241.51, 242.59, 'SPEAKER_05'], [242.98, 244.7, 'SPEAKER_05'], [244.97, 247.38, 'SPEAKER_05'], [247.98, 249.09, 'SPEAKER_05'], [249.39, 251.1, 'SPEAKER_05'], [251.1, 252.41, 'SPEAKER_02'], [252.68, 253.09, 'SPEAKER_02'], [256.5, 256.85, 'SPEAKER_06'], [265.98, 266.42, 'SPEAKER_06'], [267.28, 267.48, 'SPEAKER_06'], [294.89, 295.34, 'SPEAKER_06']]\n",
      "logs_chunk_0.pkl\n",
      "[[1.04, 1.87, 'SPEAKER_00'], [7.05, 7.96, 'SPEAKER_00'], [8.32, 8.37, 'SPEAKER_00'], [19.98, 21.87, 'SPEAKER_00'], [28.33, 28.82, 'SPEAKER_00'], [29.29, 29.73, 'SPEAKER_00'], [30.66, 36.73, 'SPEAKER_04'], [36.73, 42.59, 'SPEAKER_01'], [42.99, 43.55, 'SPEAKER_01'], [44.01, 46.37, 'SPEAKER_01'], [47.21, 47.5, 'SPEAKER_01'], [47.89, 48.26, 'SPEAKER_01'], [48.26, 48.51, 'SPEAKER_00'], [48.51, 49.04, 'SPEAKER_01'], [49.04, 49.76, 'SPEAKER_00'], [50.18, 50.52, 'SPEAKER_00'], [52.75, 53.52, 'SPEAKER_00'], [54.6, 55.72, 'SPEAKER_00'], [55.74, 56.04, 'SPEAKER_00'], [64.27, 64.63, 'SPEAKER_00'], [71.85, 72.61, 'SPEAKER_02'], [74.03, 74.99, 'SPEAKER_02'], [75.5, 76.98, 'SPEAKER_02'], [77.52, 80.47, 'SPEAKER_02'], [80.88, 84.05, 'SPEAKER_02'], [84.73, 86.04, 'SPEAKER_01'], [86.62, 87.83, 'SPEAKER_02'], [88.41, 89.87, 'SPEAKER_02'], [95.31, 96.42, 'SPEAKER_04'], [96.86, 98.04, 'SPEAKER_04'], [98.51, 98.9, 'SPEAKER_02'], [99.68, 101.38, 'SPEAKER_02'], [102.41, 103.09, 'SPEAKER_04'], [103.47, 104.0, 'SPEAKER_02'], [104.61, 105.4, 'SPEAKER_02'], [107.15, 108.13, 'SPEAKER_02'], [108.54, 109.87, 'SPEAKER_02'], [110.33, 110.98, 'SPEAKER_02'], [111.47, 115.96, 'SPEAKER_02'], [116.16, 117.16, 'SPEAKER_02'], [120.99, 122.12, 'SPEAKER_02'], [124.2, 130.51, 'SPEAKER_02'], [130.68, 132.09, 'SPEAKER_02'], [132.09, 132.33, 'SPEAKER_04'], [137.34, 137.63, 'SPEAKER_00'], [139.13, 139.18, 'SPEAKER_00'], [139.22, 139.23, 'SPEAKER_00'], [139.27, 139.72, 'SPEAKER_00'], [140.25, 140.52, 'SPEAKER_00'], [148.87, 150.02, 'SPEAKER_04'], [150.62, 151.23, 'SPEAKER_04'], [152.26, 152.88, 'SPEAKER_03'], [155.97, 156.7, 'SPEAKER_04'], [159.28, 163.14, 'SPEAKER_02'], [170.06, 171.13, 'SPEAKER_00'], [171.84, 173.22, 'SPEAKER_00'], [172.31, 172.34, 'SPEAKER_01'], [175.56, 176.44, 'SPEAKER_00'], [176.44, 176.49, 'SPEAKER_01'], [176.49, 179.61, 'SPEAKER_04'], [176.53, 176.56, 'SPEAKER_01'], [181.05, 181.57, 'SPEAKER_01'], [182.13, 182.16, 'SPEAKER_01'], [182.16, 182.18, 'SPEAKER_00'], [182.18, 182.35, 'SPEAKER_04'], [182.35, 182.37, 'SPEAKER_01'], [183.93, 184.54, 'SPEAKER_04'], [185.18, 185.89, 'SPEAKER_04'], [186.36, 188.83, 'SPEAKER_04'], [190.09, 190.48, 'SPEAKER_03'], [190.6, 191.85, 'SPEAKER_04'], [194.7, 195.11, 'SPEAKER_03'], [196.93, 197.37, 'SPEAKER_03'], [201.37, 201.92, 'SPEAKER_03'], [203.21, 204.88, 'SPEAKER_03'], [209.38, 212.72, 'SPEAKER_03'], [213.72, 214.31, 'SPEAKER_03'], [225.48, 227.54, 'SPEAKER_03'], [228.13, 228.54, 'SPEAKER_03'], [232.42, 233.82, 'SPEAKER_02'], [234.73, 234.8, 'SPEAKER_03'], [236.2, 240.23, 'SPEAKER_02'], [241.87, 242.9, 'SPEAKER_04'], [244.35, 244.38, 'SPEAKER_04'], [244.38, 244.97, 'SPEAKER_01'], [246.07, 248.06, 'SPEAKER_01'], [248.48, 248.95, 'SPEAKER_01'], [249.43, 250.64, 'SPEAKER_02'], [251.35, 253.7, 'SPEAKER_02'], [253.92, 255.5, 'SPEAKER_04'], [255.89, 256.21, 'SPEAKER_04'], [257.91, 257.93, 'SPEAKER_02'], [257.93, 258.27, 'SPEAKER_03'], [270.12, 271.84, 'SPEAKER_02'], [272.34, 272.87, 'SPEAKER_02'], [272.48, 273.56, 'SPEAKER_04'], [274.17, 274.71, 'SPEAKER_04'], [275.87, 277.61, 'SPEAKER_04'], [290.04, 290.25, 'SPEAKER_00'], [292.17, 294.01, 'SPEAKER_00'], [298.01, 298.85, 'SPEAKER_00']]\n",
      "logs_chunk_6.pkl\n",
      "[]\n",
      "logs_chunk_1.pkl\n",
      "[[1.41, 1.85, 'SPEAKER_02'], [2.93, 3.73, 'SPEAKER_02'], [4.45, 6.43, 'SPEAKER_02'], [7.14, 9.4, 'SPEAKER_02'], [10.39, 11.66, 'SPEAKER_01'], [12.11, 12.84, 'SPEAKER_01'], [13.04, 14.05, 'SPEAKER_01'], [14.53, 15.61, 'SPEAKER_04'], [16.03, 16.08, 'SPEAKER_04'], [16.08, 16.11, 'SPEAKER_01'], [16.11, 16.53, 'SPEAKER_04'], [29.11, 29.83, 'SPEAKER_04'], [31.2, 31.6, 'SPEAKER_04'], [33.06, 33.54, 'SPEAKER_04'], [33.63, 34.03, 'SPEAKER_04'], [34.03, 34.3, 'SPEAKER_01'], [34.3, 34.34, 'SPEAKER_04'], [34.47, 34.52, 'SPEAKER_04'], [34.52, 35.18, 'SPEAKER_01'], [36.13, 36.48, 'SPEAKER_04'], [36.7, 37.16, 'SPEAKER_01'], [38.08, 38.86, 'SPEAKER_01'], [39.74, 40.28, 'SPEAKER_01'], [40.28, 40.58, 'SPEAKER_03'], [40.94, 42.13, 'SPEAKER_03'], [42.18, 43.01, 'SPEAKER_01'], [43.94, 45.56, 'SPEAKER_03'], [45.36, 46.99, 'SPEAKER_01'], [46.18, 46.37, 'SPEAKER_03'], [47.74, 49.26, 'SPEAKER_03'], [49.09, 51.8, 'SPEAKER_01'], [53.09, 54.55, 'SPEAKER_01'], [54.87, 55.14, 'SPEAKER_01'], [55.72, 55.74, 'SPEAKER_04'], [55.74, 55.77, 'SPEAKER_01'], [55.77, 55.92, 'SPEAKER_04'], [55.92, 56.36, 'SPEAKER_01'], [56.66, 57.17, 'SPEAKER_01'], [57.78, 57.79, 'SPEAKER_01'], [57.79, 57.98, 'SPEAKER_04'], [58.1, 58.89, 'SPEAKER_04'], [59.33, 60.0, 'SPEAKER_04'], [60.66, 62.74, 'SPEAKER_04'], [63.85, 64.76, 'SPEAKER_01'], [64.83, 65.56, 'SPEAKER_01'], [65.89, 66.38, 'SPEAKER_01'], [67.5, 67.83, 'SPEAKER_01'], [68.73, 69.56, 'SPEAKER_01'], [70.32, 70.7, 'SPEAKER_01'], [70.7, 70.72, 'SPEAKER_04'], [71.23, 71.75, 'SPEAKER_03'], [72.37, 73.18, 'SPEAKER_03'], [73.59, 75.82, 'SPEAKER_03'], [78.09, 78.43, 'SPEAKER_04'], [86.7, 88.3, 'SPEAKER_04'], [87.27, 87.65, 'SPEAKER_00'], [87.65, 87.7, 'SPEAKER_01'], [89.55, 90.41, 'SPEAKER_04'], [92.03, 92.88, 'SPEAKER_01'], [92.88, 92.89, 'SPEAKER_04'], [93.45, 94.87, 'SPEAKER_01'], [94.87, 94.89, 'SPEAKER_04'], [95.51, 95.78, 'SPEAKER_04'], [96.39, 97.4, 'SPEAKER_04'], [99.02, 99.81, 'SPEAKER_04'], [102.41, 104.08, 'SPEAKER_04'], [105.36, 106.28, 'SPEAKER_04'], [106.9, 107.09, 'SPEAKER_04'], [107.19, 108.1, 'SPEAKER_04'], [108.96, 109.68, 'SPEAKER_04'], [117.8, 118.16, 'SPEAKER_04'], [120.47, 120.94, 'SPEAKER_04'], [121.43, 121.94, 'SPEAKER_04'], [122.63, 123.17, 'SPEAKER_04'], [124.69, 125.36, 'SPEAKER_04'], [125.78, 126.27, 'SPEAKER_04'], [133.88, 134.64, 'SPEAKER_04'], [137.02, 137.39, 'SPEAKER_04'], [137.63, 139.45, 'SPEAKER_04'], [142.47, 142.98, 'SPEAKER_04'], [142.98, 143.01, 'SPEAKER_03'], [147.54, 155.89, 'SPEAKER_03'], [157.0, 157.91, 'SPEAKER_03'], [158.22, 159.03, 'SPEAKER_03'], [159.53, 160.28, 'SPEAKER_03'], [162.32, 162.44, 'SPEAKER_03'], [164.19, 166.72, 'SPEAKER_04'], [168.16, 168.73, 'SPEAKER_04'], [169.57, 170.69, 'SPEAKER_04'], [171.75, 172.14, 'SPEAKER_04'], [176.58, 177.0, 'SPEAKER_04'], [177.44, 179.41, 'SPEAKER_04'], [180.83, 182.21, 'SPEAKER_02'], [182.57, 184.41, 'SPEAKER_04'], [186.26, 188.0, 'SPEAKER_02'], [188.54, 189.54, 'SPEAKER_02'], [190.3, 191.09, 'SPEAKER_04'], [192.05, 192.51, 'SPEAKER_04'], [193.0, 193.03, 'SPEAKER_04'], [193.11, 193.81, 'SPEAKER_04'], [194.97, 196.95, 'SPEAKER_04'], [219.93, 220.17, 'SPEAKER_03'], [245.92, 248.72, 'SPEAKER_03'], [259.03, 259.89, 'SPEAKER_04'], [265.56, 266.03, 'SPEAKER_04'], [266.03, 267.01, 'SPEAKER_02'], [267.85, 268.65, 'SPEAKER_00'], [269.31, 271.47, 'SPEAKER_00'], [271.62, 272.19, 'SPEAKER_02'], [272.88, 279.72, 'SPEAKER_02'], [280.11, 283.04, 'SPEAKER_02'], [283.73, 284.04, 'SPEAKER_02'], [284.04, 284.32, 'SPEAKER_00'], [284.32, 284.36, 'SPEAKER_02'], [286.79, 287.51, 'SPEAKER_00'], [288.12, 289.39, 'SPEAKER_00'], [290.3, 294.53, 'SPEAKER_00'], [295.43, 299.97, 'SPEAKER_00']]\n"
     ]
    }
   ],
   "source": [
    "remove_collision(folder_name)\n",
    "\n",
    "#TODO: fix split_diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def split_diarization(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        logs_no_collision\n",
    "        audio_path\n",
    "    Output:\n",
    "        split_diary\n",
    "            Nguoi phan xu\n",
    "                chunk_1\n",
    "                    output 0.0 to 1.0.wav\n",
    "                    output 1.0 to 2.0.wav\n",
    "                chunk_2...\n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/split_diary/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/logs_no_col/{folder_name}'):\n",
    "        print(file_name)\n",
    "        with open(f'{data_path}/logs_no_col/{folder_name}/{file_name}', 'r') as f:\n",
    "            logs = json.load(f)\n",
    "        audio_path = f'{data_path}/denoised/{folder_name}/{file_name[5:-5]}.mp3'\n",
    "        print(audio_path)\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        for log in logs:\n",
    "            start, end, speaker = log[0][0], log[0][1], log[1]\n",
    "            print(start, end, speaker)\n",
    "            segment = y[int(start*sr):int(end*sr)]\n",
    "\n",
    "            if not os.path.exists(f'{save_path}/{file_name[5:-5]}'):\n",
    "                os.makedirs(f'{save_path}/{file_name[5:-5]}')\n",
    "\n",
    "            sf.write(f'{save_path}/{file_name[5:-5]}/{round(start,1)} {round(end,1)} {speaker}.wav', segment, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_chunk_3.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_3.mp3\n",
      "1.8 6.11 SPEAKER_03\n",
      "7.52 10.11 SPEAKER_03\n",
      "15.37 20.13 SPEAKER_03\n",
      "27.05 28.36 SPEAKER_00\n",
      "31.77 33.9 SPEAKER_00\n",
      "35.79 39.03 SPEAKER_00\n",
      "49.19 58.01 SPEAKER_00\n",
      "61.56 63.26 SPEAKER_00\n",
      "79.17 80.47 SPEAKER_00\n",
      "83.87 87.14 SPEAKER_00\n",
      "88.56 89.74 SPEAKER_03\n",
      "92.89 93.96 SPEAKER_03\n",
      "96.51 97.53 SPEAKER_03\n",
      "98.99 106.53 SPEAKER_03\n",
      "110.73 111.95 SPEAKER_03\n",
      "120.45 121.92 SPEAKER_03\n",
      "122.68 125.61 SPEAKER_03\n",
      "130.76 132.09 SPEAKER_03\n",
      "143.37 144.48 SPEAKER_03\n",
      "169.44 171.35 SPEAKER_00\n",
      "208.05 209.53 SPEAKER_02\n",
      "212.55 214.31 SPEAKER_01\n",
      "215.22 216.99 SPEAKER_01\n",
      "220.0 221.65 SPEAKER_01\n",
      "228.0 229.7 SPEAKER_02\n",
      "231.98 234.07 SPEAKER_01\n",
      "234.32 235.79 SPEAKER_01\n",
      "238.58 240.01 SPEAKER_01\n",
      "240.55 242.64 SPEAKER_01\n",
      "242.79 244.7 SPEAKER_01\n",
      "246.2 247.55 SPEAKER_02\n",
      "248.62 251.01 SPEAKER_02\n",
      "252.21 253.48 SPEAKER_02\n",
      "259.3 260.99 SPEAKER_02\n",
      "261.63 264.12 SPEAKER_02\n",
      "265.14 266.37 SPEAKER_01\n",
      "267.69 271.01 SPEAKER_01\n",
      "271.7 274.28 SPEAKER_01\n",
      "276.0 278.28 SPEAKER_02\n",
      "278.82 280.11 SPEAKER_02\n",
      "284.04 285.17 SPEAKER_02\n",
      "286.32 287.87 SPEAKER_02\n",
      "292.96 294.16 SPEAKER_02\n",
      "294.26 295.56 SPEAKER_02\n",
      "297.45 298.79 SPEAKER_02\n",
      "299.46 299.97 SPEAKER_02\n",
      "logs_chunk_5.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_5.mp3\n",
      "1.09 4.47 SPEAKER_01\n",
      "8.0 9.28 SPEAKER_01\n",
      "17.04 18.41 SPEAKER_03\n",
      "21.09 22.17 SPEAKER_03\n",
      "25.95 27.12 SPEAKER_01\n",
      "28.62 30.15 SPEAKER_01\n",
      "31.3 32.45 SPEAKER_01\n",
      "32.6 34.37 SPEAKER_01\n",
      "35.0 36.26 SPEAKER_01\n",
      "38.02 42.17 SPEAKER_01\n",
      "43.82 46.35 SPEAKER_01\n",
      "47.01 50.62 SPEAKER_03\n",
      "53.0 54.45 SPEAKER_01\n",
      "54.96 56.07 SPEAKER_01\n",
      "65.71 67.45 SPEAKER_01\n",
      "68.12 69.78 SPEAKER_01\n",
      "69.93 72.15 SPEAKER_03\n",
      "72.56 73.72 SPEAKER_01\n",
      "74.08 76.37 SPEAKER_01\n",
      "84.51 85.87 SPEAKER_01\n",
      "87.71 90.3 SPEAKER_01\n",
      "94.23 96.98 SPEAKER_01\n",
      "97.48 98.55 SPEAKER_01\n",
      "99.02 101.45 SPEAKER_01\n",
      "101.65 103.15 SPEAKER_01\n",
      "105.03 107.91 SPEAKER_01\n",
      "108.54 110.76 SPEAKER_03\n",
      "112.01 114.09 SPEAKER_01\n",
      "115.42 116.94 SPEAKER_01\n",
      "118.7 120.23 SPEAKER_01\n",
      "122.12 125.02 SPEAKER_01\n",
      "127.25 128.53 SPEAKER_01\n",
      "143.87 146.66 SPEAKER_00\n",
      "147.6 150.37 SPEAKER_00\n",
      "154.72 156.16 SPEAKER_03\n",
      "167.77 171.89 SPEAKER_01\n",
      "173.12 175.85 SPEAKER_03\n",
      "179.87 180.96 SPEAKER_05\n",
      "194.73 197.33 SPEAKER_04\n",
      "200.66 203.54 SPEAKER_04\n",
      "206.48 209.08 SPEAKER_04\n",
      "213.77 215.42 SPEAKER_04\n",
      "217.92 236.01 SPEAKER_03\n",
      "241.43 251.86 SPEAKER_03\n",
      "253.07 255.65 SPEAKER_03\n",
      "255.97 263.96 SPEAKER_03\n",
      "264.55 267.33 SPEAKER_03\n",
      "268.34 273.29 SPEAKER_03\n",
      "273.59 279.08 SPEAKER_03\n",
      "279.18 282.11 SPEAKER_03\n",
      "285.88 287.4 SPEAKER_02\n",
      "289.15 289.27 SPEAKER_02\n",
      "logs_chunk_2.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_2.mp3\n",
      "0.74 1.57 SPEAKER_00\n",
      "2.02 3.71 SPEAKER_00\n",
      "4.37 5.62 SPEAKER_00\n",
      "6.51 8.59 SPEAKER_00\n",
      "15.03 18.07 SPEAKER_01\n",
      "18.69 20.38 SPEAKER_01\n",
      "21.04 24.92 SPEAKER_01\n",
      "24.92 32.18 SPEAKER_00\n",
      "32.67 37.29 SPEAKER_00\n",
      "38.34 39.96 SPEAKER_01\n",
      "45.9 47.15 SPEAKER_02\n",
      "55.7 58.44 SPEAKER_02\n",
      "59.68 61.27 SPEAKER_02\n",
      "62.2 64.22 SPEAKER_02\n",
      "65.24 66.3 SPEAKER_02\n",
      "76.95 82.53 SPEAKER_02\n",
      "113.55 114.66 SPEAKER_06\n",
      "142.12 143.15 SPEAKER_06\n",
      "155.74 156.87 SPEAKER_05\n",
      "156.88 158.86 SPEAKER_04\n",
      "159.99 161.74 SPEAKER_05\n",
      "162.52 164.85 SPEAKER_05\n",
      "166.64 168.04 SPEAKER_05\n",
      "168.65 170.08 SPEAKER_05\n",
      "171.01 172.51 SPEAKER_05\n",
      "172.68 173.81 SPEAKER_05\n",
      "178.57 182.26 SPEAKER_05\n",
      "186.15 188.68 SPEAKER_03\n",
      "188.95 190.97 SPEAKER_03\n",
      "191.46 194.09 SPEAKER_05\n",
      "195.14 200.81 SPEAKER_05\n",
      "202.6 204.02 SPEAKER_05\n",
      "204.89 206.46 SPEAKER_05\n",
      "209.28 210.78 SPEAKER_03\n",
      "213.09 215.79 SPEAKER_03\n",
      "215.88 219.51 SPEAKER_03\n",
      "221.43 229.89 SPEAKER_04\n",
      "231.94 239.72 SPEAKER_04\n",
      "241.51 242.59 SPEAKER_05\n",
      "242.98 244.7 SPEAKER_05\n",
      "244.97 247.38 SPEAKER_05\n",
      "247.98 249.09 SPEAKER_05\n",
      "249.39 251.1 SPEAKER_05\n",
      "251.1 252.41 SPEAKER_02\n",
      "294.89 295.34 SPEAKER_06\n",
      "logs_chunk_1.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_1.mp3\n",
      "1.41 1.85 SPEAKER_02\n",
      "4.45 6.43 SPEAKER_02\n",
      "7.14 9.4 SPEAKER_02\n",
      "10.39 11.66 SPEAKER_01\n",
      "13.04 14.05 SPEAKER_01\n",
      "14.53 15.61 SPEAKER_04\n",
      "40.94 42.13 SPEAKER_03\n",
      "49.09 51.8 SPEAKER_01\n",
      "53.09 54.55 SPEAKER_01\n",
      "60.66 62.74 SPEAKER_04\n",
      "73.59 75.82 SPEAKER_03\n",
      "93.45 94.87 SPEAKER_01\n",
      "96.39 97.4 SPEAKER_04\n",
      "102.41 104.08 SPEAKER_04\n",
      "137.63 139.45 SPEAKER_04\n",
      "147.54 155.89 SPEAKER_03\n",
      "164.19 166.72 SPEAKER_04\n",
      "169.57 170.69 SPEAKER_04\n",
      "177.44 179.41 SPEAKER_04\n",
      "180.83 182.21 SPEAKER_02\n",
      "182.57 184.41 SPEAKER_04\n",
      "186.26 188.0 SPEAKER_02\n",
      "194.97 196.95 SPEAKER_04\n",
      "245.92 248.72 SPEAKER_03\n",
      "269.31 271.47 SPEAKER_00\n",
      "272.88 279.72 SPEAKER_02\n",
      "280.11 283.04 SPEAKER_02\n",
      "288.12 289.39 SPEAKER_00\n",
      "290.3 294.53 SPEAKER_00\n",
      "295.43 299.97 SPEAKER_00\n",
      "logs_chunk_0.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_0.mp3\n",
      "1.04 1.87 SPEAKER_00\n",
      "19.98 21.87 SPEAKER_00\n",
      "30.66 36.73 SPEAKER_04\n",
      "36.73 42.59 SPEAKER_01\n",
      "44.01 46.37 SPEAKER_01\n",
      "54.6 55.72 SPEAKER_00\n",
      "75.5 76.98 SPEAKER_02\n",
      "77.52 80.47 SPEAKER_02\n",
      "80.88 84.05 SPEAKER_02\n",
      "84.73 86.04 SPEAKER_01\n",
      "86.62 87.83 SPEAKER_02\n",
      "88.41 89.87 SPEAKER_02\n",
      "95.31 96.42 SPEAKER_04\n",
      "96.86 98.04 SPEAKER_04\n",
      "99.68 101.38 SPEAKER_02\n",
      "108.54 109.87 SPEAKER_02\n",
      "111.47 115.96 SPEAKER_02\n",
      "120.99 122.12 SPEAKER_02\n",
      "124.2 130.51 SPEAKER_02\n",
      "130.68 132.09 SPEAKER_02\n",
      "148.87 150.02 SPEAKER_04\n",
      "159.28 163.14 SPEAKER_02\n",
      "170.06 171.13 SPEAKER_00\n",
      "186.36 188.83 SPEAKER_04\n",
      "190.6 191.85 SPEAKER_04\n",
      "203.21 204.88 SPEAKER_03\n",
      "209.38 212.72 SPEAKER_03\n",
      "225.48 227.54 SPEAKER_03\n",
      "232.42 233.82 SPEAKER_02\n",
      "236.2 240.23 SPEAKER_02\n",
      "241.87 242.9 SPEAKER_04\n",
      "246.07 248.06 SPEAKER_01\n",
      "249.43 250.64 SPEAKER_02\n",
      "251.35 253.7 SPEAKER_02\n",
      "253.92 255.5 SPEAKER_04\n",
      "270.12 271.84 SPEAKER_02\n",
      "272.48 273.56 SPEAKER_04\n",
      "275.87 277.61 SPEAKER_04\n",
      "292.17 294.01 SPEAKER_00\n",
      "298.01 298.85 SPEAKER_00\n",
      "logs_chunk_4.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_4.mp3\n",
      "0.03 0.89 SPEAKER_02\n",
      "3.86 5.03 SPEAKER_02\n",
      "6.78 9.19 SPEAKER_02\n",
      "9.8 11.15 SPEAKER_02\n",
      "11.74 13.18 SPEAKER_02\n",
      "14.07 15.3 SPEAKER_02\n",
      "34.15 35.62 SPEAKER_02\n",
      "45.37 47.45 SPEAKER_03\n",
      "61.1 62.4 SPEAKER_03\n",
      "71.23 73.27 SPEAKER_02\n",
      "77.88 79.02 SPEAKER_01\n",
      "79.43 85.0 SPEAKER_01\n",
      "90.33 91.43 SPEAKER_02\n",
      "92.07 95.22 SPEAKER_02\n",
      "97.92 100.3 SPEAKER_02\n",
      "121.36 123.0 SPEAKER_03\n",
      "135.44 136.55 SPEAKER_02\n",
      "141.29 143.67 SPEAKER_02\n",
      "163.47 165.46 SPEAKER_01\n",
      "166.3 167.58 SPEAKER_01\n",
      "169.49 170.84 SPEAKER_00\n",
      "172.04 173.1 SPEAKER_02\n",
      "186.45 188.41 SPEAKER_02\n",
      "199.86 201.15 SPEAKER_02\n",
      "232.47 241.77 SPEAKER_00\n",
      "244.97 247.03 SPEAKER_01\n",
      "266.5 268.5 SPEAKER_02\n",
      "270.4 272.92 SPEAKER_02\n",
      "279.13 280.17 SPEAKER_02\n",
      "280.34 281.66 SPEAKER_02\n",
      "logs_chunk_6.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_6.mp3\n"
     ]
    }
   ],
   "source": [
    "split_diarization(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/speechbrain/utils/checkpoints.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from speechbrain.inference.speaker import SpeakerRecognition # type: ignore\n",
    "\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "\n",
    "anchor_path = '../../data/anchor'\n",
    "\n",
    "def compute_similarities_score(unverified_path, anchor_path):\n",
    "    scores = []\n",
    "    for audio in os.listdir(anchor_path):\n",
    "        audio_path = os.path.join(anchor_path, audio)\n",
    "        score, _ = verification.verify_files(unverified_path, audio_path)\n",
    "        scores.append(score)\n",
    "    return sum(scores)/len(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # df = pd.DataFrame(columns=['audio_path', 'diary_label', 'model_label', 'score', 'verified'])\n",
    "    # for path in os.listdir(folder_name):\n",
    "    #     d = {}\n",
    "    #     diary_label = path.split()[1]\n",
    "    #     audio_path = os.path.join(folder_name, path)\n",
    "    #     for anchor in os.listdir(anchor_path):\n",
    "    #         d[anchor] = compute_similarities_score(audio_path, os.path.join(anchor_path, anchor))\n",
    "    #     print(d, path)\n",
    "    #     \"\"\"\n",
    "    #     {'BichNgoc': tensor([-0.0291]), 'DucAnh': tensor([0.2324])} output SPEAKER_02 213.7 to 214.3.wav\"\"\"\n",
    "    #     max_key = max(d, key=lambda x: d[x].item())\n",
    "    #     df = df.append({'audio_path': audio_path, 'diary_label': diary_label, 'model_label': max_key, 'score': d[max_key].item(), 'verified': (d[max_key]>=0.25)}, ignore_index=True)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_speaker(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        split_diarization audio\n",
    "        anchor\n",
    "\n",
    "    Output:\n",
    "        verified_speaker\n",
    "            Nguoi phan xu\n",
    "                chunk_1.csv\n",
    "                ...        \n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/verified_speaker/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    \n",
    "    for sub_name in os.listdir(f'{data_path}/split_diary/{folder_name}'):    #chunk_1, chunk_2,...\n",
    "        df = pd.DataFrame(columns=['audio_path', 'diary_label', 'model_label', 'start', 'end', 'score', 'verified'])\n",
    "        sub_path = os.path.join(f'{data_path}/split_diary/{folder_name}', sub_name)\n",
    "        for file_name in os.listdir(sub_path):\n",
    "        \n",
    "            d = {}\n",
    "            audio_path = os.path.join(f'{sub_path}', file_name)\n",
    "            # print(audio_path)\n",
    "            diary_label = file_name.split(' ')[-1][:-4]\n",
    "            start, end = float(file_name.split()[0]), float(file_name.split()[1])\n",
    "            for anchor in os.listdir(anchor_path):\n",
    "                d[anchor] = compute_similarities_score(audio_path, os.path.join(anchor_path, anchor))\n",
    "            max_key = max(d, key=lambda x: d[x].item())\n",
    "            new_row = pd.DataFrame([{'audio_path': audio_path, 'diary_label': diary_label, 'model_label': max_key, 'start':start, 'end':end, 'score': d[max_key].item(), 'verified': (d[max_key]>=0.25)}])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df = df.sort_values(by='start')\n",
    "        df.to_csv(f'{data_path}/verified_speaker/{sub_name}.csv', index=False)\n",
    "        print(f'{data_path}/verified_speaker/{folder_name}/{sub_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_1.csv\n"
     ]
    }
   ],
   "source": [
    "verify_speaker(folder_name)             # Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataframe:\n",
    "\taudio_path\t    diary_label\t    model_label\t    score\t    verified\t        start\n",
    "30\t/kaggle/...\t    SPEAKER_00\t    DucAnh\t        0.220918\t[tensor(False)]\t    7.0     \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Concat near audio files to one file\n",
    "Condition:\n",
    "    1. Must have same speaker\n",
    "    2. Must have a distance less than 0.5\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "# import argparse\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-df\", \"--data_frame\", type=str, default=0,\n",
    "# \thelp=\"path of data frame\")\n",
    "# ap.add_argument(\"-ap\", \"--audio_path\", type=str, default=0,\n",
    "#     help=\"path of audio file\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def concat_diary(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/concat_diary/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Load dataframe\n",
    "    for df_name in os.listdir(f'{data_path}/verified_speaker/{folder_name}'):   #chunk_4.csv\n",
    "\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end'])\n",
    "        df_path = os.path.join(f'{data_path}/verified_speaker/{folder_name}', df_name)\n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        ##\n",
    "        q = []\n",
    "        current_speaker = None\n",
    "        for _, row in df.iterrows():\n",
    "            if row['verified'] == 'tensor([True])': #phat hien nguoi noi dung\n",
    "                if not current_speaker:             # khoi tao\n",
    "                    current_speaker = row['model_label']\n",
    "                    q.append(row['start']), q.append(row['end'])\n",
    "                else:\n",
    "                    if row['model_label'] == current_speaker:\n",
    "                        q.append(row['end'])\n",
    "                    else:\n",
    "                        new_row = pd.DataFrame([{'audio_path': f'{data_path}/denoised/{df_name[:-4]}', 'model_label': current_speaker, 'start': q[0], 'end': q[-1]}])\n",
    "                        new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "                        current_speaker = row['model_label']\n",
    "                        q = []\n",
    "                        q.append(row['start']), q.append(row['end'])\n",
    "            else:\n",
    "                if len(q)>0:\n",
    "                    new_row = pd.DataFrame([{'audio_path': f'{data_path}/denoised/{df_name[:-4]}', 'model_label': current_speaker, 'start': q[0], 'end': q[-1]}])\n",
    "                    new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "                    q = []\n",
    "                    current_speaker= None\n",
    "                    q.append(row['start']), q.append(row['end'])\n",
    "                q = []\n",
    "                current_speaker = None\n",
    "        new_df.to_csv(f'{save_path}/{df_name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:101: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "concat_diary(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_audio(audio_path, folder_name, q, current_speaker):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/concat_audio/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    start, end = q[0], q[-1]\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    segment = y[int(start*sr):int(end*sr)]\n",
    "    sf.write(f'{save_path}/{round(start,1)} {round(end,1)} {current_speaker}.wav', segment, sr)\n",
    "\n",
    "def concat_audio(folder_name):\n",
    "    data_path = '../../data'\n",
    "    # df = pd.DataFrame(columns=['audio_path', 'model_label', 'score', 'start', 'end'])\n",
    "    for dir in os.listdir(f'{data_path}/concat_diary/{folder_name}'):    #chunk_1, chunk_2,...\n",
    "        dir_path = os.path.join(f'{data_path}/concat_diary/{folder_name}', dir)\n",
    "        audio_path = os.path.join(f'{data_path}/denoised/{folder_name}', dir[:-4]+'.mp3')\n",
    "        print(dir_path, audio_path)\n",
    "        df = pd.read_csv(dir_path)\n",
    "        print(df)\n",
    "        for _, row in df.iterrows():\n",
    "            # print(f'{folder_name}/{dir}')\n",
    "            create_audio(audio_path, f'{folder_name}/{dir[:-4]}', [row['start'], row['end']], row['model_label'])\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/concat_diary/MYNBYT/T1/chunk_4.csv ../../data/denoised/MYNBYT/T1/chunk_4.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_4    BichNgoc  163.5  165.5\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_1.csv ../../data/denoised/MYNBYT/T1/chunk_1.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_1      DucAnh    4.5    9.4\n",
      "1           1  ../../data/denoised/chunk_1      DucAnh  186.3  188.0\n",
      "2           2  ../../data/denoised/chunk_1      DucAnh  272.9  279.7\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_2.csv ../../data/denoised/MYNBYT/T1/chunk_2.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_2      DucAnh    6.5    8.6\n",
      "1           1  ../../data/denoised/chunk_2      DucAnh   24.9   37.3\n",
      "2           2  ../../data/denoised/chunk_2    BichNgoc   55.7   58.4\n",
      "3           3  ../../data/denoised/chunk_2    BichNgoc  156.9  158.9\n",
      "4           4  ../../data/denoised/chunk_2    BichNgoc  162.5  164.8\n",
      "5           5  ../../data/denoised/chunk_2    BichNgoc  188.9  194.1\n",
      "6           6  ../../data/denoised/chunk_2    BichNgoc  215.9  229.9\n",
      "7           7  ../../data/denoised/chunk_2    BichNgoc  248.0  249.1\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_5.csv ../../data/denoised/MYNBYT/T1/chunk_5.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_5    BichNgoc   32.6   36.3\n",
      "1           1  ../../data/denoised/chunk_5      DucAnh   47.0   50.6\n",
      "2           2  ../../data/denoised/chunk_5      DucAnh   69.9   72.2\n",
      "3           3  ../../data/denoised/chunk_5    BichNgoc   87.7   90.3\n",
      "4           4  ../../data/denoised/chunk_5    BichNgoc   99.0  101.5\n",
      "5           5  ../../data/denoised/chunk_5      DucAnh  108.5  110.8\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_3.csv ../../data/denoised/MYNBYT/T1/chunk_3.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_3      DucAnh   99.0  106.5\n",
      "1           1  ../../data/denoised/chunk_3    BichNgoc  220.0  221.7\n",
      "2           2  ../../data/denoised/chunk_3    BichNgoc  242.8  244.7\n",
      "3           3  ../../data/denoised/chunk_3      DucAnh  293.0  294.2\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_0.csv ../../data/denoised/MYNBYT/T1/chunk_0.mp3\n",
      "    Unnamed: 0                   audio_path model_label  start    end\n",
      "0            0  ../../data/denoised/chunk_0      DucAnh   75.5   84.0\n",
      "1            1  ../../data/denoised/chunk_0    BichNgoc   84.7   86.0\n",
      "2            2  ../../data/denoised/chunk_0      DucAnh   86.6   89.9\n",
      "3            3  ../../data/denoised/chunk_0    BichNgoc   96.9   98.0\n",
      "4            4  ../../data/denoised/chunk_0      DucAnh   99.7  109.9\n",
      "5            5  ../../data/denoised/chunk_0      DucAnh  121.0  132.1\n",
      "6            6  ../../data/denoised/chunk_0    BichNgoc  148.9  150.0\n",
      "7            7  ../../data/denoised/chunk_0      DucAnh  159.3  163.1\n",
      "8            8  ../../data/denoised/chunk_0    BichNgoc  186.4  188.8\n",
      "9            9  ../../data/denoised/chunk_0      DucAnh  203.2  240.2\n",
      "10          10  ../../data/denoised/chunk_0    BichNgoc  241.9  248.1\n",
      "11          11  ../../data/denoised/chunk_0      DucAnh  249.4  253.7\n",
      "12          12  ../../data/denoised/chunk_0    BichNgoc  253.9  255.5\n",
      "13          13  ../../data/denoised/chunk_0      DucAnh  270.1  271.8\n",
      "14          14  ../../data/denoised/chunk_0    BichNgoc  275.9  277.6\n"
     ]
    }
   ],
   "source": [
    "concat_audio(folder_name)               # Step 5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"vinai/PhoWhisper-large\", device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.9.11 safetensors-0.4.5 tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        concat audio\n",
    "        \n",
    "    Output:\n",
    "        transcripted audio\n",
    "            audio_path, transcript, speaker\n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/transcriber/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for folder in os.listdir(f'{data_path}/concat_audio/{folder_name}'):\n",
    "        folder_path = os.path.join(f'{data_path}/concat_audio/{folder_name}', folder)\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end', 'script'])\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            script = transcriber(file_path)\n",
    "            start, end, speaker = file_name.split()[0],file_name.split()[1],file_name.split()[2][:-4]\n",
    "            new_row = pd.DataFrame([{'audio_path': file_path, 'model_label': speaker, 'start': start, 'end': end, 'script':script}])\n",
    "            new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "        new_df.to_csv(f'{save_path}/{folder}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: create transcript func\n",
    "transcript(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-20 07:14:17--  https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..kycRgHdnJlANzMbsbUhs9g.GWYcOMJEqidV2e7CcxL_tjVbj7nAf-YUh50KSs-jGA-_KgzJJUHmn-7DEdXZE_pItnkjr2sGUbR3y4LbubVtn_OJNXMfuDgbhAcaQ4N-BwdL-fiJZ8VxUQQbfCB8Zg-mu3gZUxmk12djyDFdeo7hug6KzbY1pFSK1EvJotzP6yS-LtoVj0OONfoqrC0ssjY_zV3NuCH-fcMev-wfIMl2yCEtUMkRgwjx68hK-_LR8wMdRF8kjjMldsLy0qqxtTbMZVHNGFJtBBnABkutTbJLYoCbQ7VxuR0efxo3jZrXbNDVCX8J_BucKkr-B3oK-nwdeW8MxryKEZUBp6ISOfD8990Yg0sSI25PhvrW3Y66rM7W__vzNCvAsiFZvnAXcGU0ryJi6p2Ol9AZAgm2hDH_fLRyt0A5ksP8nY3269hYbUhNS0tNbYpy4p-t0AYbLPt-oT1m9_2y3aQ9TRSKOBjvJ6MrYJmdKE_YWNFNsK4N1OmiORCOiS5C4-FY6zlSam5KUsZnXOPDdSzYbB3j7ajd42qLeDJ7Xx7lRFpOvz7V_0R_bw1xIfpMjrbMhEIjnfDE2H85otdFzmvDev1274tAeqVtWcwd6SNp6O4wH00m1wBfA3Kc8aah_Z9YLvWkpNHjrEbS-IAyLPf9iQwO_DcP5MoADCxXLg0E0mEv9sre5oU.4rPptLagIpP5xZNt90yZ_Q/phobert_fold5.pth\n",
      "Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n",
      "Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 540096685 (515M) [application/x-zip]\n",
      "Saving to: phobert_fold5.pth\n",
      "\n",
      "phobert_fold5.pth   100%[===================>] 515.08M  7.11MB/s    in 77s     \n",
      "\n",
      "2024-09-20 07:15:35 (6.68 MB/s) - phobert_fold5.pth saved [540096685/540096685]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..kycRgHdnJlANzMbsbUhs9g.GWYcOMJEqidV2e7CcxL_tjVbj7nAf-YUh50KSs-jGA-_KgzJJUHmn-7DEdXZE_pItnkjr2sGUbR3y4LbubVtn_OJNXMfuDgbhAcaQ4N-BwdL-fiJZ8VxUQQbfCB8Zg-mu3gZUxmk12djyDFdeo7hug6KzbY1pFSK1EvJotzP6yS-LtoVj0OONfoqrC0ssjY_zV3NuCH-fcMev-wfIMl2yCEtUMkRgwjx68hK-_LR8wMdRF8kjjMldsLy0qqxtTbMZVHNGFJtBBnABkutTbJLYoCbQ7VxuR0efxo3jZrXbNDVCX8J_BucKkr-B3oK-nwdeW8MxryKEZUBp6ISOfD8990Yg0sSI25PhvrW3Y66rM7W__vzNCvAsiFZvnAXcGU0ryJi6p2Ol9AZAgm2hDH_fLRyt0A5ksP8nY3269hYbUhNS0tNbYpy4p-t0AYbLPt-oT1m9_2y3aQ9TRSKOBjvJ6MrYJmdKE_YWNFNsK4N1OmiORCOiS5C4-FY6zlSam5KUsZnXOPDdSzYbB3j7ajd42qLeDJ7Xx7lRFpOvz7V_0R_bw1xIfpMjrbMhEIjnfDE2H85otdFzmvDev1274tAeqVtWcwd6SNp6O4wH00m1wBfA3Kc8aah_Z9YLvWkpNHjrEbS-IAyLPf9iQwO_DcP5MoADCxXLg0E0mEv9sre5oU.4rPptLagIpP5xZNt90yZ_Q/phobert_fold5.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " concat_audio.py\t\t  'output 186.3 to 188.8.wav'\n",
      " create_diarization.py\t\t  'output 86.6 to 87.8.wav'\n",
      " denoise.py\t\t\t   phobert_fold5.pth\n",
      "'_e2e_speaker_label copy.ipynb'    pretrained_models\n",
      " _e2e_speaker_label.ipynb\t   __pycache__\n",
      " e2e_speaker_label.py\t\t   remove_collision.py\n",
      "'hierarchy tree.txt'\t\t   split_audio.py\n",
      "'output 104.6 to 105.4.wav'\t   temp.py\n",
      "'output 148.9 to 150.0.wav'\t   transcript.py\n",
      "'output 150.6 to 151.2.wav'\t   verify_speaker.py\n",
      "'output 152.3 to 152.9 ngy.wav'\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        last_hidden_state, output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False # Dropout will errors if without this\n",
    "        )\n",
    "\n",
    "        x = self.drop(output)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-20 07:25:10--  https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..HkEQpkATUWOQR2L4A444Uw.qHq40kZoU9ZuZWfxfgL8zm-O2YzWPv3KpsoNlNbIpRJ9qE0LT90gQfHNmHOL7JcAXsRfRlwgvTxsD8_Zbxsr_6sEtfMG79_ZzT0WOUDGYa8pV8w1Wy3kLuegmKA4OKRC7RNYTt05U35ctsx0e-dAHetUQvTnOVpz9BQZiNDlIC8M4YUyEefyuXqANcmGZzrQ3uxJRzw_7u6g7QEqngkL0XL4PTt6IongZQYVbIs6oftalCekmMaEGofXEN2z4KmrKkuXN1POHMnhH58pml_fT7jMuR-qi3nBCJgv5jb-aUCGlXJ8FzO5mWUaa20T9MBJUA9KLQXByIhV4e3TxgS65AJ59ntmWVuMEADuNkyvDnF9kT8LOse7G-P6m9NChydaZYZ94Q6TGFpMfes6yvH_gfomvFTRB6dv79c2b-y3t-CLecbw-TMOZllx4_je9wXmCNBJs1VOlnCL5KuBvpR7KyZOFgZccu1WE2pVZSBeEOvEqpojEGedCoql94tqW1eCfCoflRoJIxmsXvwvWaiAeOghmNQGdSEJdYD0uyyf94W-oOp10AsvhMUyx1A-LAh1JCQ79gS_3XshTlDvyvvBGWzatBJlOG5yLS9cMOqiJKYcjNxPyTstvnDBg7EW2gPWhIQUpikblYlt_Fj4SGXebJNmm8bYyhy-cQzrK0wrhiY.RaNQ0i-wgcYw-VFgNoOr5A/phobert_fold4.pth\n",
      "Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n",
      "Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 540096685 (515M) [application/x-zip]\n",
      "Saving to: phobert_fold4.pth\n",
      "\n",
      "phobert_fold4.pth   100%[===================>] 515.08M  6.29MB/s    in 83s     \n",
      "\n",
      "2024-09-20 07:26:33 (6.23 MB/s) - phobert_fold4.pth saved [540096685/540096685]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..HkEQpkATUWOQR2L4A444Uw.qHq40kZoU9ZuZWfxfgL8zm-O2YzWPv3KpsoNlNbIpRJ9qE0LT90gQfHNmHOL7JcAXsRfRlwgvTxsD8_Zbxsr_6sEtfMG79_ZzT0WOUDGYa8pV8w1Wy3kLuegmKA4OKRC7RNYTt05U35ctsx0e-dAHetUQvTnOVpz9BQZiNDlIC8M4YUyEefyuXqANcmGZzrQ3uxJRzw_7u6g7QEqngkL0XL4PTt6IongZQYVbIs6oftalCekmMaEGofXEN2z4KmrKkuXN1POHMnhH58pml_fT7jMuR-qi3nBCJgv5jb-aUCGlXJ8FzO5mWUaa20T9MBJUA9KLQXByIhV4e3TxgS65AJ59ntmWVuMEADuNkyvDnF9kT8LOse7G-P6m9NChydaZYZ94Q6TGFpMfes6yvH_gfomvFTRB6dv79c2b-y3t-CLecbw-TMOZllx4_je9wXmCNBJs1VOlnCL5KuBvpR7KyZOFgZccu1WE2pVZSBeEOvEqpojEGedCoql94tqW1eCfCoflRoJIxmsXvwvWaiAeOghmNQGdSEJdYD0uyyf94W-oOp10AsvhMUyx1A-LAh1JCQ79gS_3XshTlDvyvvBGWzatBJlOG5yLS9cMOqiJKYcjNxPyTstvnDBg7EW2gPWhIQUpikblYlt_Fj4SGXebJNmm8bYyhy-cQzrK0wrhiY.RaNQ0i-wgcYw-VFgNoOr5A/phobert_fold4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier(n_classes=7).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/1143647024.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/home/tuannd/tuanlha/EXpressiveTTS/src/speaker_diarization/phobert_fold4.pth'), strict=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('/home/tuannd/tuanlha/EXpressiveTTS/src/speaker_diarization/phobert_fold4.pth'), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "class_names = ['Enjoyment', 'Disgust', 'Sadness', 'Anger', 'Surprise', 'Fear', 'Other']\n",
    "\n",
    "def infer(text, tokenizer, max_len=120):\n",
    "    encoded_review = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_review['input_ids'].to(device)\n",
    "    attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "    output = model(input_ids, attention_mask)\n",
    "    _, y_pred = torch.max(output, dim=1)\n",
    "\n",
    "    print(f'Text: {text}')\n",
    "    print(f'Sentiment: {class_names[y_pred]}')\n",
    "    return class_names[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Cm n bn  chy th model ca mnh. Chc mt ngy tt lnh nha!\n",
      "Sentiment: Enjoyment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Enjoyment'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer('Cm n bn  chy th model ca mnh. Chc mt ngy tt lnh nha!', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_label(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/emotion_label/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for folder in os.listdir(f'{data_path}/transcriber/{folder_name}'):\n",
    "        folder_path = os.path.join(f'{data_path}/transcriber/{folder_name}', folder)\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end', 'script', 'emotion'])\n",
    "        df = pd.read_csv(folder_path)\n",
    "        # print(df)\n",
    "        for _, row in df.iterrows():\n",
    "            audio_path,model_label,start,end,script = row['audio_path'], row['model_label'], row['start'], row['end'], row['script']\n",
    "            emotion = infer(script, tokenizer)\n",
    "            new_row = pd.DataFrame([{'audio_path': audio_path, 'model_label': model_label, 'start': start, 'end': end, 'script':script, 'emotion': emotion}])\n",
    "            new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "        new_df.to_csv(f'{save_path}/{folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 'hm qua  spa c lin hoan.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': ' m nay tao phi chy t lai nn chc l v mun nu m c g m hn say qu th my a hn v nh.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'c i l ng y ch tun trc a h ni rt but lnh lm c  va ma phn nm m.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'gi  nhc em l nh qu c.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'em hc ni ging si gn  trn mng .'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'd vng y chu cng  nh bay vo thm ng anh h  trong khu cng nghip bnh dng nhng m gi v th ny th kh qu bn chu li taxi th ny ngy c vi trm by gi m i th mt mt ngy cng.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'vui th  li lu lu mt xu nh.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'hm nay vi ngy mai l em xin ngh nh em c khch  qu ra cn g  th thoa i ht mm tm ri bo ci nhung ra ch mua i nhung ra ch mua mm tm cho m bo trong trong v ly tin cho m i thi.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'my th c ti sao li ni vi m nh th h.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'thi ch d lut i nh.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'm chu nghe ni t ngy mng mt thng ba.'}\n",
      "Sentiment: Enjoyment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 'th hai l khoi no lm sao em bit c cng c th l c anh hay l ci hn n khoi nhm th sao.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': ' n ni m chng con c v khng con cng khng bit.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'lm g u c ng l g m i khc u.'}\n",
      "Sentiment: Disgust\n",
      "Text: {'text': 'cn ci thi ny thng nc anh u anh y i lm t thng  m.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'lc y con hay i v m xong vo sng i sm chc thn khng bit.'}\n",
      "Sentiment: Fear\n",
      "Text: {'text': 'mang ci xch t y no y no ra kha cng.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'ci ci trch dt ngoi ca l.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'mnh bo l nh th c in khng.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'cha  trong y ng lm ri.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'may qu g i mt tin p khng y anh i khng t t  anh y c g em a anh i bnh vin kim tra xem mnh kim tra chp chiu xem thng khp hay l.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'em gi ch a no nghe my c.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'thi mnh n nhanh i cn vic khng thi lm na.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'chu c chn ra ch xin hc cho  bui lin.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'm ny mi hai gi y nh ng mi hai gi m khng gi mail th c ng c trch y.'}\n",
      "Sentiment: Other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 't xong vic  y nh em s v cng ty lm vic tip cho anh.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'thi tp trung by gi tt c cc em hon thnh phn vic ca mnh ng hai ting na gi email cho anh anh s  y tng hp x l ri gi cho khch hng anh em mnh phi n cht con iu ny.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'leo cht phi gi lc my gi l tt.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'vn phi c gng  thc lc ch.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'y l ln u tin m em ch ra mt xu thi em i chi bn v t em s chn elai cho anh.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'vng vng vng em bit ri .'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'thng lm lm chp v pht ngn xut sc tht nht hay nht tht  ny t t tr vi ci tin i mun vn hn n cng ty cha tr u.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'va kim c mt ci rt rt ngon lun anh  gi mail phn cng cng vic cho tng a ri check mail lun i mnh c ng mt m nay  lm bn k hoch chi tit truyn thng cho khch hng.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'trc by gi sng mai c nh thng anh  lm vic ring vi tr l bn h ri.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'em y em y.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'by gi anh cho my ng ba mi giy  tr li ang  u vi ai lm g.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'chu nh gi cho c  bo vi c l  hm nay a phin ngc l phi tng ca v mun c  d vng d vng  c yn tm i ng trc i  cho cho c.anh chiu my qu nn my h ng khng anh nhn my vo cng ty khng phi l  ni di m xong ri kim c i chi c nh.'}\n",
      "Sentiment: Disgust\n"
     ]
    }
   ],
   "source": [
    "emotion_label(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuanlha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
