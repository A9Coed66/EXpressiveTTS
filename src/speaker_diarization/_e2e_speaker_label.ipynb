{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Chunk audio\n",
    "    output: 1. chunked audio: audio file\n",
    "2. Denoise audio\n",
    "    output: 2.denoise audio: audio file\n",
    "3. Diarization\n",
    "    output: 3. diary: dataframe [columns: start, end, speaker]\n",
    "4. Speaker labeled from diary logs\n",
    "    output: 4. speaker labeled: dataframe [columns: audio_path, diary_label, model_label, score, verified]\n",
    "5. Concat near audio files to one file\n",
    "    output: 5. concatenated audio:  dataframe [columns: start. end, speaker]\n",
    "                                    audio file\n",
    "6. Audio speech recognition:\n",
    "    output: 6. transcript: dataframe [columns: audio_path, transcript, speaker]\n",
    "\"\"\"\n",
    "### 0. setup data\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-ap\", \"--audio_path\", type=str, default=0,\n",
    "#     help=\"path of audio file\")\n",
    "# ap.add_argument(\"-fn\", \"--folder_name\", type=str)\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "### 1. Chunk audio\n",
    "from split_audio import split_audio\n",
    "from denoise import denoise\n",
    "from create_diarization import create_diarization\n",
    "from remove_collision import remove_collision, split_diarization\n",
    "# from verify_speaker import verify_speaker\n",
    "# from concat_audio import concat_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/home/tuannd/tuanlha/EXpressiveTTS/data/audio/y2mate.com - Mình Yêu Nhau Bình Yên Thôi Tập 2  Phim truyền hình VTV3 hay nhất 2024   Full HD  SK Pictures_320kbps.mp3'\n",
    "folder_name = 'MYNBYT/T2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_audio import split_audio\n",
    "split_audio(audio_path, folder_name)    # Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save chunk_4.mp3\n",
      "Save chunk_0.mp3\n",
      "Save chunk_2.mp3\n",
      "Save chunk_1.mp3\n",
      "Save chunk_3.mp3\n"
     ]
    }
   ],
   "source": [
    "from denoise import denoise\n",
    "denoise(folder_name)                    # Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display as disp\n",
    "import torch\n",
    "import torchaudio\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio\n",
    "import os\n",
    "\n",
    "def denoise(folder_name, get_audio = True):\n",
    "    model = pretrained.dns64().cuda()\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/denoised/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/chunk/{folder_name}'):    # file_name = chunk/yeunhaudi/chunk_{i}.mp3\n",
    "        file_path = os.path.join(f'{data_path}/chunk/{folder_name}', file_name)\n",
    "        wav, sr = torchaudio.load(file_path)\n",
    "        wav = convert_audio(wav.cuda(), sr, model.sample_rate, model.chin)\n",
    "        with torch.no_grad():\n",
    "            denoised = model(wav[None])[0]\n",
    "        if get_audio:\n",
    "            torchaudio.save(f'{save_path}/{file_name}', denoised.to('cpu'), sr)\n",
    "            print(f\"Save {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading diarization model...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "secret = \"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\"\n",
    "\n",
    "print(\"Loading diarization model...\")\n",
    "diarization = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=secret)\n",
    "\n",
    "\n",
    "diarization.to(torch.device(\"cuda\"))\n",
    "\n",
    "def create_diarization(folder_name):\n",
    "    # apply pretrained pipeline\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/diary/{folder_name}'\n",
    "\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/denoised/{folder_name}'):\n",
    "        file_path = os.path.join(f'{data_path}/denoised/{folder_name}', file_name)\n",
    "        diary = diarization(file_path)\n",
    "        with open(f'{save_path}/logs_{file_name[:-4]}.pkl', 'wb') as f:\n",
    "            pickle.dump(diary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_diarization(folder_name)         # Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=1.0s stop=1.9s speaker_SPEAKER_00\n",
      "start=7.1s stop=8.0s speaker_SPEAKER_00\n",
      "start=8.3s stop=8.4s speaker_SPEAKER_00\n",
      "start=20.0s stop=21.9s speaker_SPEAKER_00\n",
      "start=28.3s stop=28.8s speaker_SPEAKER_00\n",
      "start=29.3s stop=29.7s speaker_SPEAKER_00\n",
      "start=30.7s stop=36.7s speaker_SPEAKER_04\n",
      "start=36.7s stop=42.6s speaker_SPEAKER_01\n",
      "start=43.0s stop=43.6s speaker_SPEAKER_01\n",
      "start=44.0s stop=46.4s speaker_SPEAKER_01\n",
      "start=47.2s stop=47.5s speaker_SPEAKER_01\n",
      "start=47.9s stop=48.3s speaker_SPEAKER_01\n",
      "start=48.3s stop=48.5s speaker_SPEAKER_00\n",
      "start=48.5s stop=49.0s speaker_SPEAKER_01\n",
      "start=49.0s stop=49.8s speaker_SPEAKER_00\n",
      "start=50.2s stop=50.5s speaker_SPEAKER_00\n",
      "start=52.7s stop=53.5s speaker_SPEAKER_00\n",
      "start=54.6s stop=55.7s speaker_SPEAKER_00\n",
      "start=55.7s stop=56.0s speaker_SPEAKER_00\n",
      "start=64.3s stop=64.6s speaker_SPEAKER_00\n",
      "start=71.9s stop=72.6s speaker_SPEAKER_02\n",
      "start=74.0s stop=75.0s speaker_SPEAKER_02\n",
      "start=75.5s stop=77.0s speaker_SPEAKER_02\n",
      "start=77.5s stop=80.5s speaker_SPEAKER_02\n",
      "start=80.9s stop=84.1s speaker_SPEAKER_02\n",
      "start=84.7s stop=86.0s speaker_SPEAKER_01\n",
      "start=86.6s stop=87.8s speaker_SPEAKER_02\n",
      "start=88.4s stop=89.9s speaker_SPEAKER_02\n",
      "start=95.3s stop=96.4s speaker_SPEAKER_04\n",
      "start=96.9s stop=98.0s speaker_SPEAKER_04\n",
      "start=98.5s stop=98.9s speaker_SPEAKER_02\n",
      "start=99.7s stop=101.4s speaker_SPEAKER_02\n",
      "start=102.4s stop=103.1s speaker_SPEAKER_04\n",
      "start=103.5s stop=104.0s speaker_SPEAKER_02\n",
      "start=104.6s stop=105.4s speaker_SPEAKER_02\n",
      "start=107.2s stop=108.1s speaker_SPEAKER_02\n",
      "start=108.5s stop=109.9s speaker_SPEAKER_02\n",
      "start=110.3s stop=111.0s speaker_SPEAKER_02\n",
      "start=111.5s stop=116.0s speaker_SPEAKER_02\n",
      "start=116.2s stop=117.2s speaker_SPEAKER_02\n",
      "start=121.0s stop=122.1s speaker_SPEAKER_02\n",
      "start=124.2s stop=130.5s speaker_SPEAKER_02\n",
      "start=130.7s stop=132.1s speaker_SPEAKER_02\n",
      "start=132.1s stop=132.3s speaker_SPEAKER_04\n",
      "start=137.3s stop=137.6s speaker_SPEAKER_00\n",
      "start=139.1s stop=139.2s speaker_SPEAKER_00\n",
      "start=139.2s stop=139.2s speaker_SPEAKER_00\n",
      "start=139.3s stop=139.7s speaker_SPEAKER_00\n",
      "start=140.2s stop=140.5s speaker_SPEAKER_00\n",
      "start=148.9s stop=150.0s speaker_SPEAKER_04\n",
      "start=150.6s stop=151.2s speaker_SPEAKER_04\n",
      "start=152.3s stop=152.9s speaker_SPEAKER_03\n",
      "start=156.0s stop=156.7s speaker_SPEAKER_04\n",
      "start=159.3s stop=163.1s speaker_SPEAKER_02\n",
      "start=170.1s stop=171.1s speaker_SPEAKER_00\n",
      "start=171.8s stop=173.2s speaker_SPEAKER_00\n",
      "start=172.3s stop=172.3s speaker_SPEAKER_01\n",
      "start=175.6s stop=176.4s speaker_SPEAKER_00\n",
      "start=176.4s stop=176.5s speaker_SPEAKER_01\n",
      "start=176.5s stop=179.6s speaker_SPEAKER_04\n",
      "start=176.5s stop=176.6s speaker_SPEAKER_01\n",
      "start=181.0s stop=181.6s speaker_SPEAKER_01\n",
      "start=182.1s stop=182.2s speaker_SPEAKER_01\n",
      "start=182.2s stop=182.2s speaker_SPEAKER_00\n",
      "start=182.2s stop=182.3s speaker_SPEAKER_04\n",
      "start=182.3s stop=182.4s speaker_SPEAKER_01\n",
      "start=183.9s stop=184.5s speaker_SPEAKER_04\n",
      "start=185.2s stop=185.9s speaker_SPEAKER_04\n",
      "start=186.4s stop=188.8s speaker_SPEAKER_04\n",
      "start=190.1s stop=190.5s speaker_SPEAKER_03\n",
      "start=190.6s stop=191.8s speaker_SPEAKER_04\n",
      "start=194.7s stop=195.1s speaker_SPEAKER_03\n",
      "start=196.9s stop=197.4s speaker_SPEAKER_03\n",
      "start=201.4s stop=201.9s speaker_SPEAKER_03\n",
      "start=203.2s stop=204.9s speaker_SPEAKER_03\n",
      "start=209.4s stop=212.7s speaker_SPEAKER_03\n",
      "start=213.7s stop=214.3s speaker_SPEAKER_03\n",
      "start=225.5s stop=227.5s speaker_SPEAKER_03\n",
      "start=228.1s stop=228.5s speaker_SPEAKER_03\n",
      "start=232.4s stop=233.8s speaker_SPEAKER_02\n",
      "start=234.7s stop=234.8s speaker_SPEAKER_03\n",
      "start=236.2s stop=240.2s speaker_SPEAKER_02\n",
      "start=241.9s stop=242.9s speaker_SPEAKER_04\n",
      "start=244.3s stop=244.4s speaker_SPEAKER_04\n",
      "start=244.4s stop=245.0s speaker_SPEAKER_01\n",
      "start=246.1s stop=248.1s speaker_SPEAKER_01\n",
      "start=248.5s stop=249.0s speaker_SPEAKER_01\n",
      "start=249.4s stop=250.6s speaker_SPEAKER_02\n",
      "start=251.4s stop=253.7s speaker_SPEAKER_02\n",
      "start=253.9s stop=255.5s speaker_SPEAKER_04\n",
      "start=255.9s stop=256.2s speaker_SPEAKER_04\n",
      "start=257.9s stop=257.9s speaker_SPEAKER_02\n",
      "start=257.9s stop=258.3s speaker_SPEAKER_03\n",
      "start=270.1s stop=271.8s speaker_SPEAKER_02\n",
      "start=272.3s stop=272.9s speaker_SPEAKER_02\n",
      "start=272.5s stop=273.6s speaker_SPEAKER_04\n",
      "start=274.2s stop=274.7s speaker_SPEAKER_04\n",
      "start=275.9s stop=277.6s speaker_SPEAKER_04\n",
      "start=290.0s stop=290.2s speaker_SPEAKER_00\n",
      "start=292.2s stop=294.0s speaker_SPEAKER_00\n",
      "start=298.0s stop=298.9s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/tuannd/tuanlha/EXpressiveTTS/data/diary/MYNBYT/T1/logs_chunk_0.pkl\"\n",
    "with open(path, 'rb') as file:\n",
    "    # Sử dụng pickle để tải đối tượng từ tệp\n",
    "    loaded_object = pickle.load(file)\n",
    "for turn, _, speaker in loaded_object.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import librosa\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def create_origin_logs(diarization):\n",
    "    logs = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        logs.append([round(turn.start,2), round(turn.end,2), speaker])\n",
    "    return logs\n",
    "\n",
    "def remove_collision(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/logs_no_col/{folder_name}'\n",
    "\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    for file_name in os.listdir(f'{data_path}/diary/{folder_name}'):\n",
    "        print(file_name)\n",
    "        file_path = os.path.join(f'{data_path}/diary/{folder_name}', file_name)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            diary = pickle.load(f)\n",
    "        origin_log = create_origin_logs(diary)\n",
    "        print(origin_log)\n",
    "        log = []\n",
    "        # Pre\n",
    "        if not origin_log:\n",
    "            with open(f'{save_path}/{file_name[:-4]}.json', 'w') as f:   \n",
    "            # /log_no_col/Yen nhau di/logs_chunk_1.json\n",
    "                json.dump(log, f)\n",
    "            continue\n",
    "\n",
    "        preivous = [origin_log[0][0], origin_log[0][1]]\n",
    "        last_end = origin_log[0][1]\n",
    "        if last_end < origin_log[1][0]:\n",
    "            log.append([preivous, origin_log[0][2]])\n",
    "        \n",
    "        # In\n",
    "        for i in range(1, len(origin_log)-1):\n",
    "            start, end = origin_log[i][0], origin_log[i][1]\n",
    "            if start < last_end:\n",
    "                last_end = max(last_end, end)\n",
    "            else:\n",
    "                if end > origin_log[i+1][0]:\n",
    "                    preivous = [start, end]\n",
    "                else:\n",
    "                    preivous = [start, end]\n",
    "                    if end-start > 1:\n",
    "                        log.append([[start, end], origin_log[i][2]])\n",
    "        \n",
    "        # End\n",
    "        if origin_log[-1][0] > last_end+1:\n",
    "            if origin_log[-1][1] - origin_log[-1][0]>0.1:\n",
    "                log.append([[origin_log[-1][0], origin_log[-1][1]], origin_log[-1][2]])\n",
    "\n",
    "        # Save\n",
    "        with open(f'{save_path}/{file_name[:-4]}.json', 'w') as f:   \n",
    "            # /log_no_col/Yen nhau di/logs_chunk_1.json\n",
    "            json.dump(log, f)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_chunk_4.pkl\n",
      "[[1.41, 2.22, 'SPEAKER_00'], [2.65, 3.12, 'SPEAKER_00'], [4.13, 4.98, 'SPEAKER_00'], [6.06, 7.71, 'SPEAKER_00'], [8.81, 9.31, 'SPEAKER_00'], [10.24, 11.57, 'SPEAKER_00'], [16.21, 16.38, 'SPEAKER_00'], [17.21, 17.51, 'SPEAKER_00'], [17.87, 19.37, 'SPEAKER_00'], [19.61, 20.57, 'SPEAKER_00'], [22.41, 23.5, 'SPEAKER_00'], [24.23, 24.7, 'SPEAKER_00'], [26.22, 26.93, 'SPEAKER_00'], [29.78, 30.1, 'SPEAKER_00'], [30.69, 31.08, 'SPEAKER_00'], [31.2, 31.86, 'SPEAKER_00'], [31.98, 32.7, 'SPEAKER_00'], [33.29, 34.52, 'SPEAKER_00'], [35.57, 36.31, 'SPEAKER_00'], [36.8, 37.93, 'SPEAKER_00'], [40.04, 41.53, 'SPEAKER_00'], [42.74, 44.23, 'SPEAKER_00'], [45.46, 45.83, 'SPEAKER_00'], [46.44, 46.89, 'SPEAKER_00'], [47.62, 47.89, 'SPEAKER_00'], [50.52, 53.12, 'SPEAKER_00'], [54.22, 54.62, 'SPEAKER_00'], [57.14, 57.73, 'SPEAKER_00'], [60.02, 60.95, 'SPEAKER_00'], [62.2, 63.18, 'SPEAKER_00'], [64.26, 65.3, 'SPEAKER_00'], [65.94, 66.5, 'SPEAKER_00'], [66.86, 67.55, 'SPEAKER_00'], [68.49, 69.3, 'SPEAKER_00'], [69.83, 75.04, 'SPEAKER_00'], [76.05, 76.24, 'SPEAKER_00'], [77.23, 77.86, 'SPEAKER_00'], [78.52, 80.63, 'SPEAKER_00'], [81.49, 85.03, 'SPEAKER_00'], [86.82, 87.33, 'SPEAKER_00'], [87.75, 91.22, 'SPEAKER_00']]\n",
      "logs_chunk_3.pkl\n",
      "[[0.28, 2.22, 'SPEAKER_00'], [2.53, 3.07, 'SPEAKER_00'], [4.79, 5.11, 'SPEAKER_00'], [5.72, 6.43, 'SPEAKER_00'], [6.78, 9.21, 'SPEAKER_00'], [24.65, 25.02, 'SPEAKER_00'], [25.19, 25.46, 'SPEAKER_00'], [26.36, 26.56, 'SPEAKER_00'], [26.76, 32.97, 'SPEAKER_00'], [33.11, 34.22, 'SPEAKER_00'], [34.39, 34.52, 'SPEAKER_00'], [35.96, 37.71, 'SPEAKER_00'], [38.59, 43.33, 'SPEAKER_00'], [57.05, 57.91, 'SPEAKER_00'], [72.68, 72.76, 'SPEAKER_00'], [95.88, 96.02, 'SPEAKER_00'], [96.69, 97.08, 'SPEAKER_00'], [97.72, 99.17, 'SPEAKER_00'], [100.44, 102.65, 'SPEAKER_00'], [103.47, 103.96, 'SPEAKER_00'], [104.17, 104.59, 'SPEAKER_00'], [104.86, 104.98, 'SPEAKER_00']]\n",
      "logs_chunk_2.pkl\n",
      "[[0.03, 0.91, 'SPEAKER_00'], [1.45, 2.01, 'SPEAKER_00'], [2.61, 3.36, 'SPEAKER_00'], [6.06, 6.36, 'SPEAKER_00'], [6.65, 8.43, 'SPEAKER_00'], [8.52, 10.93, 'SPEAKER_00'], [11.78, 12.27, 'SPEAKER_00'], [12.55, 13.21, 'SPEAKER_00'], [13.92, 16.89, 'SPEAKER_00'], [17.63, 18.63, 'SPEAKER_00'], [18.83, 19.4, 'SPEAKER_00'], [20.04, 20.64, 'SPEAKER_00'], [20.96, 21.16, 'SPEAKER_00'], [22.26, 23.32, 'SPEAKER_00'], [24.18, 26.74, 'SPEAKER_00'], [27.0, 28.65, 'SPEAKER_00'], [28.7, 28.87, 'SPEAKER_00'], [28.95, 30.15, 'SPEAKER_00'], [30.25, 30.36, 'SPEAKER_00'], [34.89, 38.94, 'SPEAKER_00'], [40.68, 42.56, 'SPEAKER_00'], [43.64, 45.34, 'SPEAKER_00'], [45.58, 45.85, 'SPEAKER_00'], [46.93, 47.28, 'SPEAKER_00'], [49.63, 53.15, 'SPEAKER_00'], [53.73, 54.35, 'SPEAKER_00'], [54.94, 62.08, 'SPEAKER_00'], [62.64, 65.98, 'SPEAKER_00'], [66.37, 66.59, 'SPEAKER_00'], [67.16, 70.18, 'SPEAKER_00'], [70.75, 74.48, 'SPEAKER_00'], [74.8, 77.32, 'SPEAKER_00'], [77.61, 79.44, 'SPEAKER_00'], [79.58, 85.38, 'SPEAKER_00'], [86.18, 86.28, 'SPEAKER_00'], [87.14, 87.85, 'SPEAKER_00'], [88.61, 89.33, 'SPEAKER_00'], [89.49, 91.53, 'SPEAKER_00'], [92.93, 93.43, 'SPEAKER_00'], [93.72, 98.09, 'SPEAKER_00'], [99.07, 100.3, 'SPEAKER_00'], [101.48, 104.86, 'SPEAKER_00'], [105.28, 105.53, 'SPEAKER_00'], [105.75, 106.17, 'SPEAKER_00'], [106.92, 106.97, 'SPEAKER_00'], [107.22, 108.98, 'SPEAKER_00']]\n",
      "logs_chunk_0.pkl\n",
      "[[2.04, 3.03, 'SPEAKER_00'], [3.46, 8.69, 'SPEAKER_00'], [10.04, 11.51, 'SPEAKER_00'], [17.06, 17.16, 'SPEAKER_00'], [21.31, 21.51, 'SPEAKER_00'], [21.93, 22.96, 'SPEAKER_00'], [23.81, 25.21, 'SPEAKER_00'], [25.97, 27.44, 'SPEAKER_00'], [28.26, 28.5, 'SPEAKER_00'], [29.11, 29.39, 'SPEAKER_00'], [30.88, 32.38, 'SPEAKER_00'], [33.11, 33.68, 'SPEAKER_00'], [38.81, 38.91, 'SPEAKER_00'], [40.13, 40.8, 'SPEAKER_00'], [41.27, 41.56, 'SPEAKER_00'], [41.86, 43.69, 'SPEAKER_00'], [44.11, 44.29, 'SPEAKER_00'], [44.51, 44.85, 'SPEAKER_00'], [54.44, 54.82, 'SPEAKER_00'], [55.16, 55.33, 'SPEAKER_00'], [59.43, 61.84, 'SPEAKER_00'], [62.6, 63.92, 'SPEAKER_00'], [65.12, 65.22, 'SPEAKER_00'], [65.84, 67.35, 'SPEAKER_00'], [67.6, 69.37, 'SPEAKER_00'], [69.79, 69.84, 'SPEAKER_00'], [70.13, 71.9, 'SPEAKER_00'], [73.74, 74.25, 'SPEAKER_00'], [75.28, 75.55, 'SPEAKER_00'], [80.12, 83.7, 'SPEAKER_00'], [84.17, 86.48, 'SPEAKER_00'], [87.63, 87.9, 'SPEAKER_00'], [88.59, 89.77, 'SPEAKER_00'], [90.16, 91.65, 'SPEAKER_00'], [93.28, 94.16, 'SPEAKER_00'], [95.32, 96.3, 'SPEAKER_00'], [96.69, 96.89, 'SPEAKER_00'], [97.57, 99.12, 'SPEAKER_00'], [99.56, 100.86, 'SPEAKER_00'], [103.31, 104.03, 'SPEAKER_00'], [104.39, 107.42, 'SPEAKER_00'], [108.23, 108.98, 'SPEAKER_00']]\n",
      "logs_chunk_1.pkl\n",
      "[[0.03, 0.12, 'SPEAKER_01'], [0.03, 0.42, 'SPEAKER_00'], [0.57, 1.2, 'SPEAKER_00'], [1.65, 2.14, 'SPEAKER_00'], [2.78, 3.69, 'SPEAKER_00'], [4.6, 5.09, 'SPEAKER_00'], [5.31, 5.72, 'SPEAKER_00'], [7.05, 8.2, 'SPEAKER_00'], [8.65, 14.75, 'SPEAKER_00'], [14.91, 25.61, 'SPEAKER_00'], [26.39, 26.76, 'SPEAKER_00'], [27.28, 28.3, 'SPEAKER_00'], [29.97, 30.73, 'SPEAKER_00'], [31.45, 32.26, 'SPEAKER_00'], [36.89, 38.05, 'SPEAKER_00'], [38.27, 38.67, 'SPEAKER_00'], [39.2, 39.45, 'SPEAKER_00'], [40.16, 43.2, 'SPEAKER_00'], [44.06, 46.69, 'SPEAKER_00'], [45.64, 46.37, 'SPEAKER_01'], [46.91, 47.28, 'SPEAKER_00'], [48.93, 51.09, 'SPEAKER_00'], [51.35, 51.84, 'SPEAKER_00'], [53.73, 57.25, 'SPEAKER_00'], [57.56, 58.13, 'SPEAKER_00'], [58.99, 59.03, 'SPEAKER_00'], [59.06, 59.41, 'SPEAKER_00'], [59.85, 60.04, 'SPEAKER_00'], [61.89, 62.49, 'SPEAKER_00'], [62.69, 63.41, 'SPEAKER_00'], [63.82, 64.93, 'SPEAKER_00'], [66.21, 68.05, 'SPEAKER_00'], [68.29, 69.07, 'SPEAKER_00'], [69.1, 70.23, 'SPEAKER_00'], [71.21, 72.75, 'SPEAKER_00'], [72.98, 76.42, 'SPEAKER_00'], [76.74, 77.07, 'SPEAKER_00'], [77.49, 78.53, 'SPEAKER_00'], [78.79, 80.71, 'SPEAKER_00'], [81.23, 81.98, 'SPEAKER_00'], [83.07, 83.39, 'SPEAKER_00'], [83.8, 84.15, 'SPEAKER_00'], [84.52, 85.47, 'SPEAKER_00'], [85.76, 86.57, 'SPEAKER_00'], [87.33, 88.03, 'SPEAKER_00'], [90.48, 91.26, 'SPEAKER_00'], [91.43, 92.34, 'SPEAKER_00'], [92.4, 92.49, 'SPEAKER_00'], [93.27, 95.19, 'SPEAKER_00'], [95.34, 95.64, 'SPEAKER_00'], [96.4, 99.1, 'SPEAKER_00'], [99.71, 100.15, 'SPEAKER_00'], [100.27, 100.77, 'SPEAKER_00'], [102.16, 104.2, 'SPEAKER_00'], [104.61, 107.1, 'SPEAKER_00'], [108.27, 108.3, 'SPEAKER_00']]\n"
     ]
    }
   ],
   "source": [
    "remove_collision(folder_name)\n",
    "\n",
    "#TODO: fix split_diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def split_diarization(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        logs_no_collision\n",
    "        audio_path\n",
    "    Output:\n",
    "        split_diary\n",
    "            Nguoi phan xu\n",
    "                chunk_1\n",
    "                    output 0.0 to 1.0.wav\n",
    "                    output 1.0 to 2.0.wav\n",
    "                chunk_2...\n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/split_diary/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/logs_no_col/{folder_name}'):\n",
    "        print(file_name)\n",
    "        with open(f'{data_path}/logs_no_col/{folder_name}/{file_name}', 'r') as f:\n",
    "            logs = json.load(f)\n",
    "        audio_path = f'{data_path}/denoised/{folder_name}/{file_name[5:-5]}.mp3'\n",
    "        print(audio_path)\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        for log in logs:\n",
    "            start, end, speaker = log[0][0], log[0][1], log[1]\n",
    "            print(start, end, speaker)\n",
    "            segment = y[int(start*sr):int(end*sr)]\n",
    "\n",
    "            if not os.path.exists(f'{save_path}/{file_name[5:-5]}'):\n",
    "                os.makedirs(f'{save_path}/{file_name[5:-5]}')\n",
    "\n",
    "            sf.write(f'{save_path}/{file_name[5:-5]}/{round(start,1)} {round(end,1)} {speaker}.wav', segment, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_chunk_3.json\n",
      "../../data/denoised/MYNBYT/T2/chunk_3.mp3\n",
      "0.28 2.22 SPEAKER_00\n",
      "6.78 9.21 SPEAKER_00\n",
      "26.76 32.97 SPEAKER_00\n",
      "33.11 34.22 SPEAKER_00\n",
      "35.96 37.71 SPEAKER_00\n",
      "38.59 43.33 SPEAKER_00\n",
      "97.72 99.17 SPEAKER_00\n",
      "100.44 102.65 SPEAKER_00\n",
      "104.86 104.98 SPEAKER_00\n",
      "logs_chunk_2.json\n",
      "../../data/denoised/MYNBYT/T2/chunk_2.mp3\n",
      "0.03 0.91 SPEAKER_00\n",
      "6.65 8.43 SPEAKER_00\n",
      "8.52 10.93 SPEAKER_00\n",
      "13.92 16.89 SPEAKER_00\n",
      "22.26 23.32 SPEAKER_00\n",
      "24.18 26.74 SPEAKER_00\n",
      "27.0 28.65 SPEAKER_00\n",
      "28.95 30.15 SPEAKER_00\n",
      "34.89 38.94 SPEAKER_00\n",
      "40.68 42.56 SPEAKER_00\n",
      "43.64 45.34 SPEAKER_00\n",
      "49.63 53.15 SPEAKER_00\n",
      "54.94 62.08 SPEAKER_00\n",
      "62.64 65.98 SPEAKER_00\n",
      "67.16 70.18 SPEAKER_00\n",
      "70.75 74.48 SPEAKER_00\n",
      "74.8 77.32 SPEAKER_00\n",
      "77.61 79.44 SPEAKER_00\n",
      "79.58 85.38 SPEAKER_00\n",
      "89.49 91.53 SPEAKER_00\n",
      "93.72 98.09 SPEAKER_00\n",
      "99.07 100.3 SPEAKER_00\n",
      "101.48 104.86 SPEAKER_00\n",
      "107.22 108.98 SPEAKER_00\n",
      "logs_chunk_1.json\n",
      "../../data/denoised/MYNBYT/T2/chunk_1.mp3\n",
      "7.05 8.2 SPEAKER_00\n",
      "8.65 14.75 SPEAKER_00\n",
      "14.91 25.61 SPEAKER_00\n",
      "27.28 28.3 SPEAKER_00\n",
      "36.89 38.05 SPEAKER_00\n",
      "40.16 43.2 SPEAKER_00\n",
      "48.93 51.09 SPEAKER_00\n",
      "53.73 57.25 SPEAKER_00\n",
      "63.82 64.93 SPEAKER_00\n",
      "66.21 68.05 SPEAKER_00\n",
      "69.1 70.23 SPEAKER_00\n",
      "71.21 72.75 SPEAKER_00\n",
      "72.98 76.42 SPEAKER_00\n",
      "77.49 78.53 SPEAKER_00\n",
      "78.79 80.71 SPEAKER_00\n",
      "93.27 95.19 SPEAKER_00\n",
      "96.4 99.1 SPEAKER_00\n",
      "102.16 104.2 SPEAKER_00\n",
      "104.61 107.1 SPEAKER_00\n",
      "logs_chunk_0.json\n",
      "../../data/denoised/MYNBYT/T2/chunk_0.mp3\n",
      "2.04 3.03 SPEAKER_00\n",
      "3.46 8.69 SPEAKER_00\n",
      "10.04 11.51 SPEAKER_00\n",
      "21.93 22.96 SPEAKER_00\n",
      "23.81 25.21 SPEAKER_00\n",
      "25.97 27.44 SPEAKER_00\n",
      "30.88 32.38 SPEAKER_00\n",
      "41.86 43.69 SPEAKER_00\n",
      "59.43 61.84 SPEAKER_00\n",
      "62.6 63.92 SPEAKER_00\n",
      "65.84 67.35 SPEAKER_00\n",
      "67.6 69.37 SPEAKER_00\n",
      "70.13 71.9 SPEAKER_00\n",
      "80.12 83.7 SPEAKER_00\n",
      "84.17 86.48 SPEAKER_00\n",
      "88.59 89.77 SPEAKER_00\n",
      "90.16 91.65 SPEAKER_00\n",
      "97.57 99.12 SPEAKER_00\n",
      "99.56 100.86 SPEAKER_00\n",
      "104.39 107.42 SPEAKER_00\n",
      "108.23 108.98 SPEAKER_00\n",
      "logs_chunk_4.json\n",
      "../../data/denoised/MYNBYT/T2/chunk_4.mp3\n",
      "1.41 2.22 SPEAKER_00\n",
      "6.06 7.71 SPEAKER_00\n",
      "10.24 11.57 SPEAKER_00\n",
      "17.87 19.37 SPEAKER_00\n",
      "22.41 23.5 SPEAKER_00\n",
      "33.29 34.52 SPEAKER_00\n",
      "36.8 37.93 SPEAKER_00\n",
      "40.04 41.53 SPEAKER_00\n",
      "42.74 44.23 SPEAKER_00\n",
      "50.52 53.12 SPEAKER_00\n",
      "64.26 65.3 SPEAKER_00\n",
      "69.83 75.04 SPEAKER_00\n",
      "78.52 80.63 SPEAKER_00\n",
      "81.49 85.03 SPEAKER_00\n",
      "87.75 91.22 SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "split_diarization(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from speechbrain.inference.speaker import SpeakerRecognition # type: ignore\n",
    "\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "\n",
    "anchor_path = '../../data/anchor'\n",
    "\n",
    "def compute_similarities_score(unverified_path, anchor_path):\n",
    "    scores = []\n",
    "    for audio in os.listdir(anchor_path):\n",
    "        audio_path = os.path.join(anchor_path, audio)\n",
    "        score, _ = verification.verify_files(unverified_path, audio_path)\n",
    "        scores.append(score)\n",
    "    return sum(scores)/len(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # df = pd.DataFrame(columns=['audio_path', 'diary_label', 'model_label', 'score', 'verified'])\n",
    "    # for path in os.listdir(folder_name):\n",
    "    #     d = {}\n",
    "    #     diary_label = path.split()[1]\n",
    "    #     audio_path = os.path.join(folder_name, path)\n",
    "    #     for anchor in os.listdir(anchor_path):\n",
    "    #         d[anchor] = compute_similarities_score(audio_path, os.path.join(anchor_path, anchor))\n",
    "    #     print(d, path)\n",
    "    #     \"\"\"\n",
    "    #     {'BichNgoc': tensor([-0.0291]), 'DucAnh': tensor([0.2324])} output SPEAKER_02 213.7 to 214.3.wav\"\"\"\n",
    "    #     max_key = max(d, key=lambda x: d[x].item())\n",
    "    #     df = df.append({'audio_path': audio_path, 'diary_label': diary_label, 'model_label': max_key, 'score': d[max_key].item(), 'verified': (d[max_key]>=0.25)}, ignore_index=True)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_speaker(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        split_diarization audio\n",
    "        anchor\n",
    "\n",
    "    Output:\n",
    "        verified_speaker\n",
    "            Nguoi phan xu\n",
    "                chunk_1.csv\n",
    "                ...        \n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/verified_speaker/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    \n",
    "    for sub_name in os.listdir(f'{data_path}/split_diary/{folder_name}'):    #chunk_1, chunk_2,...\n",
    "        df = pd.DataFrame(columns=['audio_path', 'diary_label', 'model_label', 'start', 'end', 'score', 'verified'])\n",
    "        sub_path = os.path.join(f'{data_path}/split_diary/{folder_name}', sub_name)\n",
    "        for file_name in os.listdir(sub_path):\n",
    "        \n",
    "            d = {}\n",
    "            audio_path = os.path.join(f'{sub_path}', file_name)\n",
    "            # print(audio_path)\n",
    "            diary_label = file_name.split(' ')[-1][:-4]\n",
    "            start, end = float(file_name.split()[0]), float(file_name.split()[1])\n",
    "            for anchor in os.listdir(anchor_path):\n",
    "                d[anchor] = compute_similarities_score(audio_path, os.path.join(anchor_path, anchor))\n",
    "            max_key = max(d, key=lambda x: d[x].item())\n",
    "            new_row = pd.DataFrame([{'audio_path': audio_path, 'diary_label': diary_label, 'model_label': max_key, 'start':start, 'end':end, 'score': d[max_key].item(), 'verified': (d[max_key]>=0.25)}])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df = df.sort_values(by='start')\n",
    "        df.to_csv(f'{data_path}/verified_speaker/{folder_name}/{sub_name}.csv', index=False)\n",
    "        print(f'{data_path}/verified_speaker/{folder_name}/{sub_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T2/chunk_3.csv\n",
      "../../data/verified_speaker/MYNBYT/T2/chunk_4.csv\n",
      "../../data/verified_speaker/MYNBYT/T2/chunk_0.csv\n",
      "../../data/verified_speaker/MYNBYT/T2/chunk_2.csv\n",
      "../../data/verified_speaker/MYNBYT/T2/chunk_1.csv\n"
     ]
    }
   ],
   "source": [
    "verify_speaker(folder_name)             # Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataframe:\n",
    "\taudio_path\t    diary_label\t    model_label\t    score\t    verified\t        start\n",
    "30\t/kaggle/...\t    SPEAKER_00\t    DucAnh\t        0.220918\t[tensor(False)]\t    7.0     \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Concat near audio files to one file\n",
    "Condition:\n",
    "    1. Must have same speaker\n",
    "    2. Must have a distance less than 0.5\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "# import argparse\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-df\", \"--data_frame\", type=str, default=0,\n",
    "# \thelp=\"path of data frame\")\n",
    "# ap.add_argument(\"-ap\", \"--audio_path\", type=str, default=0,\n",
    "#     help=\"path of audio file\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def concat_diary(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/concat_diary/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Load dataframe\n",
    "    for df_name in os.listdir(f'{data_path}/verified_speaker/{folder_name}'):   #chunk_4.csv\n",
    "\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end'])\n",
    "        df_path = os.path.join(f'{data_path}/verified_speaker/{folder_name}', df_name)\n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        ##\n",
    "        q = []\n",
    "        current_speaker = None\n",
    "        for _, row in df.iterrows():\n",
    "            if row['verified'] == 'tensor([True])': #phat hien nguoi noi dung\n",
    "                if not current_speaker:             # khoi tao\n",
    "                    current_speaker = row['model_label']\n",
    "                    q.append(row['start']), q.append(row['end'])\n",
    "                else:\n",
    "                    if row['model_label'] == current_speaker:\n",
    "                        q.append(row['end'])\n",
    "                    else:\n",
    "                        new_row = pd.DataFrame([{'audio_path': f'{data_path}/denoised/{df_name[:-4]}', 'model_label': current_speaker, 'start': q[0], 'end': q[-1]}])\n",
    "                        new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "                        current_speaker = row['model_label']\n",
    "                        q = []\n",
    "                        q.append(row['start']), q.append(row['end'])\n",
    "            else:\n",
    "                if len(q)>0:\n",
    "                    new_row = pd.DataFrame([{'audio_path': f'{data_path}/denoised/{df_name[:-4]}', 'model_label': current_speaker, 'start': q[0], 'end': q[-1]}])\n",
    "                    new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "                    q = []\n",
    "                    current_speaker= None\n",
    "                    q.append(row['start']), q.append(row['end'])\n",
    "                q = []\n",
    "                current_speaker = None\n",
    "        new_df.to_csv(f'{save_path}/{df_name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_diary(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_audio(audio_path, folder_name, q, current_speaker):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/concat_audio/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    start, end = q[0], q[-1]\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    segment = y[int(start*sr):int(end*sr)]\n",
    "    sf.write(f'{save_path}/{round(start,1)} {round(end,1)} {current_speaker}.wav', segment, sr)\n",
    "\n",
    "def concat_audio(folder_name):\n",
    "    data_path = '../../data'\n",
    "    # df = pd.DataFrame(columns=['audio_path', 'model_label', 'score', 'start', 'end'])\n",
    "    for dir in os.listdir(f'{data_path}/concat_diary/{folder_name}'):    #chunk_1, chunk_2,...\n",
    "        dir_path = os.path.join(f'{data_path}/concat_diary/{folder_name}', dir)\n",
    "        audio_path = os.path.join(f'{data_path}/denoised/{folder_name}', dir[:-4]+'.mp3')\n",
    "        print(dir_path, audio_path)\n",
    "        df = pd.read_csv(dir_path)\n",
    "        print(df)\n",
    "        for _, row in df.iterrows():\n",
    "            # print(f'{folder_name}/{dir}')\n",
    "            create_audio(audio_path, f'{folder_name}/{dir[:-4]}', [row['start'], row['end']], row['model_label'])\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_audio(folder_name)               # Step 5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"vinai/PhoWhisper-large\", device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        concat audio\n",
    "        \n",
    "    Output:\n",
    "        transcripted audio\n",
    "            audio_path, transcript, speaker\n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/transcriber/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for folder in os.listdir(f'{data_path}/concat_audio/{folder_name}'):\n",
    "        folder_path = os.path.join(f'{data_path}/concat_audio/{folder_name}', folder)\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end', 'script'])\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            script = transcriber(file_path)\n",
    "            start, end, speaker = file_name.split()[0],file_name.split()[1],file_name.split()[2][:-4]\n",
    "            new_row = pd.DataFrame([{'audio_path': file_path, 'model_label': speaker, 'start': start, 'end': end, 'script':script}])\n",
    "            new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "        new_df.to_csv(f'{save_path}/{folder}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/concat_audio/MYNBYT/T2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: create transcript func\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtranscript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m, in \u001b[0;36mtranscript\u001b[0;34m(folder_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_path):\n\u001b[1;32m     14\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(save_path)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/concat_audio/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     17\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/concat_audio/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, folder)\n\u001b[1;32m     19\u001b[0m     new_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_path\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/concat_audio/MYNBYT/T2'"
     ]
    }
   ],
   "source": [
    "# TODO: create transcript func\n",
    "transcript(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-20 07:14:17--  https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..kycRgHdnJlANzMbsbUhs9g.GWYcOMJEqidV2e7CcxL_tjVbj7nAf-YUh50KSs-jGA-_KgzJJUHmn-7DEdXZE_pItnkjr2sGUbR3y4LbubVtn_OJNXMfuDgbhAcaQ4N-BwdL-fiJZ8VxUQQbfCB8Zg-mu3gZUxmk12djyDFdeo7hug6KzbY1pFSK1EvJotzP6yS-LtoVj0OONfoqrC0ssjY_zV3NuCH-fcMev-wfIMl2yCEtUMkRgwjx68hK-_LR8wMdRF8kjjMldsLy0qqxtTbMZVHNGFJtBBnABkutTbJLYoCbQ7VxuR0efxo3jZrXbNDVCX8J_BucKkr-B3oK-nwdeW8MxryKEZUBp6ISOfD8990Yg0sSI25PhvrW3Y66rM7W__vzNCvAsiFZvnAXcGU0ryJi6p2Ol9AZAgm2hDH_fLRyt0A5ksP8nY3269hYbUhNS0tNbYpy4p-t0AYbLPt-oT1m9_2y3aQ9TRSKOBjvJ6MrYJmdKE_YWNFNsK4N1OmiORCOiS5C4-FY6zlSam5KUsZnXOPDdSzYbB3j7ajd42qLeDJ7Xx7lRFpOvz7V_0R_bw1xIfpMjrbMhEIjnfDE2H85otdFzmvDev1274tAeqVtWcwd6SNp6O4wH00m1wBfA3Kc8aah_Z9YLvWkpNHjrEbS-IAyLPf9iQwO_DcP5MoADCxXLg0E0mEv9sre5oU.4rPptLagIpP5xZNt90yZ_Q/phobert_fold5.pth\n",
      "Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n",
      "Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 540096685 (515M) [application/x-zip]\n",
      "Saving to: ‘phobert_fold5.pth’\n",
      "\n",
      "phobert_fold5.pth   100%[===================>] 515.08M  7.11MB/s    in 77s     \n",
      "\n",
      "2024-09-20 07:15:35 (6.68 MB/s) - ‘phobert_fold5.pth’ saved [540096685/540096685]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..kycRgHdnJlANzMbsbUhs9g.GWYcOMJEqidV2e7CcxL_tjVbj7nAf-YUh50KSs-jGA-_KgzJJUHmn-7DEdXZE_pItnkjr2sGUbR3y4LbubVtn_OJNXMfuDgbhAcaQ4N-BwdL-fiJZ8VxUQQbfCB8Zg-mu3gZUxmk12djyDFdeo7hug6KzbY1pFSK1EvJotzP6yS-LtoVj0OONfoqrC0ssjY_zV3NuCH-fcMev-wfIMl2yCEtUMkRgwjx68hK-_LR8wMdRF8kjjMldsLy0qqxtTbMZVHNGFJtBBnABkutTbJLYoCbQ7VxuR0efxo3jZrXbNDVCX8J_BucKkr-B3oK-nwdeW8MxryKEZUBp6ISOfD8990Yg0sSI25PhvrW3Y66rM7W__vzNCvAsiFZvnAXcGU0ryJi6p2Ol9AZAgm2hDH_fLRyt0A5ksP8nY3269hYbUhNS0tNbYpy4p-t0AYbLPt-oT1m9_2y3aQ9TRSKOBjvJ6MrYJmdKE_YWNFNsK4N1OmiORCOiS5C4-FY6zlSam5KUsZnXOPDdSzYbB3j7ajd42qLeDJ7Xx7lRFpOvz7V_0R_bw1xIfpMjrbMhEIjnfDE2H85otdFzmvDev1274tAeqVtWcwd6SNp6O4wH00m1wBfA3Kc8aah_Z9YLvWkpNHjrEbS-IAyLPf9iQwO_DcP5MoADCxXLg0E0mEv9sre5oU.4rPptLagIpP5xZNt90yZ_Q/phobert_fold5.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " concat_audio.py\t\t  'output 186.3 to 188.8.wav'\n",
      " create_diarization.py\t\t  'output 86.6 to 87.8.wav'\n",
      " denoise.py\t\t\t   phobert_fold5.pth\n",
      "'_e2e_speaker_label copy.ipynb'    pretrained_models\n",
      " _e2e_speaker_label.ipynb\t   __pycache__\n",
      " e2e_speaker_label.py\t\t   remove_collision.py\n",
      "'hierarchy tree.txt'\t\t   split_audio.py\n",
      "'output 104.6 to 105.4.wav'\t   temp.py\n",
      "'output 148.9 to 150.0.wav'\t   transcript.py\n",
      "'output 150.6 to 151.2.wav'\t   verify_speaker.py\n",
      "'output 152.3 to 152.9 ảngy.wav'\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        last_hidden_state, output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False # Dropout will errors if without this\n",
    "        )\n",
    "\n",
    "        x = self.drop(output)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-20 07:25:10--  https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..HkEQpkATUWOQR2L4A444Uw.qHq40kZoU9ZuZWfxfgL8zm-O2YzWPv3KpsoNlNbIpRJ9qE0LT90gQfHNmHOL7JcAXsRfRlwgvTxsD8_Zbxsr_6sEtfMG79_ZzT0WOUDGYa8pV8w1Wy3kLuegmKA4OKRC7RNYTt05U35ctsx0e-dAHetUQvTnOVpz9BQZiNDlIC8M4YUyEefyuXqANcmGZzrQ3uxJRzw_7u6g7QEqngkL0XL4PTt6IongZQYVbIs6oftalCekmMaEGofXEN2z4KmrKkuXN1POHMnhH58pml_fT7jMuR-qi3nBCJgv5jb-aUCGlXJ8FzO5mWUaa20T9MBJUA9KLQXByIhV4e3TxgS65AJ59ntmWVuMEADuNkyvDnF9kT8LOse7G-P6m9NChydaZYZ94Q6TGFpMfes6yvH_gfomvFTRB6dv79c2b-y3t-CLecbw-TMOZllx4_je9wXmCNBJs1VOlnCL5KuBvpR7KyZOFgZccu1WE2pVZSBeEOvEqpojEGedCoql94tqW1eCfCoflRoJIxmsXvwvWaiAeOghmNQGdSEJdYD0uyyf94W-oOp10AsvhMUyx1A-LAh1JCQ79gS_3XshTlDvyvvBGWzatBJlOG5yLS9cMOqiJKYcjNxPyTstvnDBg7EW2gPWhIQUpikblYlt_Fj4SGXebJNmm8bYyhy-cQzrK0wrhiY.RaNQ0i-wgcYw-VFgNoOr5A/phobert_fold4.pth\n",
      "Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n",
      "Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 540096685 (515M) [application/x-zip]\n",
      "Saving to: ‘phobert_fold4.pth’\n",
      "\n",
      "phobert_fold4.pth   100%[===================>] 515.08M  6.29MB/s    in 83s     \n",
      "\n",
      "2024-09-20 07:26:33 (6.23 MB/s) - ‘phobert_fold4.pth’ saved [540096685/540096685]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..HkEQpkATUWOQR2L4A444Uw.qHq40kZoU9ZuZWfxfgL8zm-O2YzWPv3KpsoNlNbIpRJ9qE0LT90gQfHNmHOL7JcAXsRfRlwgvTxsD8_Zbxsr_6sEtfMG79_ZzT0WOUDGYa8pV8w1Wy3kLuegmKA4OKRC7RNYTt05U35ctsx0e-dAHetUQvTnOVpz9BQZiNDlIC8M4YUyEefyuXqANcmGZzrQ3uxJRzw_7u6g7QEqngkL0XL4PTt6IongZQYVbIs6oftalCekmMaEGofXEN2z4KmrKkuXN1POHMnhH58pml_fT7jMuR-qi3nBCJgv5jb-aUCGlXJ8FzO5mWUaa20T9MBJUA9KLQXByIhV4e3TxgS65AJ59ntmWVuMEADuNkyvDnF9kT8LOse7G-P6m9NChydaZYZ94Q6TGFpMfes6yvH_gfomvFTRB6dv79c2b-y3t-CLecbw-TMOZllx4_je9wXmCNBJs1VOlnCL5KuBvpR7KyZOFgZccu1WE2pVZSBeEOvEqpojEGedCoql94tqW1eCfCoflRoJIxmsXvwvWaiAeOghmNQGdSEJdYD0uyyf94W-oOp10AsvhMUyx1A-LAh1JCQ79gS_3XshTlDvyvvBGWzatBJlOG5yLS9cMOqiJKYcjNxPyTstvnDBg7EW2gPWhIQUpikblYlt_Fj4SGXebJNmm8bYyhy-cQzrK0wrhiY.RaNQ0i-wgcYw-VFgNoOr5A/phobert_fold4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier(n_classes=7).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/1143647024.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/home/tuannd/tuanlha/EXpressiveTTS/src/speaker_diarization/phobert_fold4.pth'), strict=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('/home/tuannd/tuanlha/EXpressiveTTS/src/speaker_diarization/phobert_fold4.pth'), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "class_names = ['Enjoyment', 'Disgust', 'Sadness', 'Anger', 'Surprise', 'Fear', 'Other']\n",
    "\n",
    "def infer(text, tokenizer, max_len=120):\n",
    "    encoded_review = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_review['input_ids'].to(device)\n",
    "    attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "    output = model(input_ids, attention_mask)\n",
    "    _, y_pred = torch.max(output, dim=1)\n",
    "\n",
    "    print(f'Text: {text}')\n",
    "    print(f'Sentiment: {class_names[y_pred]}')\n",
    "    return class_names[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Cảm ơn bạn đã chạy thử model của mình. Chúc một ngày tốt lành nha!\n",
      "Sentiment: Enjoyment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Enjoyment'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer('Cảm ơn bạn đã chạy thử model của mình. Chúc một ngày tốt lành nha!', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_label(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/emotion_label/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for folder in os.listdir(f'{data_path}/transcriber/{folder_name}'):\n",
    "        folder_path = os.path.join(f'{data_path}/transcriber/{folder_name}', folder)\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end', 'script', 'emotion'])\n",
    "        df = pd.read_csv(folder_path)\n",
    "        # print(df)\n",
    "        for _, row in df.iterrows():\n",
    "            audio_path,model_label,start,end,script = row['audio_path'], row['model_label'], row['start'], row['end'], row['script']\n",
    "            emotion = infer(script, tokenizer)\n",
    "            new_row = pd.DataFrame([{'audio_path': audio_path, 'model_label': model_label, 'start': start, 'end': end, 'script':script, 'emotion': emotion}])\n",
    "            new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "        new_df.to_csv(f'{save_path}/{folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 'hôm qua ở spa có liên hoan.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'ờ đêm nay tao phải chạy đết lai nên chắc là về muộn nếu mà có gì mà hân say quá thì mày đưa hân về nhá.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'cô đi là đúng đấy chứ tuần trước a hà nội rét buốt lạnh lắm cô ạ vừa mưa phùn nồm ẩm.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'gọi để nhắc em là nhớ quá cỡ.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'em học nói giọng sài gòn ở trên mạng đó.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'dạ vâng đấy cháu cũng đã định bay vào thăm ông anh họ ở trong khu công nghiệp bình dương nhưng mà giá vé thế này thì khó quá bọn cháu lái taxi thế này ngày được vài trăm bây giờ mà đi thì mất một ngày công.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'vui thì ở lại lâu lâu một xíu nhá.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'hôm nay với ngày mai là em xin nghỉ nhà em có khách ở quê ra còn gì ơ thì thoa ơi hết mắm tôm rồi bảo cái nhung ra chợ mua đi nhung ra chợ mua mắm tôm cho mẹ bảo trong trong ví lấy tiền cho mẹ đi thôi.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'mày thì cứ tại sao lại nói với mẹ như thế hả.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'thôi chị dự luật đi nhá.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'mà cháu nghe nói từ ngày mùng một tháng ba.'}\n",
      "Sentiment: Enjoyment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 'thứ hai là khoái nào làm sao em biết được cũng có thể là đức anh hay là cái hân nó khoái nhầm thì sao.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'để đến nỗi đêm chồng con có về không con cũng không biết.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'làm gì đâu có đúng là gì mà đòi khác đâu.'}\n",
      "Sentiment: Disgust\n",
      "Text: {'text': 'còn cái thi này thắng nước anh đâu anh ấy đi làm từ tháng à mẹ.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'lúc đấy con hay đi về đêm xong vào sáng đi sớm chắc thân không biết.'}\n",
      "Sentiment: Fear\n",
      "Text: {'text': 'mang cái xích từ đầy nào đầy nào ra khóa cổng.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'cái cái trích dắt ngoài cửa là.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'mình bảo là như thế có điện không.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'chưa ở trong đây đông lắm rồi.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'may quá gì đi mất tiền đẹp không ấy anh ơi không từ từ để anh đây có gì em đưa anh đi bệnh viện kiểm tra xem mình kiểm tra chụp chiếu xem thương khớp hay là.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'em gọi chả đứa nào nghe máy cả.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'thôi mình ăn nhanh đi còn việc không thi làm nữa.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'cháu có chọn ra chú xin học cho ế buổi liền.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'mẹ này mười hai giờ đấy nhá đúng mười hai giờ mà không gửi mail thì cô đừng có trách đấy.'}\n",
      "Sentiment: Other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 'tí xong việc ở đây nhá em sẽ về công ty làm việc tiếp cho anh.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'thôi tập trung bây giờ tất cả các em hoàn thành phần việc của mình đúng hai tiếng nữa gửi email cho anh anh sẽ ở đây tổng hợp xử lý rồi gửi cho khách hàng anh em mình phải ăn chặt con điêu này.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'leo chốt phải gửi lúc mấy giờ là tết.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'vẫn phải cố gắng ở thực lực chứ.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'đây là lần đầu tiên mà em chỉ ra một xíu thôi em đi chơi bạn về tí em sẽ chặn elai cho anh.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'vâng vâng vâng em biết rồi ạ.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'thưởng lắm lắm chụp vì phát ngôn xuất sắc thật nhát hay nhát thật à này từ từ trừ với cái tiền đi muộn vẫn hôn nợ công ty chưa trả đâu.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'vừa kiếm được một cái rót rất ngon luôn anh đã gửi mail phân công công việc cho từng đứa rồi check mail luôn đi mình có đúng một đêm nay để làm bản kế hoạch chi tiết truyền thông cho khách hàng.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'trước bảy giờ sáng mai có như thắng anh đã làm việc riêng với trợ lý bên họ rồi.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'em đây em đây.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'bây giờ anh cho mày đúng ba mươi giây để trả lời đang ở đâu với ai làm gì.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'cháu định gọi cho cô để báo với cô là à hôm nay a phiến ngọc là phải tăng ca về muộn cô ạ dạ vâng dạ vâng ạ cô yên tâm đi ngủ trước đi ạ chào chào cô.anh chiều mày quá nên mày hư đúng không anh nhận mày vào công ty không phải là để nói dối mẹ xong rồi kiếm cớ đi chơi được nhé.'}\n",
      "Sentiment: Disgust\n"
     ]
    }
   ],
   "source": [
    "emotion_label(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TuanLHA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
