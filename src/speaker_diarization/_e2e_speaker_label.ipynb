{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Chunk audio\n",
    "    output: 1. chunked audio: audio file\n",
    "2. Denoise audio\n",
    "    output: 2.denoise audio: audio file\n",
    "3. Diarization\n",
    "    output: 3. diary: dataframe [columns: start, end, speaker]\n",
    "4. Speaker labeled from diary logs\n",
    "    output: 4. speaker labeled: dataframe [columns: audio_path, diary_label, model_label, score, verified]\n",
    "5. Concat near audio files to one file\n",
    "    output: 5. concatenated audio:  dataframe [columns: start. end, speaker]\n",
    "                                    audio file\n",
    "6. Audio speech recognition:\n",
    "    output: 6. transcript: dataframe [columns: audio_path, transcript, speaker]\n",
    "\"\"\"\n",
    "### 0. setup data\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-ap\", \"--audio_path\", type=str, default=0,\n",
    "#     help=\"path of audio file\")\n",
    "# ap.add_argument(\"-fn\", \"--folder_name\", type=str)\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "### 1. Chunk audio\n",
    "from split_audio import split_audio\n",
    "from denoise import denoise\n",
    "from create_diarization import create_diarization\n",
    "from remove_collision import remove_collision, split_diarization\n",
    "# from verify_speaker import verify_speaker\n",
    "# from concat_audio import concat_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/home/tuannd/tuanlha/EXpressiveTTS/data/audio/minh yeu nhau di.mp3'\n",
    "folder_name = 'MYNBYT/T1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_audio import split_audio\n",
    "split_audio(audio_path, folder_name)    # Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save chunk_4.mp3\n",
      "Save chunk_0.mp3\n",
      "Save chunk_5.mp3\n",
      "Save chunk_2.mp3\n",
      "Save chunk_1.mp3\n",
      "Save chunk_6.mp3\n",
      "Save chunk_3.mp3\n"
     ]
    }
   ],
   "source": [
    "from denoise import denoise\n",
    "denoise(folder_name)                    # Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display as disp\n",
    "import torch\n",
    "import torchaudio\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio\n",
    "import os\n",
    "\n",
    "def denoise(folder_name, get_audio = True):\n",
    "    model = pretrained.dns64().cuda()\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/denoised/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/chunk/{folder_name}'):    # file_name = chunk/yeunhaudi/chunk_{i}.mp3\n",
    "        file_path = os.path.join(f'{data_path}/chunk/{folder_name}', file_name)\n",
    "        wav, sr = torchaudio.load(file_path)\n",
    "        wav = convert_audio(wav.cuda(), sr, model.sample_rate, model.chin)\n",
    "        with torch.no_grad():\n",
    "            denoised = model(wav[None])[0]\n",
    "        if get_audio:\n",
    "            torchaudio.save(f'{save_path}/{file_name}', denoised.to('cpu'), sr)\n",
    "            print(f\"Save {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading diarization model...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "secret = \"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\"\n",
    "\n",
    "print(\"Loading diarization model...\")\n",
    "diarization = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=secret)\n",
    "\n",
    "\n",
    "diarization.to(torch.device(\"cuda\"))\n",
    "\n",
    "def create_diarization(folder_name):\n",
    "    # apply pretrained pipeline\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/diary/{folder_name}'\n",
    "\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/denoised/{folder_name}'):\n",
    "        file_path = os.path.join(f'{data_path}/denoised/{folder_name}', file_name)\n",
    "        diary = diarization(file_path)\n",
    "        with open(f'{save_path}/logs_{file_name[:-4]}.pkl', 'wb') as f:\n",
    "            pickle.dump(diary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3008) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2816) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1472) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1280) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3168) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2688) too large for available bit count (2384)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (840)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (736) too large for available bit count (656)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2528) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2208) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2656) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (928) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3488) too large for available bit count (3352)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1792) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1024) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1984) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2208) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2816) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2496) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1600) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2272) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2784) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1280) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (656)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (840)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1760) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3072) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1984) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2368) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2272) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2528) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2368) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2048) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2464) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1024) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2496) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2048) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2272) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2464) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2016) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1888) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1792) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2560) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2368) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1568) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1472) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1728) too large for available bit count (1704)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2240) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1984) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2240) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1824) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1216) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3008) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1472) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1312) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1472) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1760) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1568) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (656)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1984) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2016) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2016) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (832) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1568) too large for available bit count (1520)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2368) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (928) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1536) too large for available bit count (1520)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2848) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1504) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1824) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (608) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1280) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2688) too large for available bit count (2568)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1952) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3104) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1024) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1728) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1232)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1248) too large for available bit count (1232)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (384) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (448) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1920) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (416) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (704) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2304) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2592) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (320) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2080) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1632) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (576) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1696) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2272) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (896) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (960) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2464) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (992) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2144) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1664) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2432) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (256) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (800) too large for available bit count (656)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (544) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (640) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (512) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1024) too large for available bit count (944)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1120) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (928) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3072) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (864) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2528) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (288) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1376) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (352) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1152) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1056) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (672) too large for available bit count (472)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (768) too large for available bit count (760)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1440) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (192) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (480) too large for available bit count (368)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (224) too large for available bit count (184)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2336) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2048) too large for available bit count (1912)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1760) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3072) too large for available bit count (2776)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1824) too large for available bit count (1624)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1088) too large for available bit count (1048)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (2400) too large for available bit count (2200)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1344) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1408) too large for available bit count (1336)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (1184) too large for available bit count (1048)\n"
     ]
    }
   ],
   "source": [
    "create_diarization(folder_name)         # Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=1.0s stop=1.9s speaker_SPEAKER_00\n",
      "start=7.1s stop=8.0s speaker_SPEAKER_00\n",
      "start=8.3s stop=8.4s speaker_SPEAKER_00\n",
      "start=20.0s stop=21.9s speaker_SPEAKER_00\n",
      "start=28.3s stop=28.8s speaker_SPEAKER_00\n",
      "start=29.3s stop=29.7s speaker_SPEAKER_00\n",
      "start=30.7s stop=36.7s speaker_SPEAKER_04\n",
      "start=36.7s stop=42.6s speaker_SPEAKER_01\n",
      "start=43.0s stop=43.6s speaker_SPEAKER_01\n",
      "start=44.0s stop=46.4s speaker_SPEAKER_01\n",
      "start=47.2s stop=47.5s speaker_SPEAKER_01\n",
      "start=47.9s stop=48.3s speaker_SPEAKER_01\n",
      "start=48.3s stop=48.5s speaker_SPEAKER_00\n",
      "start=48.5s stop=49.0s speaker_SPEAKER_01\n",
      "start=49.0s stop=49.8s speaker_SPEAKER_00\n",
      "start=50.2s stop=50.5s speaker_SPEAKER_00\n",
      "start=52.7s stop=53.5s speaker_SPEAKER_00\n",
      "start=54.6s stop=55.7s speaker_SPEAKER_00\n",
      "start=55.7s stop=56.0s speaker_SPEAKER_00\n",
      "start=64.3s stop=64.6s speaker_SPEAKER_00\n",
      "start=71.9s stop=72.6s speaker_SPEAKER_02\n",
      "start=74.0s stop=75.0s speaker_SPEAKER_02\n",
      "start=75.5s stop=77.0s speaker_SPEAKER_02\n",
      "start=77.5s stop=80.5s speaker_SPEAKER_02\n",
      "start=80.9s stop=84.1s speaker_SPEAKER_02\n",
      "start=84.7s stop=86.0s speaker_SPEAKER_01\n",
      "start=86.6s stop=87.8s speaker_SPEAKER_02\n",
      "start=88.4s stop=89.9s speaker_SPEAKER_02\n",
      "start=95.3s stop=96.4s speaker_SPEAKER_04\n",
      "start=96.9s stop=98.0s speaker_SPEAKER_04\n",
      "start=98.5s stop=98.9s speaker_SPEAKER_02\n",
      "start=99.7s stop=101.4s speaker_SPEAKER_02\n",
      "start=102.4s stop=103.1s speaker_SPEAKER_04\n",
      "start=103.5s stop=104.0s speaker_SPEAKER_02\n",
      "start=104.6s stop=105.4s speaker_SPEAKER_02\n",
      "start=107.2s stop=108.1s speaker_SPEAKER_02\n",
      "start=108.5s stop=109.9s speaker_SPEAKER_02\n",
      "start=110.3s stop=111.0s speaker_SPEAKER_02\n",
      "start=111.5s stop=116.0s speaker_SPEAKER_02\n",
      "start=116.2s stop=117.2s speaker_SPEAKER_02\n",
      "start=121.0s stop=122.1s speaker_SPEAKER_02\n",
      "start=124.2s stop=130.5s speaker_SPEAKER_02\n",
      "start=130.7s stop=132.1s speaker_SPEAKER_02\n",
      "start=132.1s stop=132.3s speaker_SPEAKER_04\n",
      "start=137.3s stop=137.6s speaker_SPEAKER_00\n",
      "start=139.1s stop=139.2s speaker_SPEAKER_00\n",
      "start=139.2s stop=139.2s speaker_SPEAKER_00\n",
      "start=139.3s stop=139.7s speaker_SPEAKER_00\n",
      "start=140.2s stop=140.5s speaker_SPEAKER_00\n",
      "start=148.9s stop=150.0s speaker_SPEAKER_04\n",
      "start=150.6s stop=151.2s speaker_SPEAKER_04\n",
      "start=152.3s stop=152.9s speaker_SPEAKER_03\n",
      "start=156.0s stop=156.7s speaker_SPEAKER_04\n",
      "start=159.3s stop=163.1s speaker_SPEAKER_02\n",
      "start=170.1s stop=171.1s speaker_SPEAKER_00\n",
      "start=171.8s stop=173.2s speaker_SPEAKER_00\n",
      "start=172.3s stop=172.3s speaker_SPEAKER_01\n",
      "start=175.6s stop=176.4s speaker_SPEAKER_00\n",
      "start=176.4s stop=176.5s speaker_SPEAKER_01\n",
      "start=176.5s stop=179.6s speaker_SPEAKER_04\n",
      "start=176.5s stop=176.6s speaker_SPEAKER_01\n",
      "start=181.0s stop=181.6s speaker_SPEAKER_01\n",
      "start=182.1s stop=182.2s speaker_SPEAKER_01\n",
      "start=182.2s stop=182.2s speaker_SPEAKER_00\n",
      "start=182.2s stop=182.3s speaker_SPEAKER_04\n",
      "start=182.3s stop=182.4s speaker_SPEAKER_01\n",
      "start=183.9s stop=184.5s speaker_SPEAKER_04\n",
      "start=185.2s stop=185.9s speaker_SPEAKER_04\n",
      "start=186.4s stop=188.8s speaker_SPEAKER_04\n",
      "start=190.1s stop=190.5s speaker_SPEAKER_03\n",
      "start=190.6s stop=191.8s speaker_SPEAKER_04\n",
      "start=194.7s stop=195.1s speaker_SPEAKER_03\n",
      "start=196.9s stop=197.4s speaker_SPEAKER_03\n",
      "start=201.4s stop=201.9s speaker_SPEAKER_03\n",
      "start=203.2s stop=204.9s speaker_SPEAKER_03\n",
      "start=209.4s stop=212.7s speaker_SPEAKER_03\n",
      "start=213.7s stop=214.3s speaker_SPEAKER_03\n",
      "start=225.5s stop=227.5s speaker_SPEAKER_03\n",
      "start=228.1s stop=228.5s speaker_SPEAKER_03\n",
      "start=232.4s stop=233.8s speaker_SPEAKER_02\n",
      "start=234.7s stop=234.8s speaker_SPEAKER_03\n",
      "start=236.2s stop=240.2s speaker_SPEAKER_02\n",
      "start=241.9s stop=242.9s speaker_SPEAKER_04\n",
      "start=244.3s stop=244.4s speaker_SPEAKER_04\n",
      "start=244.4s stop=245.0s speaker_SPEAKER_01\n",
      "start=246.1s stop=248.1s speaker_SPEAKER_01\n",
      "start=248.5s stop=249.0s speaker_SPEAKER_01\n",
      "start=249.4s stop=250.6s speaker_SPEAKER_02\n",
      "start=251.4s stop=253.7s speaker_SPEAKER_02\n",
      "start=253.9s stop=255.5s speaker_SPEAKER_04\n",
      "start=255.9s stop=256.2s speaker_SPEAKER_04\n",
      "start=257.9s stop=257.9s speaker_SPEAKER_02\n",
      "start=257.9s stop=258.3s speaker_SPEAKER_03\n",
      "start=270.1s stop=271.8s speaker_SPEAKER_02\n",
      "start=272.3s stop=272.9s speaker_SPEAKER_02\n",
      "start=272.5s stop=273.6s speaker_SPEAKER_04\n",
      "start=274.2s stop=274.7s speaker_SPEAKER_04\n",
      "start=275.9s stop=277.6s speaker_SPEAKER_04\n",
      "start=290.0s stop=290.2s speaker_SPEAKER_00\n",
      "start=292.2s stop=294.0s speaker_SPEAKER_00\n",
      "start=298.0s stop=298.9s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/tuannd/tuanlha/EXpressiveTTS/data/diary/MYNBYT/T1/logs_chunk_0.pkl\"\n",
    "with open(path, 'rb') as file:\n",
    "    # Sử dụng pickle để tải đối tượng từ tệp\n",
    "    loaded_object = pickle.load(file)\n",
    "for turn, _, speaker in loaded_object.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import librosa\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def create_origin_logs(diarization):\n",
    "    logs = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        logs.append([round(turn.start,2), round(turn.end,2), speaker])\n",
    "    return logs\n",
    "\n",
    "def remove_collision(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/logs_no_col/{folder_name}'\n",
    "\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    for file_name in os.listdir(f'{data_path}/diary/{folder_name}'):\n",
    "        print(file_name)\n",
    "        file_path = os.path.join(f'{data_path}/diary/{folder_name}', file_name)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            diary = pickle.load(f)\n",
    "        origin_log = create_origin_logs(diary)\n",
    "        print(origin_log)\n",
    "        log = []\n",
    "        # Pre\n",
    "        if not origin_log:\n",
    "            with open(f'{save_path}/{file_name[:-4]}.json', 'w') as f:   \n",
    "            # /log_no_col/Yen nhau di/logs_chunk_1.json\n",
    "                json.dump(log, f)\n",
    "            continue\n",
    "\n",
    "        preivous = [origin_log[0][0], origin_log[0][1]]\n",
    "        last_end = origin_log[0][1]\n",
    "        if last_end < origin_log[1][0]:\n",
    "            log.append([preivous, origin_log[0][2]])\n",
    "        \n",
    "        # In\n",
    "        for i in range(1, len(origin_log)-1):\n",
    "            start, end = origin_log[i][0], origin_log[i][1]\n",
    "            if start < last_end:\n",
    "                last_end = max(last_end, end)\n",
    "            else:\n",
    "                if end > origin_log[i+1][0]:\n",
    "                    preivous = [start, end]\n",
    "                else:\n",
    "                    preivous = [start, end]\n",
    "                    if end-start > 1:\n",
    "                        log.append([[start, end], origin_log[i][2]])\n",
    "        \n",
    "        # End\n",
    "        if origin_log[-1][0] > last_end+1:\n",
    "            if origin_log[-1][1] - origin_log[-1][0]>0.1:\n",
    "                log.append([[origin_log[-1][0], origin_log[-1][1]], origin_log[-1][2]])\n",
    "\n",
    "        # Save\n",
    "        with open(f'{save_path}/{file_name[:-4]}.json', 'w') as f:   \n",
    "            # /log_no_col/Yen nhau di/logs_chunk_1.json\n",
    "            json.dump(log, f)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_chunk_4.pkl\n",
      "[[0.03, 0.89, 'SPEAKER_02'], [3.86, 5.03, 'SPEAKER_02'], [5.09, 5.43, 'SPEAKER_02'], [6.78, 9.19, 'SPEAKER_02'], [9.8, 11.15, 'SPEAKER_02'], [11.74, 13.18, 'SPEAKER_02'], [14.07, 15.3, 'SPEAKER_02'], [24.45, 25.04, 'SPEAKER_02'], [26.44, 26.93, 'SPEAKER_02'], [28.5, 29.26, 'SPEAKER_02'], [31.99, 32.19, 'SPEAKER_02'], [34.15, 35.62, 'SPEAKER_02'], [39.16, 40.35, 'SPEAKER_03'], [39.43, 39.5, 'SPEAKER_02'], [39.54, 39.74, 'SPEAKER_02'], [42.08, 42.89, 'SPEAKER_03'], [42.99, 43.03, 'SPEAKER_03'], [43.06, 43.91, 'SPEAKER_03'], [43.97, 44.06, 'SPEAKER_03'], [44.11, 44.63, 'SPEAKER_03'], [45.37, 47.45, 'SPEAKER_03'], [47.5, 47.92, 'SPEAKER_03'], [50.89, 51.13, 'SPEAKER_03'], [51.72, 53.74, 'SPEAKER_02'], [53.05, 53.69, 'SPEAKER_03'], [61.1, 62.4, 'SPEAKER_03'], [69.96, 70.35, 'SPEAKER_02'], [71.23, 73.27, 'SPEAKER_02'], [73.27, 73.35, 'SPEAKER_01'], [73.93, 74.89, 'SPEAKER_02'], [76.22, 77.03, 'SPEAKER_02'], [77.03, 77.47, 'SPEAKER_01'], [77.88, 79.02, 'SPEAKER_01'], [79.43, 85.0, 'SPEAKER_01'], [87.78, 88.24, 'SPEAKER_02'], [88.49, 89.4, 'SPEAKER_02'], [90.33, 91.43, 'SPEAKER_02'], [92.07, 95.22, 'SPEAKER_02'], [97.92, 100.3, 'SPEAKER_02'], [121.36, 123.0, 'SPEAKER_03'], [128.47, 129.19, 'SPEAKER_02'], [130.56, 131.5, 'SPEAKER_02'], [133.75, 134.22, 'SPEAKER_02'], [135.44, 136.55, 'SPEAKER_02'], [137.34, 138.3, 'SPEAKER_02'], [141.29, 143.67, 'SPEAKER_02'], [144.13, 144.78, 'SPEAKER_02'], [146.03, 146.71, 'SPEAKER_02'], [147.99, 148.83, 'SPEAKER_01'], [162.54, 163.09, 'SPEAKER_01'], [163.47, 165.46, 'SPEAKER_01'], [166.3, 167.58, 'SPEAKER_01'], [167.84, 167.92, 'SPEAKER_01'], [169.14, 169.42, 'SPEAKER_00'], [169.42, 169.49, 'SPEAKER_01'], [169.49, 170.84, 'SPEAKER_00'], [170.84, 170.86, 'SPEAKER_02'], [170.86, 170.87, 'SPEAKER_00'], [171.5, 172.04, 'SPEAKER_01'], [172.04, 173.1, 'SPEAKER_02'], [174.64, 175.62, 'SPEAKER_02'], [177.47, 177.62, 'SPEAKER_02'], [178.77, 179.11, 'SPEAKER_02'], [179.56, 179.88, 'SPEAKER_02'], [179.95, 180.04, 'SPEAKER_02'], [180.53, 181.25, 'SPEAKER_02'], [185.08, 185.49, 'SPEAKER_02'], [186.45, 188.41, 'SPEAKER_02'], [194.4, 194.9, 'SPEAKER_02'], [199.86, 201.15, 'SPEAKER_02'], [206.13, 206.85, 'SPEAKER_03'], [211.42, 212.25, 'SPEAKER_03'], [227.98, 228.48, 'SPEAKER_03'], [230.97, 231.03, 'SPEAKER_03'], [232.47, 241.77, 'SPEAKER_00'], [242.36, 242.71, 'SPEAKER_00'], [244.09, 244.9, 'SPEAKER_00'], [244.9, 244.94, 'SPEAKER_01'], [244.94, 244.97, 'SPEAKER_00'], [244.97, 247.03, 'SPEAKER_01'], [247.03, 247.79, 'SPEAKER_02'], [254.96, 255.43, 'SPEAKER_02'], [256.97, 257.49, 'SPEAKER_02'], [262.35, 263.01, 'SPEAKER_03'], [265.24, 266.15, 'SPEAKER_02'], [266.5, 268.5, 'SPEAKER_02'], [268.68, 269.02, 'SPEAKER_02'], [269.22, 269.85, 'SPEAKER_02'], [270.4, 272.92, 'SPEAKER_02'], [273.81, 274.06, 'SPEAKER_02'], [275.73, 275.75, 'SPEAKER_03'], [275.75, 275.97, 'SPEAKER_02'], [275.97, 276.04, 'SPEAKER_03'], [276.04, 276.21, 'SPEAKER_02'], [279.13, 280.17, 'SPEAKER_02'], [280.34, 281.66, 'SPEAKER_02'], [282.33, 282.74, 'SPEAKER_02'], [283.02, 283.43, 'SPEAKER_02'], [283.53, 284.07, 'SPEAKER_02'], [284.71, 285.08, 'SPEAKER_02'], [285.71, 286.06, 'SPEAKER_02'], [286.3, 286.74, 'SPEAKER_02'], [287.31, 288.19, 'SPEAKER_02'], [288.34, 289.17, 'SPEAKER_02'], [289.96, 290.31, 'SPEAKER_02'], [290.87, 291.33, 'SPEAKER_02'], [292.14, 292.15, 'SPEAKER_02'], [292.15, 292.17, 'SPEAKER_03'], [292.17, 292.42, 'SPEAKER_02'], [293.23, 293.27, 'SPEAKER_03'], [293.27, 293.45, 'SPEAKER_02'], [294.09, 294.97, 'SPEAKER_02'], [296.98, 297.55, 'SPEAKER_02'], [297.96, 298.47, 'SPEAKER_02'], [298.97, 299.92, 'SPEAKER_02'], [299.95, 299.97, 'SPEAKER_02']]\n",
      "logs_chunk_5.pkl\n",
      "[[1.09, 4.47, 'SPEAKER_01'], [5.36, 6.19, 'SPEAKER_01'], [6.61, 7.41, 'SPEAKER_01'], [8.0, 9.28, 'SPEAKER_01'], [10.02, 10.63, 'SPEAKER_01'], [12.84, 13.09, 'SPEAKER_01'], [14.29, 15.25, 'SPEAKER_01'], [15.74, 16.25, 'SPEAKER_03'], [17.04, 18.41, 'SPEAKER_03'], [19.96, 20.69, 'SPEAKER_01'], [21.09, 22.17, 'SPEAKER_03'], [24.57, 25.48, 'SPEAKER_01'], [25.95, 27.12, 'SPEAKER_01'], [27.5, 28.13, 'SPEAKER_01'], [28.62, 30.15, 'SPEAKER_01'], [31.3, 32.45, 'SPEAKER_01'], [32.6, 34.37, 'SPEAKER_01'], [35.0, 36.26, 'SPEAKER_01'], [36.97, 37.29, 'SPEAKER_01'], [38.02, 42.17, 'SPEAKER_01'], [42.81, 43.53, 'SPEAKER_01'], [43.82, 46.35, 'SPEAKER_01'], [47.01, 50.62, 'SPEAKER_03'], [53.0, 54.45, 'SPEAKER_01'], [54.96, 56.07, 'SPEAKER_01'], [56.7, 57.47, 'SPEAKER_01'], [65.69, 65.71, 'SPEAKER_05'], [65.71, 67.45, 'SPEAKER_01'], [68.12, 69.78, 'SPEAKER_01'], [69.93, 72.15, 'SPEAKER_03'], [72.56, 73.72, 'SPEAKER_01'], [74.08, 76.37, 'SPEAKER_01'], [76.37, 76.39, 'SPEAKER_05'], [84.49, 84.51, 'SPEAKER_05'], [84.51, 85.87, 'SPEAKER_01'], [86.3, 87.17, 'SPEAKER_01'], [87.71, 90.3, 'SPEAKER_01'], [91.51, 91.88, 'SPEAKER_01'], [94.23, 96.98, 'SPEAKER_01'], [97.48, 98.55, 'SPEAKER_01'], [99.02, 101.45, 'SPEAKER_01'], [101.65, 103.15, 'SPEAKER_01'], [103.74, 104.15, 'SPEAKER_01'], [105.03, 107.91, 'SPEAKER_01'], [108.54, 110.76, 'SPEAKER_03'], [111.3, 111.71, 'SPEAKER_03'], [112.01, 114.09, 'SPEAKER_01'], [115.42, 116.94, 'SPEAKER_01'], [118.7, 120.23, 'SPEAKER_01'], [120.67, 121.35, 'SPEAKER_01'], [122.12, 125.02, 'SPEAKER_01'], [126.02, 126.78, 'SPEAKER_01'], [127.25, 128.53, 'SPEAKER_01'], [128.53, 128.55, 'SPEAKER_05'], [129.38, 129.7, 'SPEAKER_05'], [142.14, 142.15, 'SPEAKER_05'], [142.15, 142.68, 'SPEAKER_00'], [142.68, 142.71, 'SPEAKER_05'], [143.86, 143.87, 'SPEAKER_05'], [143.87, 146.66, 'SPEAKER_00'], [147.6, 150.37, 'SPEAKER_00'], [150.66, 155.01, 'SPEAKER_00'], [153.83, 154.18, 'SPEAKER_03'], [154.72, 156.16, 'SPEAKER_03'], [162.32, 163.3, 'SPEAKER_05'], [163.3, 163.31, 'SPEAKER_01'], [167.77, 171.89, 'SPEAKER_01'], [173.12, 175.85, 'SPEAKER_03'], [177.64, 177.67, 'SPEAKER_01'], [177.67, 178.16, 'SPEAKER_05'], [178.16, 178.18, 'SPEAKER_01'], [179.87, 180.96, 'SPEAKER_05'], [183.87, 184.09, 'SPEAKER_02'], [188.02, 188.31, 'SPEAKER_02'], [194.73, 197.33, 'SPEAKER_04'], [200.66, 203.54, 'SPEAKER_04'], [206.48, 209.08, 'SPEAKER_04'], [211.17, 211.96, 'SPEAKER_04'], [212.34, 213.31, 'SPEAKER_04'], [213.77, 215.42, 'SPEAKER_04'], [217.9, 217.92, 'SPEAKER_04'], [217.92, 236.01, 'SPEAKER_03'], [239.2, 239.25, 'SPEAKER_04'], [239.25, 239.96, 'SPEAKER_03'], [241.41, 241.43, 'SPEAKER_04'], [241.43, 251.86, 'SPEAKER_03'], [253.07, 255.65, 'SPEAKER_03'], [255.97, 263.96, 'SPEAKER_03'], [264.55, 267.33, 'SPEAKER_03'], [267.97, 268.26, 'SPEAKER_02'], [268.34, 273.29, 'SPEAKER_03'], [273.59, 279.08, 'SPEAKER_03'], [279.18, 282.11, 'SPEAKER_03'], [283.55, 283.72, 'SPEAKER_02'], [284.1, 284.29, 'SPEAKER_02'], [285.88, 287.4, 'SPEAKER_02'], [289.15, 289.27, 'SPEAKER_02']]\n",
      "logs_chunk_3.pkl\n",
      "[[1.8, 6.11, 'SPEAKER_03'], [7.52, 10.11, 'SPEAKER_03'], [15.37, 20.13, 'SPEAKER_03'], [20.33, 20.79, 'SPEAKER_03'], [23.98, 24.63, 'SPEAKER_00'], [27.05, 28.36, 'SPEAKER_00'], [31.77, 33.9, 'SPEAKER_00'], [34.54, 34.89, 'SPEAKER_00'], [35.79, 39.03, 'SPEAKER_00'], [49.19, 58.01, 'SPEAKER_00'], [60.38, 60.51, 'SPEAKER_00'], [61.47, 61.51, 'SPEAKER_00'], [61.56, 63.26, 'SPEAKER_00'], [65.67, 65.76, 'SPEAKER_00'], [68.71, 69.51, 'SPEAKER_00'], [71.18, 71.58, 'SPEAKER_00'], [76.69, 76.78, 'SPEAKER_03'], [77.59, 78.08, 'SPEAKER_03'], [79.17, 80.47, 'SPEAKER_00'], [82.28, 83.04, 'SPEAKER_00'], [83.87, 87.14, 'SPEAKER_00'], [88.56, 89.74, 'SPEAKER_03'], [90.77, 90.89, 'SPEAKER_03'], [91.11, 91.29, 'SPEAKER_03'], [91.83, 92.44, 'SPEAKER_03'], [92.89, 93.96, 'SPEAKER_03'], [96.51, 97.53, 'SPEAKER_03'], [97.97, 98.97, 'SPEAKER_03'], [98.99, 106.53, 'SPEAKER_03'], [107.36, 108.64, 'SPEAKER_03'], [107.52, 107.85, 'SPEAKER_00'], [109.79, 110.24, 'SPEAKER_03'], [110.73, 111.95, 'SPEAKER_03'], [113.89, 116.55, 'SPEAKER_03'], [114.49, 114.66, 'SPEAKER_00'], [120.45, 121.92, 'SPEAKER_03'], [121.94, 122.36, 'SPEAKER_03'], [122.68, 125.61, 'SPEAKER_03'], [127.81, 128.65, 'SPEAKER_03'], [130.76, 132.09, 'SPEAKER_03'], [132.09, 132.16, 'SPEAKER_00'], [132.26, 132.5, 'SPEAKER_00'], [133.55, 134.29, 'SPEAKER_00'], [143.37, 144.48, 'SPEAKER_03'], [144.89, 145.27, 'SPEAKER_00'], [146.73, 146.93, 'SPEAKER_03'], [146.93, 147.11, 'SPEAKER_00'], [147.67, 148.19, 'SPEAKER_00'], [148.58, 149.04, 'SPEAKER_00'], [167.35, 167.89, 'SPEAKER_00'], [169.44, 171.35, 'SPEAKER_00'], [179.6, 180.09, 'SPEAKER_00'], [205.06, 205.5, 'SPEAKER_00'], [206.07, 206.55, 'SPEAKER_00'], [206.55, 206.56, 'SPEAKER_01'], [208.05, 209.53, 'SPEAKER_02'], [210.26, 211.26, 'SPEAKER_01'], [212.55, 214.31, 'SPEAKER_01'], [215.22, 216.99, 'SPEAKER_01'], [218.41, 218.83, 'SPEAKER_01'], [219.19, 219.66, 'SPEAKER_01'], [220.0, 221.65, 'SPEAKER_01'], [222.06, 222.7, 'SPEAKER_01'], [222.7, 223.14, 'SPEAKER_02'], [223.84, 224.82, 'SPEAKER_02'], [226.51, 227.29, 'SPEAKER_02'], [228.0, 229.7, 'SPEAKER_02'], [229.78, 230.71, 'SPEAKER_02'], [231.98, 234.07, 'SPEAKER_01'], [234.32, 235.79, 'SPEAKER_01'], [236.43, 236.65, 'SPEAKER_01'], [237.43, 238.15, 'SPEAKER_01'], [238.58, 240.01, 'SPEAKER_01'], [240.55, 242.64, 'SPEAKER_01'], [242.79, 244.7, 'SPEAKER_01'], [245.28, 245.83, 'SPEAKER_02'], [246.2, 247.55, 'SPEAKER_02'], [248.62, 251.01, 'SPEAKER_02'], [252.21, 253.48, 'SPEAKER_02'], [254.08, 254.47, 'SPEAKER_02'], [257.91, 258.61, 'SPEAKER_02'], [259.3, 260.99, 'SPEAKER_02'], [261.63, 264.12, 'SPEAKER_02'], [265.14, 266.37, 'SPEAKER_01'], [266.37, 266.4, 'SPEAKER_02'], [267.69, 271.01, 'SPEAKER_01'], [271.7, 274.28, 'SPEAKER_01'], [274.57, 275.46, 'SPEAKER_02'], [276.0, 278.28, 'SPEAKER_02'], [278.82, 280.11, 'SPEAKER_02'], [281.27, 282.11, 'SPEAKER_02'], [282.7, 283.28, 'SPEAKER_02'], [284.04, 285.17, 'SPEAKER_02'], [286.32, 287.87, 'SPEAKER_02'], [288.34, 288.86, 'SPEAKER_01'], [291.61, 292.41, 'SPEAKER_02'], [292.96, 294.16, 'SPEAKER_02'], [294.26, 295.56, 'SPEAKER_02'], [295.66, 295.73, 'SPEAKER_02'], [295.73, 295.9, 'SPEAKER_01'], [295.9, 295.97, 'SPEAKER_02'], [295.97, 296.17, 'SPEAKER_03'], [296.17, 297.15, 'SPEAKER_02'], [297.45, 298.79, 'SPEAKER_02'], [298.97, 299.26, 'SPEAKER_02'], [299.46, 299.97, 'SPEAKER_02']]\n",
      "logs_chunk_2.pkl\n",
      "[[0.74, 1.57, 'SPEAKER_00'], [2.02, 3.71, 'SPEAKER_00'], [4.37, 5.62, 'SPEAKER_00'], [6.04, 6.33, 'SPEAKER_00'], [6.51, 8.59, 'SPEAKER_00'], [8.91, 9.89, 'SPEAKER_00'], [10.48, 11.03, 'SPEAKER_00'], [11.59, 12.52, 'SPEAKER_00'], [12.52, 12.97, 'SPEAKER_01'], [13.6, 14.29, 'SPEAKER_01'], [15.03, 18.07, 'SPEAKER_01'], [18.69, 20.38, 'SPEAKER_01'], [21.04, 24.92, 'SPEAKER_01'], [24.92, 32.18, 'SPEAKER_00'], [32.67, 37.29, 'SPEAKER_00'], [38.34, 39.96, 'SPEAKER_01'], [39.96, 40.43, 'SPEAKER_00'], [44.29, 44.88, 'SPEAKER_02'], [45.9, 47.15, 'SPEAKER_02'], [52.48, 53.0, 'SPEAKER_02'], [53.88, 54.79, 'SPEAKER_02'], [55.7, 58.44, 'SPEAKER_02'], [59.68, 61.27, 'SPEAKER_02'], [62.2, 64.22, 'SPEAKER_02'], [65.24, 66.3, 'SPEAKER_02'], [67.99, 68.44, 'SPEAKER_02'], [72.34, 73.29, 'SPEAKER_02'], [76.95, 82.53, 'SPEAKER_02'], [104.93, 105.89, 'SPEAKER_06'], [108.13, 108.4, 'SPEAKER_06'], [113.55, 114.66, 'SPEAKER_06'], [118.76, 119.0, 'SPEAKER_06'], [126.53, 126.95, 'SPEAKER_06'], [128.11, 128.53, 'SPEAKER_06'], [130.19, 130.44, 'SPEAKER_06'], [132.18, 132.5, 'SPEAKER_06'], [138.36, 139.01, 'SPEAKER_06'], [142.12, 143.15, 'SPEAKER_06'], [143.2, 143.42, 'SPEAKER_06'], [148.65, 148.77, 'SPEAKER_06'], [155.72, 155.74, 'SPEAKER_02'], [155.74, 156.87, 'SPEAKER_05'], [156.87, 156.88, 'SPEAKER_02'], [156.88, 158.86, 'SPEAKER_04'], [159.99, 161.74, 'SPEAKER_05'], [162.52, 164.85, 'SPEAKER_05'], [166.64, 168.04, 'SPEAKER_05'], [168.65, 170.08, 'SPEAKER_05'], [171.01, 172.51, 'SPEAKER_05'], [172.68, 173.81, 'SPEAKER_05'], [178.57, 182.26, 'SPEAKER_05'], [182.92, 184.1, 'SPEAKER_05'], [183.56, 184.32, 'SPEAKER_03'], [185.39, 185.81, 'SPEAKER_03'], [186.15, 188.68, 'SPEAKER_03'], [188.95, 190.97, 'SPEAKER_03'], [190.97, 191.22, 'SPEAKER_05'], [191.22, 191.24, 'SPEAKER_03'], [191.34, 191.43, 'SPEAKER_05'], [191.43, 191.46, 'SPEAKER_03'], [191.46, 194.09, 'SPEAKER_05'], [195.14, 200.81, 'SPEAKER_05'], [201.52, 201.74, 'SPEAKER_05'], [202.6, 204.02, 'SPEAKER_05'], [204.89, 206.46, 'SPEAKER_05'], [207.69, 208.44, 'SPEAKER_02'], [208.44, 208.47, 'SPEAKER_03'], [209.28, 210.78, 'SPEAKER_03'], [211.66, 212.28, 'SPEAKER_03'], [213.09, 215.79, 'SPEAKER_03'], [215.88, 219.51, 'SPEAKER_03'], [220.4, 220.55, 'SPEAKER_03'], [221.43, 229.89, 'SPEAKER_04'], [230.75, 231.61, 'SPEAKER_04'], [231.94, 239.72, 'SPEAKER_04'], [241.51, 242.59, 'SPEAKER_05'], [242.98, 244.7, 'SPEAKER_05'], [244.97, 247.38, 'SPEAKER_05'], [247.98, 249.09, 'SPEAKER_05'], [249.39, 251.1, 'SPEAKER_05'], [251.1, 252.41, 'SPEAKER_02'], [252.68, 253.09, 'SPEAKER_02'], [256.5, 256.85, 'SPEAKER_06'], [265.98, 266.42, 'SPEAKER_06'], [267.28, 267.48, 'SPEAKER_06'], [294.89, 295.34, 'SPEAKER_06']]\n",
      "logs_chunk_0.pkl\n",
      "[[1.04, 1.87, 'SPEAKER_00'], [7.05, 7.96, 'SPEAKER_00'], [8.32, 8.37, 'SPEAKER_00'], [19.98, 21.87, 'SPEAKER_00'], [28.33, 28.82, 'SPEAKER_00'], [29.29, 29.73, 'SPEAKER_00'], [30.66, 36.73, 'SPEAKER_04'], [36.73, 42.59, 'SPEAKER_01'], [42.99, 43.55, 'SPEAKER_01'], [44.01, 46.37, 'SPEAKER_01'], [47.21, 47.5, 'SPEAKER_01'], [47.89, 48.26, 'SPEAKER_01'], [48.26, 48.51, 'SPEAKER_00'], [48.51, 49.04, 'SPEAKER_01'], [49.04, 49.76, 'SPEAKER_00'], [50.18, 50.52, 'SPEAKER_00'], [52.75, 53.52, 'SPEAKER_00'], [54.6, 55.72, 'SPEAKER_00'], [55.74, 56.04, 'SPEAKER_00'], [64.27, 64.63, 'SPEAKER_00'], [71.85, 72.61, 'SPEAKER_02'], [74.03, 74.99, 'SPEAKER_02'], [75.5, 76.98, 'SPEAKER_02'], [77.52, 80.47, 'SPEAKER_02'], [80.88, 84.05, 'SPEAKER_02'], [84.73, 86.04, 'SPEAKER_01'], [86.62, 87.83, 'SPEAKER_02'], [88.41, 89.87, 'SPEAKER_02'], [95.31, 96.42, 'SPEAKER_04'], [96.86, 98.04, 'SPEAKER_04'], [98.51, 98.9, 'SPEAKER_02'], [99.68, 101.38, 'SPEAKER_02'], [102.41, 103.09, 'SPEAKER_04'], [103.47, 104.0, 'SPEAKER_02'], [104.61, 105.4, 'SPEAKER_02'], [107.15, 108.13, 'SPEAKER_02'], [108.54, 109.87, 'SPEAKER_02'], [110.33, 110.98, 'SPEAKER_02'], [111.47, 115.96, 'SPEAKER_02'], [116.16, 117.16, 'SPEAKER_02'], [120.99, 122.12, 'SPEAKER_02'], [124.2, 130.51, 'SPEAKER_02'], [130.68, 132.09, 'SPEAKER_02'], [132.09, 132.33, 'SPEAKER_04'], [137.34, 137.63, 'SPEAKER_00'], [139.13, 139.18, 'SPEAKER_00'], [139.22, 139.23, 'SPEAKER_00'], [139.27, 139.72, 'SPEAKER_00'], [140.25, 140.52, 'SPEAKER_00'], [148.87, 150.02, 'SPEAKER_04'], [150.62, 151.23, 'SPEAKER_04'], [152.26, 152.88, 'SPEAKER_03'], [155.97, 156.7, 'SPEAKER_04'], [159.28, 163.14, 'SPEAKER_02'], [170.06, 171.13, 'SPEAKER_00'], [171.84, 173.22, 'SPEAKER_00'], [172.31, 172.34, 'SPEAKER_01'], [175.56, 176.44, 'SPEAKER_00'], [176.44, 176.49, 'SPEAKER_01'], [176.49, 179.61, 'SPEAKER_04'], [176.53, 176.56, 'SPEAKER_01'], [181.05, 181.57, 'SPEAKER_01'], [182.13, 182.16, 'SPEAKER_01'], [182.16, 182.18, 'SPEAKER_00'], [182.18, 182.35, 'SPEAKER_04'], [182.35, 182.37, 'SPEAKER_01'], [183.93, 184.54, 'SPEAKER_04'], [185.18, 185.89, 'SPEAKER_04'], [186.36, 188.83, 'SPEAKER_04'], [190.09, 190.48, 'SPEAKER_03'], [190.6, 191.85, 'SPEAKER_04'], [194.7, 195.11, 'SPEAKER_03'], [196.93, 197.37, 'SPEAKER_03'], [201.37, 201.92, 'SPEAKER_03'], [203.21, 204.88, 'SPEAKER_03'], [209.38, 212.72, 'SPEAKER_03'], [213.72, 214.31, 'SPEAKER_03'], [225.48, 227.54, 'SPEAKER_03'], [228.13, 228.54, 'SPEAKER_03'], [232.42, 233.82, 'SPEAKER_02'], [234.73, 234.8, 'SPEAKER_03'], [236.2, 240.23, 'SPEAKER_02'], [241.87, 242.9, 'SPEAKER_04'], [244.35, 244.38, 'SPEAKER_04'], [244.38, 244.97, 'SPEAKER_01'], [246.07, 248.06, 'SPEAKER_01'], [248.48, 248.95, 'SPEAKER_01'], [249.43, 250.64, 'SPEAKER_02'], [251.35, 253.7, 'SPEAKER_02'], [253.92, 255.5, 'SPEAKER_04'], [255.89, 256.21, 'SPEAKER_04'], [257.91, 257.93, 'SPEAKER_02'], [257.93, 258.27, 'SPEAKER_03'], [270.12, 271.84, 'SPEAKER_02'], [272.34, 272.87, 'SPEAKER_02'], [272.48, 273.56, 'SPEAKER_04'], [274.17, 274.71, 'SPEAKER_04'], [275.87, 277.61, 'SPEAKER_04'], [290.04, 290.25, 'SPEAKER_00'], [292.17, 294.01, 'SPEAKER_00'], [298.01, 298.85, 'SPEAKER_00']]\n",
      "logs_chunk_6.pkl\n",
      "[]\n",
      "logs_chunk_1.pkl\n",
      "[[1.41, 1.85, 'SPEAKER_02'], [2.93, 3.73, 'SPEAKER_02'], [4.45, 6.43, 'SPEAKER_02'], [7.14, 9.4, 'SPEAKER_02'], [10.39, 11.66, 'SPEAKER_01'], [12.11, 12.84, 'SPEAKER_01'], [13.04, 14.05, 'SPEAKER_01'], [14.53, 15.61, 'SPEAKER_04'], [16.03, 16.08, 'SPEAKER_04'], [16.08, 16.11, 'SPEAKER_01'], [16.11, 16.53, 'SPEAKER_04'], [29.11, 29.83, 'SPEAKER_04'], [31.2, 31.6, 'SPEAKER_04'], [33.06, 33.54, 'SPEAKER_04'], [33.63, 34.03, 'SPEAKER_04'], [34.03, 34.3, 'SPEAKER_01'], [34.3, 34.34, 'SPEAKER_04'], [34.47, 34.52, 'SPEAKER_04'], [34.52, 35.18, 'SPEAKER_01'], [36.13, 36.48, 'SPEAKER_04'], [36.7, 37.16, 'SPEAKER_01'], [38.08, 38.86, 'SPEAKER_01'], [39.74, 40.28, 'SPEAKER_01'], [40.28, 40.58, 'SPEAKER_03'], [40.94, 42.13, 'SPEAKER_03'], [42.18, 43.01, 'SPEAKER_01'], [43.94, 45.56, 'SPEAKER_03'], [45.36, 46.99, 'SPEAKER_01'], [46.18, 46.37, 'SPEAKER_03'], [47.74, 49.26, 'SPEAKER_03'], [49.09, 51.8, 'SPEAKER_01'], [53.09, 54.55, 'SPEAKER_01'], [54.87, 55.14, 'SPEAKER_01'], [55.72, 55.74, 'SPEAKER_04'], [55.74, 55.77, 'SPEAKER_01'], [55.77, 55.92, 'SPEAKER_04'], [55.92, 56.36, 'SPEAKER_01'], [56.66, 57.17, 'SPEAKER_01'], [57.78, 57.79, 'SPEAKER_01'], [57.79, 57.98, 'SPEAKER_04'], [58.1, 58.89, 'SPEAKER_04'], [59.33, 60.0, 'SPEAKER_04'], [60.66, 62.74, 'SPEAKER_04'], [63.85, 64.76, 'SPEAKER_01'], [64.83, 65.56, 'SPEAKER_01'], [65.89, 66.38, 'SPEAKER_01'], [67.5, 67.83, 'SPEAKER_01'], [68.73, 69.56, 'SPEAKER_01'], [70.32, 70.7, 'SPEAKER_01'], [70.7, 70.72, 'SPEAKER_04'], [71.23, 71.75, 'SPEAKER_03'], [72.37, 73.18, 'SPEAKER_03'], [73.59, 75.82, 'SPEAKER_03'], [78.09, 78.43, 'SPEAKER_04'], [86.7, 88.3, 'SPEAKER_04'], [87.27, 87.65, 'SPEAKER_00'], [87.65, 87.7, 'SPEAKER_01'], [89.55, 90.41, 'SPEAKER_04'], [92.03, 92.88, 'SPEAKER_01'], [92.88, 92.89, 'SPEAKER_04'], [93.45, 94.87, 'SPEAKER_01'], [94.87, 94.89, 'SPEAKER_04'], [95.51, 95.78, 'SPEAKER_04'], [96.39, 97.4, 'SPEAKER_04'], [99.02, 99.81, 'SPEAKER_04'], [102.41, 104.08, 'SPEAKER_04'], [105.36, 106.28, 'SPEAKER_04'], [106.9, 107.09, 'SPEAKER_04'], [107.19, 108.1, 'SPEAKER_04'], [108.96, 109.68, 'SPEAKER_04'], [117.8, 118.16, 'SPEAKER_04'], [120.47, 120.94, 'SPEAKER_04'], [121.43, 121.94, 'SPEAKER_04'], [122.63, 123.17, 'SPEAKER_04'], [124.69, 125.36, 'SPEAKER_04'], [125.78, 126.27, 'SPEAKER_04'], [133.88, 134.64, 'SPEAKER_04'], [137.02, 137.39, 'SPEAKER_04'], [137.63, 139.45, 'SPEAKER_04'], [142.47, 142.98, 'SPEAKER_04'], [142.98, 143.01, 'SPEAKER_03'], [147.54, 155.89, 'SPEAKER_03'], [157.0, 157.91, 'SPEAKER_03'], [158.22, 159.03, 'SPEAKER_03'], [159.53, 160.28, 'SPEAKER_03'], [162.32, 162.44, 'SPEAKER_03'], [164.19, 166.72, 'SPEAKER_04'], [168.16, 168.73, 'SPEAKER_04'], [169.57, 170.69, 'SPEAKER_04'], [171.75, 172.14, 'SPEAKER_04'], [176.58, 177.0, 'SPEAKER_04'], [177.44, 179.41, 'SPEAKER_04'], [180.83, 182.21, 'SPEAKER_02'], [182.57, 184.41, 'SPEAKER_04'], [186.26, 188.0, 'SPEAKER_02'], [188.54, 189.54, 'SPEAKER_02'], [190.3, 191.09, 'SPEAKER_04'], [192.05, 192.51, 'SPEAKER_04'], [193.0, 193.03, 'SPEAKER_04'], [193.11, 193.81, 'SPEAKER_04'], [194.97, 196.95, 'SPEAKER_04'], [219.93, 220.17, 'SPEAKER_03'], [245.92, 248.72, 'SPEAKER_03'], [259.03, 259.89, 'SPEAKER_04'], [265.56, 266.03, 'SPEAKER_04'], [266.03, 267.01, 'SPEAKER_02'], [267.85, 268.65, 'SPEAKER_00'], [269.31, 271.47, 'SPEAKER_00'], [271.62, 272.19, 'SPEAKER_02'], [272.88, 279.72, 'SPEAKER_02'], [280.11, 283.04, 'SPEAKER_02'], [283.73, 284.04, 'SPEAKER_02'], [284.04, 284.32, 'SPEAKER_00'], [284.32, 284.36, 'SPEAKER_02'], [286.79, 287.51, 'SPEAKER_00'], [288.12, 289.39, 'SPEAKER_00'], [290.3, 294.53, 'SPEAKER_00'], [295.43, 299.97, 'SPEAKER_00']]\n"
     ]
    }
   ],
   "source": [
    "remove_collision(folder_name)\n",
    "\n",
    "#TODO: fix split_diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def split_diarization(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        logs_no_collision\n",
    "        audio_path\n",
    "    Output:\n",
    "        split_diary\n",
    "            Nguoi phan xu\n",
    "                chunk_1\n",
    "                    output 0.0 to 1.0.wav\n",
    "                    output 1.0 to 2.0.wav\n",
    "                chunk_2...\n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/split_diary/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "\n",
    "    for file_name in os.listdir(f'{data_path}/logs_no_col/{folder_name}'):\n",
    "        print(file_name)\n",
    "        with open(f'{data_path}/logs_no_col/{folder_name}/{file_name}', 'r') as f:\n",
    "            logs = json.load(f)\n",
    "        audio_path = f'{data_path}/denoised/{folder_name}/{file_name[5:-5]}.mp3'\n",
    "        print(audio_path)\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        for log in logs:\n",
    "            start, end, speaker = log[0][0], log[0][1], log[1]\n",
    "            print(start, end, speaker)\n",
    "            segment = y[int(start*sr):int(end*sr)]\n",
    "\n",
    "            if not os.path.exists(f'{save_path}/{file_name[5:-5]}'):\n",
    "                os.makedirs(f'{save_path}/{file_name[5:-5]}')\n",
    "\n",
    "            sf.write(f'{save_path}/{file_name[5:-5]}/{round(start,1)} {round(end,1)} {speaker}.wav', segment, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_chunk_3.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_3.mp3\n",
      "1.8 6.11 SPEAKER_03\n",
      "7.52 10.11 SPEAKER_03\n",
      "15.37 20.13 SPEAKER_03\n",
      "27.05 28.36 SPEAKER_00\n",
      "31.77 33.9 SPEAKER_00\n",
      "35.79 39.03 SPEAKER_00\n",
      "49.19 58.01 SPEAKER_00\n",
      "61.56 63.26 SPEAKER_00\n",
      "79.17 80.47 SPEAKER_00\n",
      "83.87 87.14 SPEAKER_00\n",
      "88.56 89.74 SPEAKER_03\n",
      "92.89 93.96 SPEAKER_03\n",
      "96.51 97.53 SPEAKER_03\n",
      "98.99 106.53 SPEAKER_03\n",
      "110.73 111.95 SPEAKER_03\n",
      "120.45 121.92 SPEAKER_03\n",
      "122.68 125.61 SPEAKER_03\n",
      "130.76 132.09 SPEAKER_03\n",
      "143.37 144.48 SPEAKER_03\n",
      "169.44 171.35 SPEAKER_00\n",
      "208.05 209.53 SPEAKER_02\n",
      "212.55 214.31 SPEAKER_01\n",
      "215.22 216.99 SPEAKER_01\n",
      "220.0 221.65 SPEAKER_01\n",
      "228.0 229.7 SPEAKER_02\n",
      "231.98 234.07 SPEAKER_01\n",
      "234.32 235.79 SPEAKER_01\n",
      "238.58 240.01 SPEAKER_01\n",
      "240.55 242.64 SPEAKER_01\n",
      "242.79 244.7 SPEAKER_01\n",
      "246.2 247.55 SPEAKER_02\n",
      "248.62 251.01 SPEAKER_02\n",
      "252.21 253.48 SPEAKER_02\n",
      "259.3 260.99 SPEAKER_02\n",
      "261.63 264.12 SPEAKER_02\n",
      "265.14 266.37 SPEAKER_01\n",
      "267.69 271.01 SPEAKER_01\n",
      "271.7 274.28 SPEAKER_01\n",
      "276.0 278.28 SPEAKER_02\n",
      "278.82 280.11 SPEAKER_02\n",
      "284.04 285.17 SPEAKER_02\n",
      "286.32 287.87 SPEAKER_02\n",
      "292.96 294.16 SPEAKER_02\n",
      "294.26 295.56 SPEAKER_02\n",
      "297.45 298.79 SPEAKER_02\n",
      "299.46 299.97 SPEAKER_02\n",
      "logs_chunk_5.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_5.mp3\n",
      "1.09 4.47 SPEAKER_01\n",
      "8.0 9.28 SPEAKER_01\n",
      "17.04 18.41 SPEAKER_03\n",
      "21.09 22.17 SPEAKER_03\n",
      "25.95 27.12 SPEAKER_01\n",
      "28.62 30.15 SPEAKER_01\n",
      "31.3 32.45 SPEAKER_01\n",
      "32.6 34.37 SPEAKER_01\n",
      "35.0 36.26 SPEAKER_01\n",
      "38.02 42.17 SPEAKER_01\n",
      "43.82 46.35 SPEAKER_01\n",
      "47.01 50.62 SPEAKER_03\n",
      "53.0 54.45 SPEAKER_01\n",
      "54.96 56.07 SPEAKER_01\n",
      "65.71 67.45 SPEAKER_01\n",
      "68.12 69.78 SPEAKER_01\n",
      "69.93 72.15 SPEAKER_03\n",
      "72.56 73.72 SPEAKER_01\n",
      "74.08 76.37 SPEAKER_01\n",
      "84.51 85.87 SPEAKER_01\n",
      "87.71 90.3 SPEAKER_01\n",
      "94.23 96.98 SPEAKER_01\n",
      "97.48 98.55 SPEAKER_01\n",
      "99.02 101.45 SPEAKER_01\n",
      "101.65 103.15 SPEAKER_01\n",
      "105.03 107.91 SPEAKER_01\n",
      "108.54 110.76 SPEAKER_03\n",
      "112.01 114.09 SPEAKER_01\n",
      "115.42 116.94 SPEAKER_01\n",
      "118.7 120.23 SPEAKER_01\n",
      "122.12 125.02 SPEAKER_01\n",
      "127.25 128.53 SPEAKER_01\n",
      "143.87 146.66 SPEAKER_00\n",
      "147.6 150.37 SPEAKER_00\n",
      "154.72 156.16 SPEAKER_03\n",
      "167.77 171.89 SPEAKER_01\n",
      "173.12 175.85 SPEAKER_03\n",
      "179.87 180.96 SPEAKER_05\n",
      "194.73 197.33 SPEAKER_04\n",
      "200.66 203.54 SPEAKER_04\n",
      "206.48 209.08 SPEAKER_04\n",
      "213.77 215.42 SPEAKER_04\n",
      "217.92 236.01 SPEAKER_03\n",
      "241.43 251.86 SPEAKER_03\n",
      "253.07 255.65 SPEAKER_03\n",
      "255.97 263.96 SPEAKER_03\n",
      "264.55 267.33 SPEAKER_03\n",
      "268.34 273.29 SPEAKER_03\n",
      "273.59 279.08 SPEAKER_03\n",
      "279.18 282.11 SPEAKER_03\n",
      "285.88 287.4 SPEAKER_02\n",
      "289.15 289.27 SPEAKER_02\n",
      "logs_chunk_2.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_2.mp3\n",
      "0.74 1.57 SPEAKER_00\n",
      "2.02 3.71 SPEAKER_00\n",
      "4.37 5.62 SPEAKER_00\n",
      "6.51 8.59 SPEAKER_00\n",
      "15.03 18.07 SPEAKER_01\n",
      "18.69 20.38 SPEAKER_01\n",
      "21.04 24.92 SPEAKER_01\n",
      "24.92 32.18 SPEAKER_00\n",
      "32.67 37.29 SPEAKER_00\n",
      "38.34 39.96 SPEAKER_01\n",
      "45.9 47.15 SPEAKER_02\n",
      "55.7 58.44 SPEAKER_02\n",
      "59.68 61.27 SPEAKER_02\n",
      "62.2 64.22 SPEAKER_02\n",
      "65.24 66.3 SPEAKER_02\n",
      "76.95 82.53 SPEAKER_02\n",
      "113.55 114.66 SPEAKER_06\n",
      "142.12 143.15 SPEAKER_06\n",
      "155.74 156.87 SPEAKER_05\n",
      "156.88 158.86 SPEAKER_04\n",
      "159.99 161.74 SPEAKER_05\n",
      "162.52 164.85 SPEAKER_05\n",
      "166.64 168.04 SPEAKER_05\n",
      "168.65 170.08 SPEAKER_05\n",
      "171.01 172.51 SPEAKER_05\n",
      "172.68 173.81 SPEAKER_05\n",
      "178.57 182.26 SPEAKER_05\n",
      "186.15 188.68 SPEAKER_03\n",
      "188.95 190.97 SPEAKER_03\n",
      "191.46 194.09 SPEAKER_05\n",
      "195.14 200.81 SPEAKER_05\n",
      "202.6 204.02 SPEAKER_05\n",
      "204.89 206.46 SPEAKER_05\n",
      "209.28 210.78 SPEAKER_03\n",
      "213.09 215.79 SPEAKER_03\n",
      "215.88 219.51 SPEAKER_03\n",
      "221.43 229.89 SPEAKER_04\n",
      "231.94 239.72 SPEAKER_04\n",
      "241.51 242.59 SPEAKER_05\n",
      "242.98 244.7 SPEAKER_05\n",
      "244.97 247.38 SPEAKER_05\n",
      "247.98 249.09 SPEAKER_05\n",
      "249.39 251.1 SPEAKER_05\n",
      "251.1 252.41 SPEAKER_02\n",
      "294.89 295.34 SPEAKER_06\n",
      "logs_chunk_1.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_1.mp3\n",
      "1.41 1.85 SPEAKER_02\n",
      "4.45 6.43 SPEAKER_02\n",
      "7.14 9.4 SPEAKER_02\n",
      "10.39 11.66 SPEAKER_01\n",
      "13.04 14.05 SPEAKER_01\n",
      "14.53 15.61 SPEAKER_04\n",
      "40.94 42.13 SPEAKER_03\n",
      "49.09 51.8 SPEAKER_01\n",
      "53.09 54.55 SPEAKER_01\n",
      "60.66 62.74 SPEAKER_04\n",
      "73.59 75.82 SPEAKER_03\n",
      "93.45 94.87 SPEAKER_01\n",
      "96.39 97.4 SPEAKER_04\n",
      "102.41 104.08 SPEAKER_04\n",
      "137.63 139.45 SPEAKER_04\n",
      "147.54 155.89 SPEAKER_03\n",
      "164.19 166.72 SPEAKER_04\n",
      "169.57 170.69 SPEAKER_04\n",
      "177.44 179.41 SPEAKER_04\n",
      "180.83 182.21 SPEAKER_02\n",
      "182.57 184.41 SPEAKER_04\n",
      "186.26 188.0 SPEAKER_02\n",
      "194.97 196.95 SPEAKER_04\n",
      "245.92 248.72 SPEAKER_03\n",
      "269.31 271.47 SPEAKER_00\n",
      "272.88 279.72 SPEAKER_02\n",
      "280.11 283.04 SPEAKER_02\n",
      "288.12 289.39 SPEAKER_00\n",
      "290.3 294.53 SPEAKER_00\n",
      "295.43 299.97 SPEAKER_00\n",
      "logs_chunk_0.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_0.mp3\n",
      "1.04 1.87 SPEAKER_00\n",
      "19.98 21.87 SPEAKER_00\n",
      "30.66 36.73 SPEAKER_04\n",
      "36.73 42.59 SPEAKER_01\n",
      "44.01 46.37 SPEAKER_01\n",
      "54.6 55.72 SPEAKER_00\n",
      "75.5 76.98 SPEAKER_02\n",
      "77.52 80.47 SPEAKER_02\n",
      "80.88 84.05 SPEAKER_02\n",
      "84.73 86.04 SPEAKER_01\n",
      "86.62 87.83 SPEAKER_02\n",
      "88.41 89.87 SPEAKER_02\n",
      "95.31 96.42 SPEAKER_04\n",
      "96.86 98.04 SPEAKER_04\n",
      "99.68 101.38 SPEAKER_02\n",
      "108.54 109.87 SPEAKER_02\n",
      "111.47 115.96 SPEAKER_02\n",
      "120.99 122.12 SPEAKER_02\n",
      "124.2 130.51 SPEAKER_02\n",
      "130.68 132.09 SPEAKER_02\n",
      "148.87 150.02 SPEAKER_04\n",
      "159.28 163.14 SPEAKER_02\n",
      "170.06 171.13 SPEAKER_00\n",
      "186.36 188.83 SPEAKER_04\n",
      "190.6 191.85 SPEAKER_04\n",
      "203.21 204.88 SPEAKER_03\n",
      "209.38 212.72 SPEAKER_03\n",
      "225.48 227.54 SPEAKER_03\n",
      "232.42 233.82 SPEAKER_02\n",
      "236.2 240.23 SPEAKER_02\n",
      "241.87 242.9 SPEAKER_04\n",
      "246.07 248.06 SPEAKER_01\n",
      "249.43 250.64 SPEAKER_02\n",
      "251.35 253.7 SPEAKER_02\n",
      "253.92 255.5 SPEAKER_04\n",
      "270.12 271.84 SPEAKER_02\n",
      "272.48 273.56 SPEAKER_04\n",
      "275.87 277.61 SPEAKER_04\n",
      "292.17 294.01 SPEAKER_00\n",
      "298.01 298.85 SPEAKER_00\n",
      "logs_chunk_4.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_4.mp3\n",
      "0.03 0.89 SPEAKER_02\n",
      "3.86 5.03 SPEAKER_02\n",
      "6.78 9.19 SPEAKER_02\n",
      "9.8 11.15 SPEAKER_02\n",
      "11.74 13.18 SPEAKER_02\n",
      "14.07 15.3 SPEAKER_02\n",
      "34.15 35.62 SPEAKER_02\n",
      "45.37 47.45 SPEAKER_03\n",
      "61.1 62.4 SPEAKER_03\n",
      "71.23 73.27 SPEAKER_02\n",
      "77.88 79.02 SPEAKER_01\n",
      "79.43 85.0 SPEAKER_01\n",
      "90.33 91.43 SPEAKER_02\n",
      "92.07 95.22 SPEAKER_02\n",
      "97.92 100.3 SPEAKER_02\n",
      "121.36 123.0 SPEAKER_03\n",
      "135.44 136.55 SPEAKER_02\n",
      "141.29 143.67 SPEAKER_02\n",
      "163.47 165.46 SPEAKER_01\n",
      "166.3 167.58 SPEAKER_01\n",
      "169.49 170.84 SPEAKER_00\n",
      "172.04 173.1 SPEAKER_02\n",
      "186.45 188.41 SPEAKER_02\n",
      "199.86 201.15 SPEAKER_02\n",
      "232.47 241.77 SPEAKER_00\n",
      "244.97 247.03 SPEAKER_01\n",
      "266.5 268.5 SPEAKER_02\n",
      "270.4 272.92 SPEAKER_02\n",
      "279.13 280.17 SPEAKER_02\n",
      "280.34 281.66 SPEAKER_02\n",
      "logs_chunk_6.json\n",
      "../../data/denoised/MYNBYT/T1/chunk_6.mp3\n"
     ]
    }
   ],
   "source": [
    "split_diarization(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/speechbrain/utils/checkpoints.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from speechbrain.inference.speaker import SpeakerRecognition # type: ignore\n",
    "\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "\n",
    "anchor_path = '../../data/anchor'\n",
    "\n",
    "def compute_similarities_score(unverified_path, anchor_path):\n",
    "    scores = []\n",
    "    for audio in os.listdir(anchor_path):\n",
    "        audio_path = os.path.join(anchor_path, audio)\n",
    "        score, _ = verification.verify_files(unverified_path, audio_path)\n",
    "        scores.append(score)\n",
    "    return sum(scores)/len(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # df = pd.DataFrame(columns=['audio_path', 'diary_label', 'model_label', 'score', 'verified'])\n",
    "    # for path in os.listdir(folder_name):\n",
    "    #     d = {}\n",
    "    #     diary_label = path.split()[1]\n",
    "    #     audio_path = os.path.join(folder_name, path)\n",
    "    #     for anchor in os.listdir(anchor_path):\n",
    "    #         d[anchor] = compute_similarities_score(audio_path, os.path.join(anchor_path, anchor))\n",
    "    #     print(d, path)\n",
    "    #     \"\"\"\n",
    "    #     {'BichNgoc': tensor([-0.0291]), 'DucAnh': tensor([0.2324])} output SPEAKER_02 213.7 to 214.3.wav\"\"\"\n",
    "    #     max_key = max(d, key=lambda x: d[x].item())\n",
    "    #     df = df.append({'audio_path': audio_path, 'diary_label': diary_label, 'model_label': max_key, 'score': d[max_key].item(), 'verified': (d[max_key]>=0.25)}, ignore_index=True)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_speaker(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        split_diarization audio\n",
    "        anchor\n",
    "\n",
    "    Output:\n",
    "        verified_speaker\n",
    "            Nguoi phan xu\n",
    "                chunk_1.csv\n",
    "                ...        \n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/verified_speaker/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    \n",
    "    for sub_name in os.listdir(f'{data_path}/split_diary/{folder_name}'):    #chunk_1, chunk_2,...\n",
    "        df = pd.DataFrame(columns=['audio_path', 'diary_label', 'model_label', 'start', 'end', 'score', 'verified'])\n",
    "        sub_path = os.path.join(f'{data_path}/split_diary/{folder_name}', sub_name)\n",
    "        for file_name in os.listdir(sub_path):\n",
    "        \n",
    "            d = {}\n",
    "            audio_path = os.path.join(f'{sub_path}', file_name)\n",
    "            # print(audio_path)\n",
    "            diary_label = file_name.split(' ')[-1][:-4]\n",
    "            start, end = float(file_name.split()[0]), float(file_name.split()[1])\n",
    "            for anchor in os.listdir(anchor_path):\n",
    "                d[anchor] = compute_similarities_score(audio_path, os.path.join(anchor_path, anchor))\n",
    "            max_key = max(d, key=lambda x: d[x].item())\n",
    "            new_row = pd.DataFrame([{'audio_path': audio_path, 'diary_label': diary_label, 'model_label': max_key, 'start':start, 'end':end, 'score': d[max_key].item(), 'verified': (d[max_key]>=0.25)}])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df = df.sort_values(by='start')\n",
    "        df.to_csv(f'{data_path}/verified_speaker/{sub_name}.csv', index=False)\n",
    "        print(f'{data_path}/verified_speaker/{folder_name}/{sub_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38460/667558666.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/verified_speaker/MYNBYT/T1/chunk_1.csv\n"
     ]
    }
   ],
   "source": [
    "verify_speaker(folder_name)             # Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataframe:\n",
    "\taudio_path\t    diary_label\t    model_label\t    score\t    verified\t        start\n",
    "30\t/kaggle/...\t    SPEAKER_00\t    DucAnh\t        0.220918\t[tensor(False)]\t    7.0     \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Concat near audio files to one file\n",
    "Condition:\n",
    "    1. Must have same speaker\n",
    "    2. Must have a distance less than 0.5\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "# import argparse\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-df\", \"--data_frame\", type=str, default=0,\n",
    "# \thelp=\"path of data frame\")\n",
    "# ap.add_argument(\"-ap\", \"--audio_path\", type=str, default=0,\n",
    "#     help=\"path of audio file\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def concat_diary(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/concat_diary/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Load dataframe\n",
    "    for df_name in os.listdir(f'{data_path}/verified_speaker/{folder_name}'):   #chunk_4.csv\n",
    "\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end'])\n",
    "        df_path = os.path.join(f'{data_path}/verified_speaker/{folder_name}', df_name)\n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        ##\n",
    "        q = []\n",
    "        current_speaker = None\n",
    "        for _, row in df.iterrows():\n",
    "            if row['verified'] == 'tensor([True])': #phat hien nguoi noi dung\n",
    "                if not current_speaker:             # khoi tao\n",
    "                    current_speaker = row['model_label']\n",
    "                    q.append(row['start']), q.append(row['end'])\n",
    "                else:\n",
    "                    if row['model_label'] == current_speaker:\n",
    "                        q.append(row['end'])\n",
    "                    else:\n",
    "                        new_row = pd.DataFrame([{'audio_path': f'{data_path}/denoised/{df_name[:-4]}', 'model_label': current_speaker, 'start': q[0], 'end': q[-1]}])\n",
    "                        new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "                        current_speaker = row['model_label']\n",
    "                        q = []\n",
    "                        q.append(row['start']), q.append(row['end'])\n",
    "            else:\n",
    "                if len(q)>0:\n",
    "                    new_row = pd.DataFrame([{'audio_path': f'{data_path}/denoised/{df_name[:-4]}', 'model_label': current_speaker, 'start': q[0], 'end': q[-1]}])\n",
    "                    new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "                    q = []\n",
    "                    current_speaker= None\n",
    "                    q.append(row['start']), q.append(row['end'])\n",
    "                q = []\n",
    "                current_speaker = None\n",
    "        new_df.to_csv(f'{save_path}/{df_name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_8134/1765111984.py:101: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "concat_diary(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_audio(audio_path, folder_name, q, current_speaker):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/concat_audio/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    start, end = q[0], q[-1]\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    segment = y[int(start*sr):int(end*sr)]\n",
    "    sf.write(f'{save_path}/{round(start,1)} {round(end,1)} {current_speaker}.wav', segment, sr)\n",
    "\n",
    "def concat_audio(folder_name):\n",
    "    data_path = '../../data'\n",
    "    # df = pd.DataFrame(columns=['audio_path', 'model_label', 'score', 'start', 'end'])\n",
    "    for dir in os.listdir(f'{data_path}/concat_diary/{folder_name}'):    #chunk_1, chunk_2,...\n",
    "        dir_path = os.path.join(f'{data_path}/concat_diary/{folder_name}', dir)\n",
    "        audio_path = os.path.join(f'{data_path}/denoised/{folder_name}', dir[:-4]+'.mp3')\n",
    "        print(dir_path, audio_path)\n",
    "        df = pd.read_csv(dir_path)\n",
    "        print(df)\n",
    "        for _, row in df.iterrows():\n",
    "            # print(f'{folder_name}/{dir}')\n",
    "            create_audio(audio_path, f'{folder_name}/{dir[:-4]}', [row['start'], row['end']], row['model_label'])\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/concat_diary/MYNBYT/T1/chunk_4.csv ../../data/denoised/MYNBYT/T1/chunk_4.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_4    BichNgoc  163.5  165.5\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_1.csv ../../data/denoised/MYNBYT/T1/chunk_1.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_1      DucAnh    4.5    9.4\n",
      "1           1  ../../data/denoised/chunk_1      DucAnh  186.3  188.0\n",
      "2           2  ../../data/denoised/chunk_1      DucAnh  272.9  279.7\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_2.csv ../../data/denoised/MYNBYT/T1/chunk_2.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_2      DucAnh    6.5    8.6\n",
      "1           1  ../../data/denoised/chunk_2      DucAnh   24.9   37.3\n",
      "2           2  ../../data/denoised/chunk_2    BichNgoc   55.7   58.4\n",
      "3           3  ../../data/denoised/chunk_2    BichNgoc  156.9  158.9\n",
      "4           4  ../../data/denoised/chunk_2    BichNgoc  162.5  164.8\n",
      "5           5  ../../data/denoised/chunk_2    BichNgoc  188.9  194.1\n",
      "6           6  ../../data/denoised/chunk_2    BichNgoc  215.9  229.9\n",
      "7           7  ../../data/denoised/chunk_2    BichNgoc  248.0  249.1\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_5.csv ../../data/denoised/MYNBYT/T1/chunk_5.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_5    BichNgoc   32.6   36.3\n",
      "1           1  ../../data/denoised/chunk_5      DucAnh   47.0   50.6\n",
      "2           2  ../../data/denoised/chunk_5      DucAnh   69.9   72.2\n",
      "3           3  ../../data/denoised/chunk_5    BichNgoc   87.7   90.3\n",
      "4           4  ../../data/denoised/chunk_5    BichNgoc   99.0  101.5\n",
      "5           5  ../../data/denoised/chunk_5      DucAnh  108.5  110.8\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_3.csv ../../data/denoised/MYNBYT/T1/chunk_3.mp3\n",
      "   Unnamed: 0                   audio_path model_label  start    end\n",
      "0           0  ../../data/denoised/chunk_3      DucAnh   99.0  106.5\n",
      "1           1  ../../data/denoised/chunk_3    BichNgoc  220.0  221.7\n",
      "2           2  ../../data/denoised/chunk_3    BichNgoc  242.8  244.7\n",
      "3           3  ../../data/denoised/chunk_3      DucAnh  293.0  294.2\n",
      "../../data/concat_diary/MYNBYT/T1/chunk_0.csv ../../data/denoised/MYNBYT/T1/chunk_0.mp3\n",
      "    Unnamed: 0                   audio_path model_label  start    end\n",
      "0            0  ../../data/denoised/chunk_0      DucAnh   75.5   84.0\n",
      "1            1  ../../data/denoised/chunk_0    BichNgoc   84.7   86.0\n",
      "2            2  ../../data/denoised/chunk_0      DucAnh   86.6   89.9\n",
      "3            3  ../../data/denoised/chunk_0    BichNgoc   96.9   98.0\n",
      "4            4  ../../data/denoised/chunk_0      DucAnh   99.7  109.9\n",
      "5            5  ../../data/denoised/chunk_0      DucAnh  121.0  132.1\n",
      "6            6  ../../data/denoised/chunk_0    BichNgoc  148.9  150.0\n",
      "7            7  ../../data/denoised/chunk_0      DucAnh  159.3  163.1\n",
      "8            8  ../../data/denoised/chunk_0    BichNgoc  186.4  188.8\n",
      "9            9  ../../data/denoised/chunk_0      DucAnh  203.2  240.2\n",
      "10          10  ../../data/denoised/chunk_0    BichNgoc  241.9  248.1\n",
      "11          11  ../../data/denoised/chunk_0      DucAnh  249.4  253.7\n",
      "12          12  ../../data/denoised/chunk_0    BichNgoc  253.9  255.5\n",
      "13          13  ../../data/denoised/chunk_0      DucAnh  270.1  271.8\n",
      "14          14  ../../data/denoised/chunk_0    BichNgoc  275.9  277.6\n"
     ]
    }
   ],
   "source": [
    "concat_audio(folder_name)               # Step 5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"vinai/PhoWhisper-large\", device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.9.11 safetensors-0.4.5 tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript(folder_name):\n",
    "    \"\"\"\n",
    "    Use:\n",
    "        concat audio\n",
    "        \n",
    "    Output:\n",
    "        transcripted audio\n",
    "            audio_path, transcript, speaker\n",
    "    \"\"\"\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/transcriber/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for folder in os.listdir(f'{data_path}/concat_audio/{folder_name}'):\n",
    "        folder_path = os.path.join(f'{data_path}/concat_audio/{folder_name}', folder)\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end', 'script'])\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            script = transcriber(file_path)\n",
    "            start, end, speaker = file_name.split()[0],file_name.split()[1],file_name.split()[2][:-4]\n",
    "            new_row = pd.DataFrame([{'audio_path': file_path, 'model_label': speaker, 'start': start, 'end': end, 'script':script}])\n",
    "            new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "        new_df.to_csv(f'{save_path}/{folder}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "/home/tuannd/.conda/envs/TuanLHA/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: create transcript func\n",
    "transcript(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-20 07:14:17--  https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..kycRgHdnJlANzMbsbUhs9g.GWYcOMJEqidV2e7CcxL_tjVbj7nAf-YUh50KSs-jGA-_KgzJJUHmn-7DEdXZE_pItnkjr2sGUbR3y4LbubVtn_OJNXMfuDgbhAcaQ4N-BwdL-fiJZ8VxUQQbfCB8Zg-mu3gZUxmk12djyDFdeo7hug6KzbY1pFSK1EvJotzP6yS-LtoVj0OONfoqrC0ssjY_zV3NuCH-fcMev-wfIMl2yCEtUMkRgwjx68hK-_LR8wMdRF8kjjMldsLy0qqxtTbMZVHNGFJtBBnABkutTbJLYoCbQ7VxuR0efxo3jZrXbNDVCX8J_BucKkr-B3oK-nwdeW8MxryKEZUBp6ISOfD8990Yg0sSI25PhvrW3Y66rM7W__vzNCvAsiFZvnAXcGU0ryJi6p2Ol9AZAgm2hDH_fLRyt0A5ksP8nY3269hYbUhNS0tNbYpy4p-t0AYbLPt-oT1m9_2y3aQ9TRSKOBjvJ6MrYJmdKE_YWNFNsK4N1OmiORCOiS5C4-FY6zlSam5KUsZnXOPDdSzYbB3j7ajd42qLeDJ7Xx7lRFpOvz7V_0R_bw1xIfpMjrbMhEIjnfDE2H85otdFzmvDev1274tAeqVtWcwd6SNp6O4wH00m1wBfA3Kc8aah_Z9YLvWkpNHjrEbS-IAyLPf9iQwO_DcP5MoADCxXLg0E0mEv9sre5oU.4rPptLagIpP5xZNt90yZ_Q/phobert_fold5.pth\n",
      "Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n",
      "Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 540096685 (515M) [application/x-zip]\n",
      "Saving to: ‘phobert_fold5.pth’\n",
      "\n",
      "phobert_fold5.pth   100%[===================>] 515.08M  7.11MB/s    in 77s     \n",
      "\n",
      "2024-09-20 07:15:35 (6.68 MB/s) - ‘phobert_fold5.pth’ saved [540096685/540096685]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..kycRgHdnJlANzMbsbUhs9g.GWYcOMJEqidV2e7CcxL_tjVbj7nAf-YUh50KSs-jGA-_KgzJJUHmn-7DEdXZE_pItnkjr2sGUbR3y4LbubVtn_OJNXMfuDgbhAcaQ4N-BwdL-fiJZ8VxUQQbfCB8Zg-mu3gZUxmk12djyDFdeo7hug6KzbY1pFSK1EvJotzP6yS-LtoVj0OONfoqrC0ssjY_zV3NuCH-fcMev-wfIMl2yCEtUMkRgwjx68hK-_LR8wMdRF8kjjMldsLy0qqxtTbMZVHNGFJtBBnABkutTbJLYoCbQ7VxuR0efxo3jZrXbNDVCX8J_BucKkr-B3oK-nwdeW8MxryKEZUBp6ISOfD8990Yg0sSI25PhvrW3Y66rM7W__vzNCvAsiFZvnAXcGU0ryJi6p2Ol9AZAgm2hDH_fLRyt0A5ksP8nY3269hYbUhNS0tNbYpy4p-t0AYbLPt-oT1m9_2y3aQ9TRSKOBjvJ6MrYJmdKE_YWNFNsK4N1OmiORCOiS5C4-FY6zlSam5KUsZnXOPDdSzYbB3j7ajd42qLeDJ7Xx7lRFpOvz7V_0R_bw1xIfpMjrbMhEIjnfDE2H85otdFzmvDev1274tAeqVtWcwd6SNp6O4wH00m1wBfA3Kc8aah_Z9YLvWkpNHjrEbS-IAyLPf9iQwO_DcP5MoADCxXLg0E0mEv9sre5oU.4rPptLagIpP5xZNt90yZ_Q/phobert_fold5.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " concat_audio.py\t\t  'output 186.3 to 188.8.wav'\n",
      " create_diarization.py\t\t  'output 86.6 to 87.8.wav'\n",
      " denoise.py\t\t\t   phobert_fold5.pth\n",
      "'_e2e_speaker_label copy.ipynb'    pretrained_models\n",
      " _e2e_speaker_label.ipynb\t   __pycache__\n",
      " e2e_speaker_label.py\t\t   remove_collision.py\n",
      "'hierarchy tree.txt'\t\t   split_audio.py\n",
      "'output 104.6 to 105.4.wav'\t   temp.py\n",
      "'output 148.9 to 150.0.wav'\t   transcript.py\n",
      "'output 150.6 to 151.2.wav'\t   verify_speaker.py\n",
      "'output 152.3 to 152.9 ảngy.wav'\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        last_hidden_state, output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False # Dropout will errors if without this\n",
    "        )\n",
    "\n",
    "        x = self.drop(output)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-20 07:25:10--  https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..HkEQpkATUWOQR2L4A444Uw.qHq40kZoU9ZuZWfxfgL8zm-O2YzWPv3KpsoNlNbIpRJ9qE0LT90gQfHNmHOL7JcAXsRfRlwgvTxsD8_Zbxsr_6sEtfMG79_ZzT0WOUDGYa8pV8w1Wy3kLuegmKA4OKRC7RNYTt05U35ctsx0e-dAHetUQvTnOVpz9BQZiNDlIC8M4YUyEefyuXqANcmGZzrQ3uxJRzw_7u6g7QEqngkL0XL4PTt6IongZQYVbIs6oftalCekmMaEGofXEN2z4KmrKkuXN1POHMnhH58pml_fT7jMuR-qi3nBCJgv5jb-aUCGlXJ8FzO5mWUaa20T9MBJUA9KLQXByIhV4e3TxgS65AJ59ntmWVuMEADuNkyvDnF9kT8LOse7G-P6m9NChydaZYZ94Q6TGFpMfes6yvH_gfomvFTRB6dv79c2b-y3t-CLecbw-TMOZllx4_je9wXmCNBJs1VOlnCL5KuBvpR7KyZOFgZccu1WE2pVZSBeEOvEqpojEGedCoql94tqW1eCfCoflRoJIxmsXvwvWaiAeOghmNQGdSEJdYD0uyyf94W-oOp10AsvhMUyx1A-LAh1JCQ79gS_3XshTlDvyvvBGWzatBJlOG5yLS9cMOqiJKYcjNxPyTstvnDBg7EW2gPWhIQUpikblYlt_Fj4SGXebJNmm8bYyhy-cQzrK0wrhiY.RaNQ0i-wgcYw-VFgNoOr5A/phobert_fold4.pth\n",
      "Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n",
      "Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 540096685 (515M) [application/x-zip]\n",
      "Saving to: ‘phobert_fold4.pth’\n",
      "\n",
      "phobert_fold4.pth   100%[===================>] 515.08M  6.29MB/s    in 83s     \n",
      "\n",
      "2024-09-20 07:26:33 (6.23 MB/s) - ‘phobert_fold4.pth’ saved [540096685/540096685]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.kaggleusercontent.com/kf/92356686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..HkEQpkATUWOQR2L4A444Uw.qHq40kZoU9ZuZWfxfgL8zm-O2YzWPv3KpsoNlNbIpRJ9qE0LT90gQfHNmHOL7JcAXsRfRlwgvTxsD8_Zbxsr_6sEtfMG79_ZzT0WOUDGYa8pV8w1Wy3kLuegmKA4OKRC7RNYTt05U35ctsx0e-dAHetUQvTnOVpz9BQZiNDlIC8M4YUyEefyuXqANcmGZzrQ3uxJRzw_7u6g7QEqngkL0XL4PTt6IongZQYVbIs6oftalCekmMaEGofXEN2z4KmrKkuXN1POHMnhH58pml_fT7jMuR-qi3nBCJgv5jb-aUCGlXJ8FzO5mWUaa20T9MBJUA9KLQXByIhV4e3TxgS65AJ59ntmWVuMEADuNkyvDnF9kT8LOse7G-P6m9NChydaZYZ94Q6TGFpMfes6yvH_gfomvFTRB6dv79c2b-y3t-CLecbw-TMOZllx4_je9wXmCNBJs1VOlnCL5KuBvpR7KyZOFgZccu1WE2pVZSBeEOvEqpojEGedCoql94tqW1eCfCoflRoJIxmsXvwvWaiAeOghmNQGdSEJdYD0uyyf94W-oOp10AsvhMUyx1A-LAh1JCQ79gS_3XshTlDvyvvBGWzatBJlOG5yLS9cMOqiJKYcjNxPyTstvnDBg7EW2gPWhIQUpikblYlt_Fj4SGXebJNmm8bYyhy-cQzrK0wrhiY.RaNQ0i-wgcYw-VFgNoOr5A/phobert_fold4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier(n_classes=7).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/1143647024.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/home/tuannd/tuanlha/EXpressiveTTS/src/speaker_diarization/phobert_fold4.pth'), strict=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('/home/tuannd/tuanlha/EXpressiveTTS/src/speaker_diarization/phobert_fold4.pth'), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "class_names = ['Enjoyment', 'Disgust', 'Sadness', 'Anger', 'Surprise', 'Fear', 'Other']\n",
    "\n",
    "def infer(text, tokenizer, max_len=120):\n",
    "    encoded_review = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_review['input_ids'].to(device)\n",
    "    attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "    output = model(input_ids, attention_mask)\n",
    "    _, y_pred = torch.max(output, dim=1)\n",
    "\n",
    "    print(f'Text: {text}')\n",
    "    print(f'Sentiment: {class_names[y_pred]}')\n",
    "    return class_names[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Cảm ơn bạn đã chạy thử model của mình. Chúc một ngày tốt lành nha!\n",
      "Sentiment: Enjoyment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Enjoyment'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer('Cảm ơn bạn đã chạy thử model của mình. Chúc một ngày tốt lành nha!', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_label(folder_name):\n",
    "    data_path = '../../data'\n",
    "    save_path = f'{data_path}/emotion_label/{folder_name}'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for folder in os.listdir(f'{data_path}/transcriber/{folder_name}'):\n",
    "        folder_path = os.path.join(f'{data_path}/transcriber/{folder_name}', folder)\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['audio_path', 'model_label', 'start', 'end', 'script', 'emotion'])\n",
    "        df = pd.read_csv(folder_path)\n",
    "        # print(df)\n",
    "        for _, row in df.iterrows():\n",
    "            audio_path,model_label,start,end,script = row['audio_path'], row['model_label'], row['start'], row['end'], row['script']\n",
    "            emotion = infer(script, tokenizer)\n",
    "            new_row = pd.DataFrame([{'audio_path': audio_path, 'model_label': model_label, 'start': start, 'end': end, 'script':script, 'emotion': emotion}])\n",
    "            new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "        new_df.to_csv(f'{save_path}/{folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 'hôm qua ở spa có liên hoan.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'ờ đêm nay tao phải chạy đết lai nên chắc là về muộn nếu mà có gì mà hân say quá thì mày đưa hân về nhá.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'cô đi là đúng đấy chứ tuần trước a hà nội rét buốt lạnh lắm cô ạ vừa mưa phùn nồm ẩm.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'gọi để nhắc em là nhớ quá cỡ.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'em học nói giọng sài gòn ở trên mạng đó.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'dạ vâng đấy cháu cũng đã định bay vào thăm ông anh họ ở trong khu công nghiệp bình dương nhưng mà giá vé thế này thì khó quá bọn cháu lái taxi thế này ngày được vài trăm bây giờ mà đi thì mất một ngày công.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'vui thì ở lại lâu lâu một xíu nhá.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'hôm nay với ngày mai là em xin nghỉ nhà em có khách ở quê ra còn gì ơ thì thoa ơi hết mắm tôm rồi bảo cái nhung ra chợ mua đi nhung ra chợ mua mắm tôm cho mẹ bảo trong trong ví lấy tiền cho mẹ đi thôi.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'mày thì cứ tại sao lại nói với mẹ như thế hả.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'thôi chị dự luật đi nhá.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'mà cháu nghe nói từ ngày mùng một tháng ba.'}\n",
      "Sentiment: Enjoyment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 'thứ hai là khoái nào làm sao em biết được cũng có thể là đức anh hay là cái hân nó khoái nhầm thì sao.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'để đến nỗi đêm chồng con có về không con cũng không biết.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'làm gì đâu có đúng là gì mà đòi khác đâu.'}\n",
      "Sentiment: Disgust\n",
      "Text: {'text': 'còn cái thi này thắng nước anh đâu anh ấy đi làm từ tháng à mẹ.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'lúc đấy con hay đi về đêm xong vào sáng đi sớm chắc thân không biết.'}\n",
      "Sentiment: Fear\n",
      "Text: {'text': 'mang cái xích từ đầy nào đầy nào ra khóa cổng.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'cái cái trích dắt ngoài cửa là.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'mình bảo là như thế có điện không.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'chưa ở trong đây đông lắm rồi.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'may quá gì đi mất tiền đẹp không ấy anh ơi không từ từ để anh đây có gì em đưa anh đi bệnh viện kiểm tra xem mình kiểm tra chụp chiếu xem thương khớp hay là.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'em gọi chả đứa nào nghe máy cả.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'thôi mình ăn nhanh đi còn việc không thi làm nữa.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'cháu có chọn ra chú xin học cho ế buổi liền.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'mẹ này mười hai giờ đấy nhá đúng mười hai giờ mà không gửi mail thì cô đừng có trách đấy.'}\n",
      "Sentiment: Other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
      "/tmp/ipykernel_27856/3996888680.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {'text': 'tí xong việc ở đây nhá em sẽ về công ty làm việc tiếp cho anh.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'thôi tập trung bây giờ tất cả các em hoàn thành phần việc của mình đúng hai tiếng nữa gửi email cho anh anh sẽ ở đây tổng hợp xử lý rồi gửi cho khách hàng anh em mình phải ăn chặt con điêu này.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'leo chốt phải gửi lúc mấy giờ là tết.'}\n",
      "Sentiment: Other\n",
      "Text: {'text': 'vẫn phải cố gắng ở thực lực chứ.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'đây là lần đầu tiên mà em chỉ ra một xíu thôi em đi chơi bạn về tí em sẽ chặn elai cho anh.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'vâng vâng vâng em biết rồi ạ.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'thưởng lắm lắm chụp vì phát ngôn xuất sắc thật nhát hay nhát thật à này từ từ trừ với cái tiền đi muộn vẫn hôn nợ công ty chưa trả đâu.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'vừa kiếm được một cái rót rất ngon luôn anh đã gửi mail phân công công việc cho từng đứa rồi check mail luôn đi mình có đúng một đêm nay để làm bản kế hoạch chi tiết truyền thông cho khách hàng.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'trước bảy giờ sáng mai có như thắng anh đã làm việc riêng với trợ lý bên họ rồi.'}\n",
      "Sentiment: Sadness\n",
      "Text: {'text': 'em đây em đây.'}\n",
      "Sentiment: Enjoyment\n",
      "Text: {'text': 'bây giờ anh cho mày đúng ba mươi giây để trả lời đang ở đâu với ai làm gì.'}\n",
      "Sentiment: Anger\n",
      "Text: {'text': 'cháu định gọi cho cô để báo với cô là à hôm nay a phiến ngọc là phải tăng ca về muộn cô ạ dạ vâng dạ vâng ạ cô yên tâm đi ngủ trước đi ạ chào chào cô.anh chiều mày quá nên mày hư đúng không anh nhận mày vào công ty không phải là để nói dối mẹ xong rồi kiếm cớ đi chơi được nhé.'}\n",
      "Sentiment: Disgust\n"
     ]
    }
   ],
   "source": [
    "emotion_label(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuanlha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
