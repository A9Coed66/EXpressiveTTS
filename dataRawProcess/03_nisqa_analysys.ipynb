{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NISQA Analysys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tổng kết thời gian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tool import  get_episode_duration, get_mp3_duration_ffprobe\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import os\n",
    "filter_path = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/04_denoise'\n",
    "raw_path = '/home4/tuanlha/DataTest'\n",
    "vad_path = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/03_vad'\n",
    "\n",
    "playlist_name = os.listdir(vad_path)\n",
    "sorted(playlist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_name = ['DuyThanhNguyenFinance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tong thoi gian du lieu raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_episode(playlist, vad_path, episode_name):\n",
    "    playlist_path = os.path.join(vad_path, playlist)\n",
    "    episode_path = os.path.join(playlist_path, episode_name)\n",
    "    duration = get_episode_duration(episode_path)\n",
    "    print(f'Playlist: {playlist}, Episode: {episode_name}, Duration: {duration} seconds')\n",
    "    return (playlist, episode_name, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_vad = {}\n",
    "for playlist in playlist_name:\n",
    "    playlist_path = os.path.join(vad_path, playlist)\n",
    "    dct_vad[playlist] = {}\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for episode_name in os.listdir(playlist_path):\n",
    "            futures.append(executor.submit(process_episode, playlist, vad_path, episode_name))\n",
    "        \n",
    "        for future in futures:\n",
    "            playlist, episode_name, duration = future.result()\n",
    "            dct_vad[playlist][episode_name] = duration\n",
    "    for episode_name in os.listdir(playlist_path):\n",
    "        episode_path = os.path.join(playlist_path, episode_name)\n",
    "        duration = get_episode_duration(episode_path)\n",
    "        dct_vad[playlist][episode_name] = duration\n",
    "        print(f'Playlist: {playlist}, Episode: {episode_name}, Duration: {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_raw = {}\n",
    "for playlist in playlist_name:\n",
    "    playlist_path = os.path.join(raw_path, playlist)\n",
    "    dct_raw[playlist] = {}\n",
    "    for episode_name in os.listdir(playlist_path):\n",
    "        duration = get_mp3_duration_ffprobe(os.path.join(playlist_path, episode_name))\n",
    "        episode_name = episode_name.rsplit('.', 1)[0]\n",
    "        dct_raw[playlist][episode_name] = duration\n",
    "        print(f'Playlist: {playlist}, Episode: {episode_name}, Duration: {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_filter = {}\n",
    "for playlist in playlist_name:\n",
    "    playlist_path = os.path.join(filter_path, playlist)\n",
    "    dct_filter[playlist] = {}\n",
    "    for episode_name in os.listdir(playlist_path):\n",
    "        episode_path = os.path.join(playlist_path, episode_name)\n",
    "        duration = get_episode_duration(episode_path)\n",
    "        dct_filter[playlist][episode_name] = duration\n",
    "        print(f'Playlist: {playlist}, Episode: {episode_name}, Duration: {duration} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save raw, vad, filter duration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare durations\n",
    "mean_filter_extract = {}\n",
    "mean_vad_extract={}\n",
    "for playlist in playlist_name:\n",
    "    vad_percentage = []\n",
    "    filter_percentage = []\n",
    "    print(f'Playlist: {playlist}')\n",
    "    for episode_name in dct_vad[playlist]:\n",
    "        vad_duration = dct_vad[playlist][episode_name]\n",
    "        raw_duration = dct_raw[playlist].get(episode_name, None)\n",
    "        filter_duration = dct_filter[playlist].get(episode_name, None)\n",
    "        vad_percentage.append(vad_duration * 100 / raw_duration)\n",
    "        filter_percentage.append(filter_duration * 100 / raw_duration)\n",
    "        if raw_duration is not None and filter_duration is not None:\n",
    "            print(f'Episode: {episode_name[:10]}, Raw Duration: {raw_duration}, VAD Duration: {vad_duration*100/raw_duration}, Filter Duration: {filter_duration*100/raw_duration}')\n",
    "        else:\n",
    "            print(f'Episode: {episode_name[:10]} missing in raw or filter data')\n",
    "    mean_filter_extract[playlist] = sum(filter_percentage) / len(filter_percentage) if filter_percentage else 0\n",
    "    mean_vad_extract[playlist] = sum(vad_percentage) / len(vad_percentage) if vad_percentage else 0\n",
    "print('Mean VAD Extract:', mean_vad_extract)\n",
    "print('Mean Filter Extract:', mean_filter_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "# with open('dct_vad.json', 'w') as f:\n",
    "#     json.dump(dct_vad, f, indent=4)\n",
    "# with open('dct_filter.json', 'w') as f:\n",
    "#     json.dump(dct_filter, f, indent=4)\n",
    "# with open('dct_raw.json', 'w') as f:\n",
    "#     json.dump(dct_raw, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('dct_raw.json', 'r') as f:\n",
    "#     dct_vad = json.load(f)\n",
    "\n",
    "# #get all duration\n",
    "# total_duration_vad = 0\n",
    "# for playlist, episodes in dct_vad.items():\n",
    "#     for episode_name, duration in episodes.items():\n",
    "#         total_duration_vad += duration\n",
    "# print(f'Total duration of VAD episodes: {total_duration_vad} seconds')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thống kê NISQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "filter_path = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/05_data_extract/HaveASipClean'\n",
    "\n",
    "ls = []\n",
    "for csv_file in os.listdir(filter_path):\n",
    "    if csv_file.endswith('wvmos.csv'):\n",
    "        csv_path = os.path.join(filter_path, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df['score'].tolist()\n",
    "        ls.append([csv_file, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = [0.2*i for i in range (0, 25)]\n",
    "def create_bins(data, file_name):\n",
    "    # Đếm số phần tử trong mỗi khoảng\n",
    "    counts, bin_edges = np.histogram(data, bins=bins)\n",
    "\n",
    "    # Tạo nhãn cho các khoảng (ví dụ: 0.0-0.5, 0.5-1.0,...)\n",
    "    bin_labels = [f\"{bin_edges[i]:.1f}-{bin_edges[i+1]:.1f}\" for i in range(len(bin_edges)-1)]\n",
    "\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(bin_labels, counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Thêm số lượng lên từng cột\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "    plt.title('Phân phối giá trị theo khoảng', fontweight='bold')\n",
    "    plt.xlabel(f'{file_name}')\n",
    "    plt.ylabel('Số lượng phần tử')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for csv_file, df in ls:\n",
    "    create_bins(df, csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thống kê WV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "filter_path = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/05_data_extract/HaveASipClean'\n",
    "\n",
    "ls = []\n",
    "for csv_file in os.listdir(filter_path):\n",
    "    if csv_file.endswith('mos.csv'):\n",
    "        csv_path = os.path.join(filter_path, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df['score'].tolist()\n",
    "        ls.append([csv_file, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = [0.2*i for i in range (10, 25)]\n",
    "def create_bins(data, file_name):\n",
    "    # Đếm số phần tử trong mỗi khoảng\n",
    "    counts, bin_edges = np.histogram(data, bins=bins)\n",
    "\n",
    "    # Tạo nhãn cho các khoảng (ví dụ: 0.0-0.5, 0.5-1.0,...)\n",
    "    bin_labels = [f\"{bin_edges[i]:.1f}-{bin_edges[i+1]:.1f}\" for i in range(len(bin_edges)-1)]\n",
    "\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(bin_labels, counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Thêm số lượng lên từng cột\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "    plt.title('Phân phối giá trị theo khoảng', fontweight='bold')\n",
    "    plt.xlabel(f'{file_name}')\n",
    "    plt.ylabel('Số lượng phần tử')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for csv_file, df in ls:\n",
    "    create_bins(df, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "filter_path = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/05_data_extract/HaveASipClean'\n",
    "\n",
    "ls = []\n",
    "for csv_file in os.listdir(filter_path):\n",
    "    if csv_file.endswith('results.csv'):\n",
    "        csv_path = os.path.join(filter_path, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df['mos_pred'].tolist()\n",
    "        ls.append([csv_file, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = [0.2*i for i in range (0, 25)]\n",
    "def create_bins(data, file_name):\n",
    "    # Đếm số phần tử trong mỗi khoảng\n",
    "    counts, bin_edges = np.histogram(data, bins=bins)\n",
    "\n",
    "    # Tạo nhãn cho các khoảng (ví dụ: 0.0-0.5, 0.5-1.0,...)\n",
    "    bin_labels = [f\"{bin_edges[i]:.1f}-{bin_edges[i+1]:.1f}\" for i in range(len(bin_edges)-1)]\n",
    "\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(bin_labels, counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Thêm số lượng lên từng cột\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "    plt.title('Phân phối giá trị theo khoảng', fontweight='bold')\n",
    "    plt.xlabel(f'{file_name}')\n",
    "    plt.ylabel('Số lượng phần tử')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for csv_file, df in ls:\n",
    "    create_bins(df, csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## play các audio có vấn đề"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Audio, display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_audio(audio_path):\n",
    "    if os.path.exists(audio_path):\n",
    "        display(Audio(audio_path, autoplay=True))\n",
    "    else:\n",
    "        print(f\"File {audio_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_path = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/05_data_extract/HaveASipClean'\n",
    "audio_data = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/04_vad/HaveASipClean'\n",
    "cnt_episode=  0\n",
    "for file_name in os.listdir(filter_path):\n",
    "    if file_name.endswith('results.csv'):\n",
    "        continue\n",
    "    df = pd.read_csv(os.path.join(filter_path, file_name))\n",
    "    print(df)\n",
    "    df = df[df['score'] > 3.0]\n",
    "    # df = df.tolist()\n",
    "\n",
    "    episode_name = file_name.split('_')[0]\n",
    "    episode_path = os.path.join(audio_data, episode_name)\n",
    "    print(episode_name)\n",
    "    cnt = 0\n",
    "    for index, row in df.iterrows():\n",
    "        file_path = os.path.join(episode_path, row['audio_path'])\n",
    "        print(f'Playing {row[\"audio_path\"]} audio score {row[\"score\"]}:')\n",
    "        display(Audio(file_path, autoplay=True))\n",
    "        cnt+=1\n",
    "        if cnt>4:\n",
    "            break\n",
    "    cnt_episode+=1\n",
    "    if cnt_episode>4:\n",
    "        break\n",
    "    #https://youtu.be/DcCIb1cjKvg?si=7Jog8Mc6MM4ovNJH&t=1037\n",
    "    #https://youtu.be/DcCIb1cjKvg?si=EwlihDEW_hxEKaQu&t=449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_path = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/05_data_extract/HaveASip'\n",
    "audio_data = '/home4/tuanlha/EXpressiveTTS/dataRawProcess/05_transcript/HaveASip'\n",
    "cnt_episode=  0\n",
    "for file_name in os.listdir(filter_path):\n",
    "    df = pd.read_csv(os.path.join(filter_path, file_name))\n",
    "    df = df[df['mos_pred'] > 4.0]['deg']\n",
    "    df = df.tolist()\n",
    "\n",
    "    episode_name = file_name.split('_')[0]\n",
    "    episode_path = os.path.join(audio_data, episode_name)\n",
    "    print(episode_name)\n",
    "    cnt = 0\n",
    "    for item in df:\n",
    "        file_path = os.path.join(episode_path, item)\n",
    "        print(f'Playing {item} audio:')\n",
    "        display(Audio(file_path, autoplay=True))\n",
    "        cnt+=1\n",
    "        if cnt>4:\n",
    "            break\n",
    "    cnt_episode+=1\n",
    "    if cnt_episode>4:\n",
    "        break\n",
    "    #https://youtu.be/DcCIb1cjKvg?si=7Jog8Mc6MM4ovNJH&t=1037\n",
    "    #https://youtu.be/DcCIb1cjKvg?si=EwlihDEW_hxEKaQu&t=449"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TuanLHA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
